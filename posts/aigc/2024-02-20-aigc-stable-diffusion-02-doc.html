<!doctype html>
<html lang="zh-CN" data-theme="light">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-rc.24" />
    <meta name="theme" content="VuePress Theme Hope 2.0.0-rc.94" />
    <style>
      :root {
        --vp-c-bg: #fff;
      }

      [data-theme="dark"] {
        --vp-c-bg: #1b1b1f;
      }

      html,
      body {
        background: var(--vp-c-bg);
      }
    </style>
    <script>
      const userMode = localStorage.getItem("vuepress-theme-hope-scheme");
      const systemDarkMode =
        window.matchMedia &&
        window.matchMedia("(prefers-color-scheme: dark)").matches;

      if (userMode === "dark" || (userMode !== "light" && systemDarkMode)) {
        document.documentElement.setAttribute("data-theme", "dark");
      }
    </script>
    <script type="application/ld+json">{"@context":"https://schema.org","@type":"Article","headline":"Stable Diffusion-01-入门概览","image":[""],"dateModified":"2025-12-27T05:14:38.000Z","author":[{"@type":"Person","name":"老马啸西风","url":"https://houbb.github.io"}]}</script><meta property="og:url" content="https://houbb.github.io/blog-thinking/posts/aigc/2024-02-20-aigc-stable-diffusion-02-doc.html"><meta property="og:site_name" content="老马啸西风"><meta property="og:title" content="Stable Diffusion-01-入门概览"><meta property="og:description" content="稳定扩散版本2 此仓库包含从头开始训练的Stable Diffusion模型，并将持续更新新的检查点。以下是当前可用模型的概述。更多内容即将发布。 最新动态 2023年3月24日 Stable UnCLIP 2.1 基于SD2.1-768，在768x768分辨率下的新的稳定扩散微调（Stable unCLIP 2.1，Hugging Face）。此模型..."><meta property="og:type" content="article"><meta property="og:locale" content="zh-CN"><meta property="og:updated_time" content="2025-12-27T05:14:38.000Z"><meta property="article:tag" content="sh"><meta property="article:tag" content="aigc"><meta property="article:tag" content="ai"><meta property="article:modified_time" content="2025-12-27T05:14:38.000Z"><title>Stable Diffusion-01-入门概览 | 老马啸西风</title><meta name="description" content="稳定扩散版本2 此仓库包含从头开始训练的Stable Diffusion模型，并将持续更新新的检查点。以下是当前可用模型的概述。更多内容即将发布。 最新动态 2023年3月24日 Stable UnCLIP 2.1 基于SD2.1-768，在768x768分辨率下的新的稳定扩散微调（Stable unCLIP 2.1，Hugging Face）。此模型...">
    <link rel="preload" href="/blog-thinking/assets/style-Bb931w8d.css" as="style"><link rel="stylesheet" href="/blog-thinking/assets/style-Bb931w8d.css">
    <link rel="modulepreload" href="/blog-thinking/assets/app-Dvf0wTTF.js"><link rel="modulepreload" href="/blog-thinking/assets/2024-02-20-aigc-stable-diffusion-02-doc.html-DdSzvRaR.js"><link rel="modulepreload" href="/blog-thinking/assets/plugin-vue_export-helper-DlAUqK2U.js">
    <link rel="prefetch" href="/blog-thinking/assets/index.html-DJ916H6l.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/intro.html-CotTyzew.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-03-07-ai-learn-what-is-manus.html-Bbr7cHOx.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-04-03-ai-brower-agent-01-agentGPT.html-DwLiCRpL.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-04-03-ai-brower-agent-02-browser-use.html-BkTHNJ5g.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-20-ai-sdd-09-skills-zh.html-B11OWNR6.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-20-ai-sdd-10-skills-docs-gen.html-DxF_6tZB.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-20-ai-sdd-21-agent-skills-01-what-is.html-BHpJ9tyM.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-20-ai-sdd-21-agent-skills-02-specfication.html-Cr9d79eY.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-20-ai-sdd-21-agent-skills-03-integrate.html-DSOGLC9t.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2023-03-24-ai-code.html-GOIY7SzP.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2023-03-24-ai-text-to-image-web.html-C9yfiaP6.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2023-03-24-ai-text-to-image.html-91NmUEps.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2024-02-20-ai-01-autogpt-01-overview.html-CKeNjuQh.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2024-02-20-ai-02-openui-01-overview.html-CYNMoPZ0.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2024-02-20-ai-03-awesome-prompts.html-ByxgAzaX.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2024-02-20-ai-03-prompt-guide.html-BKgppnFn.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2024-02-20-ai-04-chatGPT-deploy.html-bzJDgNFr.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2024-02-20-ai-05-gpt4free.html-BypxYV82.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2024-02-20-ai-06-chatgpt-academic.html-B0-r-2On.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2024-02-20-ai-07-aigc-for-beginners.html-DG4CCk1I.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2024-02-20-ai-08-chatGPT-next-web.html-CS8B3aJc.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2024-02-20-ai-09-openai-cookbook.html-DXj4A5d4.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2024-02-20-ai-10-openai-assistant.html-X5lYwyEZ.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2024-02-20-ai-11-quivr.html-DFVqOQU6.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2024-02-20-ai-12-lobe-chat.html-BRlRJwyK.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2024-02-20-ai-13-langchain-chat.html-CcRtp-17.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2024-02-20-ai-14-wechatMSG.html-3LKnEeWH.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2024-02-20-ai-15-autogen.html-C9-EgDu5.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2024-02-20-ai-16-code-gen-devika-intro.html-CUJJobTQ.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2024-02-20-ai-17-chatgpt-on-wechat.html-WruO0aJH.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2024-02-20-ai-nlp-segment-01-overview.html-CvKmKE1Z.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2024-02-20-ai-overview.html-Dg_6Gtoq.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2024-02-20-ai-video-01-overview copy.html-oonELA_L.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2024-02-20-ai-video-01-overview.html-B_4Odx5Y.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2024-02-20-aigc-overview.html-4fLlgw0s.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2024-02-20-aigc-stable-diffusion-01-overview.html-GYPT1tzI.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2024-02-20-aigc-stable-diffusion-02-doc.html-DQLV39gR.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2024-02-20-openai-chatgpt-paper-01-intro.html-CJJkdcd9.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2024-02-20-openai-chatgpt-paper-02-tec.html-BsA1Z-c_.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2024-02-20-openai-chatgpt-paper-03-dall-e-3-simple.html-BspJRx9N.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2024-02-20-openai-chatgpt-paper-03-dall-e-3.html-oEF4t9aV.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2024-02-20-openai-chatgpt-paper-04-sora-tech.html-Cu3OB7d2.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2024-03-20-xai-org-gork-00-attention-is-all-you-need.html-BvnOs5j5.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2024-03-20-xai-org-gork-00-transformer-intro.html-BH1q0IzY.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2024-03-20-xai-org-gork-01-sourcecode-1.html-Dhk6YTix.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2024-03-20-xai-org-gork-01-sourcecode-2.html-UKOBBeSH.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2024-03-20-xai-org-gork-01-sourcecode-3.html-DmAKCdoF.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2024-03-20-xai-org-gork-01-sourcecode-4.html-va-G_YJT.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-12-27-ai-dev-roads.html-C8KGYUz6.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2022-12-06-ai-chatGPT.html-D5bs8nPN.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2022-12-06-ai-dell2-intro-01-overview.html-DeyQjEyh.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2024-02-20-aigc-overview.html-DOQ8ZBAj.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2024-02-20-aigc-stable-diffusion-01-overview.html-BLdoa86A.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-03-07-ai-ide-00-overview.html-CBtD4kvJ.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-03-07-ai-ide-01-trae-intro.html-CeMxDffk.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-20-ai-sdd-11-gemini-cli-use-inaction.html-DweDePLd.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-20-ai-sdd-12-gemini-cli-use-intro.html-BXs_VMOj.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-20-ai-sdd-13-gemini-cli-use-for-old-project-project-profile.html-DeqF0EAq.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-20-ai-sdd-13-gemini-cli-use-for-old-project.html-Dt3kYOaP.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-20-ai-sdd-14-gemini-cli-use-for-new-project-springboot.html-S7yWU7ba.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-20-ai-sdd-15-gemini-cli-use-for-new-project-vue3.html-K7FVT-8R.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-12-15-google-cli-text-to-image.html-OFmM1Zrj.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2023-04-14-ai-learn-01-overview.html-BVV_I_G_.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2023-04-14-ai-learn-02-basic.html-D3yGk_B1.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2023-04-14-ai-learn-03-math.html-CjfOGbBO.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2023-04-14-ai-learn-04-python-ai.html-DVl9uUol.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2023-04-14-ai-learn-05-deeplearing.html-CJ4757eX.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2023-04-14-ai-weka-01-overview.html-5qL7nXsk.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2023-04-14-ai-weka-02-java-hello-world.html-BOyh7uLR.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2023-04-14-ai-weka-03-java-letter-and-digits.html-DgbySiDH.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2023-04-14-ai-weka-04-mnist.html-CCB08bJ9.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2023-05-09-ai-jpmml-01-overview.html-C1gKWQGy.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-03-dive-into-llms-00-overview.html-DaNNfR-a.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-03-dive-into-llms-01-basic-python-intro.html-CNX6ajyV.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-03-dive-into-llms-02-basic-deep-learning-intro.html-B1ixiV1h.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-03-dive-into-llms-03-basic-nlp-big-model.html-C0i_AAdS.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-03-dive-into-llms-04-transformers-01-intro.html-Dj0ySpv3.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-03-dive-into-llms-05-pytorch-01-intro.html-CQ2wb0rA.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-03-dive-into-llms-06-transformers-02-quick-start-requirements.html-K7QqUoWC.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-03-dive-into-llms-06-transformers-03-pipeline.html-FiaQoxNA.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-03-dive-into-llms-06-transformers-04-pipeline-intro.html-D1UaxFss.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-03-dive-into-llms-100-ml-history.html-Qx0efQJ0.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-03-dive-into-llms-100-ml-intro.html-yqizlYG5.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-03-dive-into-llms-101-ml-vs-dl.html-CBGUnUWO.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-03-dive-into-llms-102-ml-nlp-usage.html-DP1BXQAx.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-03-dive-into-llms-103-ml-other-usage.html-Kf_SJY90.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-03-dive-into-llms-104-ml-sentiment-analysis.html-Bnv5geMX.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-03-dive-into-llms-11-chap01.html-BNAIxXLc.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-03-dive-into-llms-30-dl-intro.html-B4W1lGQE.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-03-dive-into-llms-31-dl-how-to-learn.html-CWDIIFdx.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-03-dive-into-llms-32-dl-write-minist.html-DF0Iasw0.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-03-dive-into-llms-33-dl-write-mnist-sequence.html-BsP6cUmO.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-03-dive-into-llms-34-dl-CNN-intro.html-tn630XsE.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-02-03-deepseek-r1-ai-model-compare.html-D37jlTC2.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-02-03-deepseek-r1-how-to-earn-money-by-ai.html-BXhahlhg.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-02-03-deepseek-r1-paper-intro.html-CLPkdbgo.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-04-15-ai-mcp-01-intro.html-pLcseMfT.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-04-15-ai-mcp-02-awesome-servers.html-u3XzGTgI.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-04-15-ai-mcp-03-open-webui.html-BnXxHhN-.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-04-15-ai-mcp-04-n8n.html-DjZHelJL.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-04-15-ai-mcp-05-anything-llm.html-C5kVfPer.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-04-15-ai-mcp-06-maxkb.html-1NqTnc0v.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-04-15-ai-mcp-07-dify-intro.html-CKtg1-VD.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-04-15-ai-mcp-08-awesome-dify-vs.html-uHmFq16X.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-04-15-ai-mcp-08-awesome-dify-workflow.html-5gUwEIRG.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-04-15-ai-mcp-09-difyaia.html-B7nB1HXF.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-04-15-ai-mcp-10-activepieces.html-BHEiQIXd.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-04-15-ai-mcp-11-playwright-mcp.html-CZNJIaQX.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-04-15-ai-mcp-12-aws-mcp.html-C7CrfBEf.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-04-15-ai-mcp-13-github-mcp.html-5HTEO9Us.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-04-15-ai-mcp-14-a2a-intro.html-MIynuyzf.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-04-15-ai-mcp-15-flow-control-opensource.html-eid9JrjD.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-09-16-mcp-01-intro-and-hello-world.html-BMSm2xzD.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-03-00-ml-book-index.html-D5d-x0zU.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-03-01-ml-book-history.html-CYNVwPvf.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-03-02-ml-book-core-thought.html-IV2acD0K.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-03-03-ml-book-rate-and-stat.html-B0MyA18W.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-03-04-ml-book-matrix.html-BjRr9uL1.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-03-05-ml-book-loss-and-val.html-D-_xQRLL.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-03-06-ml-book-line-model.html-DlxZ-fKd.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-03-07-ml-book-knn.html-l7TR5fcP.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-03-08-ml-book-decision-tree.html-TbnXm_93.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-03-09-ml-book-rate-model-stat-learn.html-D_PUoz0S.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-03-10-ml-book-k-means.html-mjCiE4h2.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-03-11-ml-book-feature.html-iJt-q1Jq.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-03-12-ml-book-model-eval-and-opt.html-B28bMmLk.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-03-13-ml-book-nlp-inaction.html-CtVYS9zH.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-03-14-ml-book-cv.html-BCiMTFYD.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-03-15-ml-book-time-series.html-Bz6s6fL4.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-03-16-ml-book-deeplearning.html-DEIapI9t.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-03-17-ml-book-CNN.html-D0ysH8y6.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-03-18-ml-book-LLM.html-xWYrPU7Z.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-03-19-ml-book-believe.html-ujX1yUCh.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-03-20-ml-book-think-model.html-CCXDoL6Q.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-03-21-ml-book-future.html-DVtAslDB.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-20-ai-sdd-01-overview.html-DA8W17vT.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-20-ai-sdd-02-sepc-kit-intro.html-nqk8gPlD.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-20-ai-sdd-03-opensepc-intro.html-Bhpsoxls.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-20-ai-sdd-04-kiro-intro.html-CU7AswuS.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-20-ai-sdd-05-sepc-kit-inaction.html-DtyMHS_d.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-20-ai-sdd-06-openspec-inaction.html-DcsmTs7E.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-20-ai-sdd-07-skills.html-MgOO_axH.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-20-ai-sdd-08-ali-taobao-best-practise.html-BFp-q5mv.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-20-ai-sdd-16-what-about-rules-design.html-WhjKJDx1.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-20-ai-sdd-17-ai-corp-paper.html-BmwXEMWh.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-20-ai-sdd-18-gemini-template.html-h-mWWoIm.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-20-ai-sdd-19-project-profile-template.html-BAMLWiZ-.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-20-ai-sdd-20-design-template.html-BhM7AvF5.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/404.html-BK5oZxyf.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/index.html-C3-Oa4Q4.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/index.html-BBnO1GBe.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/index.html-B50XtgFq.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/index.html-bNsWizzc.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/index.html-BnvxU8H1.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/index.html-oHq67JwQ.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/index.html-mN0MmMhD.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/index.html-CXmVDF9j.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/index.html-CVASEOro.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/index.html-D2Vd0WXq.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/index.html-DDFTKWjR.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/index.html-mHA3wJmq.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/index.html-DdOuoQed.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/index.html-B3ktFRBf.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/index.html-CjEeKeLh.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/index.html-CfP7kdNG.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/index.html-DL_4KlzA.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/index.html-JxsLJ1hv.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/index.html-DhPaGt8D.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/index.html-B1sV4R5d.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/index.html-Cc4Oe9I_.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/index.html-B-_l2aEg.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/index.html-BwfKpv4b.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/index.html-JQ1sR7hl.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/index.html-em3-JA64.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/index.html-vwYW7S8m.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/index.html-BgaGPTxW.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/index.html-BMSPkyBH.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/index.html-CopRigQP.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/index.html-SnGb-ISj.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/index.html-TyR8su45.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/index.html-rP1xWCr3.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/index.html-C_jXk-p3.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/index.html-DL51r8Uu.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/index.html-J9ulgMIp.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/index.html-DJBwNVZ9.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/index.html-D3Agmo5I.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/photoswipe.esm-CKV1Bsxh.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/auto-BUYG9-ss.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/index-C1rb1p6e.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/flowchart-G1WAoCnn.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/index-DtWMYcbt.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/index-DMDrkyre.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/index-BPAdBlYL.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/mermaid.esm.min-DbhK467j.js" as="script">
  </head>
  <body>
    <div id="app"><!--[--><!--[--><!--[--><span tabindex="-1"></span><a href="#main-content" class="vp-skip-link sr-only">跳至主要內容</a><!--]--><div class="theme-container no-sidebar external-link-icon has-toc" vp-container><!--[--><header id="navbar" class="vp-navbar" vp-navbar><div class="vp-navbar-start"><button type="button" class="vp-toggle-sidebar-button" title="Toggle Sidebar"><span class="icon"></span></button><!--[--><a class="route-link vp-brand" href="/blog-thinking/" aria-label="带我回家"><img class="vp-nav-logo" src="/blog-thinking/assets/images/lmxxf.png" alt><!----><span class="vp-site-name hide-in-pad">老马啸西风</span></a><!--]--></div><div class="vp-navbar-center"><!--[--><nav class="vp-nav-links"><div class="vp-nav-item hide-in-mobile"><div class="vp-dropdown-wrapper"><button type="button" class="vp-dropdown-title" aria-label="个人成长"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:user-graduate" sizing="height" height="1em"></iconify-icon>个人成长<!--]--><span class="arrow"></span><ul class="vp-dropdown"><li class="vp-dropdown-item"><a class="route-link auto-link" href="/blog-thinking/category/notes/" aria-label="老马随笔"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:pen-nib" sizing="both" width="1em" height="1em"></iconify-icon><!--]-->老马随笔<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/blog-thinking/category/company/" aria-label="职业发展"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:user-tie" sizing="both" width="1em" height="1em"></iconify-icon><!--]-->职业发展<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/blog-thinking/category/methodsandmodel/" aria-label="方法模型"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:diagram-project" sizing="both" width="1em" height="1em"></iconify-icon><!--]-->方法模型<!----></a></li></ul></button></div></div><div class="vp-nav-item hide-in-mobile"><div class="vp-dropdown-wrapper"><button type="button" class="vp-dropdown-title" aria-label="财务自由"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:sack-dollar" sizing="height" height="1em"></iconify-icon>财务自由<!--]--><span class="arrow"></span><ul class="vp-dropdown"><li class="vp-dropdown-item"><a class="route-link auto-link" href="/blog-thinking/category/money/" aria-label="财富自由"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:sack-dollar" sizing="both" width="1em" height="1em"></iconify-icon><!--]-->财富自由<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/blog-thinking/category/business/" aria-label="商业思考"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:briefcase" sizing="both" width="1em" height="1em"></iconify-icon><!--]-->商业思考<!----></a></li></ul></button></div></div><div class="vp-nav-item hide-in-mobile"><div class="vp-dropdown-wrapper"><button type="button" class="vp-dropdown-title" aria-label="推广营销"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:bullhorn" sizing="height" height="1em"></iconify-icon>推广营销<!--]--><span class="arrow"></span><ul class="vp-dropdown"><li class="vp-dropdown-item"><a class="route-link auto-link" href="/blog-thinking/category/marketing/" aria-label="市场营销"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:bullhorn" sizing="both" width="1em" height="1em"></iconify-icon><!--]-->市场营销<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/blog-thinking/category/fans/" aria-label="媒体运营"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:photo-film" sizing="both" width="1em" height="1em"></iconify-icon><!--]-->媒体运营<!----></a></li></ul></button></div></div><div class="vp-nav-item hide-in-mobile"><div class="vp-dropdown-wrapper"><button type="button" class="vp-dropdown-title" aria-label="生活兴趣"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:heart" sizing="height" height="1em"></iconify-icon>生活兴趣<!--]--><span class="arrow"></span><ul class="vp-dropdown"><li class="vp-dropdown-item"><a class="route-link auto-link" href="/blog-thinking/category/travel/" aria-label="环游世界"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:globe" sizing="both" width="1em" height="1em"></iconify-icon><!--]-->环游世界<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/blog-thinking/category/moive/" aria-label="电影影视"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:film" sizing="both" width="1em" height="1em"></iconify-icon><!--]-->电影影视<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/blog-thinking/category/reading/" aria-label="读书笔记"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:book-open" sizing="both" width="1em" height="1em"></iconify-icon><!--]-->读书笔记<!----></a></li></ul></button></div></div><div class="vp-nav-item hide-in-mobile"><a class="route-link route-link-active auto-link" href="/blog-thinking/posts/" aria-label="全部文章"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:pen-to-square" sizing="height" height="1em"></iconify-icon><!--]-->全部文章<!----></a></div></nav><!--]--></div><div class="vp-navbar-end"><!--[--><!----><div class="vp-nav-item vp-action"><a class="vp-action-link" href="https://github.com/bbhou/lmxxf-notes" target="_blank" rel="noopener noreferrer" aria-label="GitHub"><svg xmlns="http://www.w3.org/2000/svg" class="icon github-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="github icon" name="github" style="width:1.25rem;height:1.25rem;vertical-align:middle;"><path d="M511.957 21.333C241.024 21.333 21.333 240.981 21.333 512c0 216.832 140.544 400.725 335.574 465.664 24.49 4.395 32.256-10.07 32.256-23.083 0-11.69.256-44.245 0-85.205-136.448 29.61-164.736-64.64-164.736-64.64-22.315-56.704-54.4-71.765-54.4-71.765-44.587-30.464 3.285-29.824 3.285-29.824 49.195 3.413 75.179 50.517 75.179 50.517 43.776 75.008 114.816 53.333 142.762 40.79 4.523-31.66 17.152-53.377 31.19-65.537-108.971-12.458-223.488-54.485-223.488-242.602 0-53.547 19.114-97.323 50.517-131.67-5.035-12.33-21.93-62.293 4.779-129.834 0 0 41.258-13.184 134.912 50.346a469.803 469.803 0 0 1 122.88-16.554c41.642.213 83.626 5.632 122.88 16.554 93.653-63.488 134.784-50.346 134.784-50.346 26.752 67.541 9.898 117.504 4.864 129.834 31.402 34.347 50.474 78.123 50.474 131.67 0 188.586-114.73 230.016-224.042 242.09 17.578 15.232 33.578 44.672 33.578 90.454v135.85c0 13.142 7.936 27.606 32.854 22.87C862.25 912.597 1002.667 728.747 1002.667 512c0-271.019-219.648-490.667-490.71-490.667z"></path></svg></a></div><div class="vp-nav-item hide-in-mobile"><button type="button" class="vp-color-mode-switch" id="color-mode-switch"><svg xmlns="http://www.w3.org/2000/svg" class="icon auto-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="auto icon" name="auto" style="display:block;"><path d="M512 992C246.92 992 32 777.08 32 512S246.92 32 512 32s480 214.92 480 480-214.92 480-480 480zm0-840c-198.78 0-360 161.22-360 360 0 198.84 161.22 360 360 360s360-161.16 360-360c0-198.78-161.22-360-360-360zm0 660V212c165.72 0 300 134.34 300 300 0 165.72-134.28 300-300 300z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon dark-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="dark icon" name="dark" style="display:none;"><path d="M524.8 938.667h-4.267a439.893 439.893 0 0 1-313.173-134.4 446.293 446.293 0 0 1-11.093-597.334A432.213 432.213 0 0 1 366.933 90.027a42.667 42.667 0 0 1 45.227 9.386 42.667 42.667 0 0 1 10.24 42.667 358.4 358.4 0 0 0 82.773 375.893 361.387 361.387 0 0 0 376.747 82.774 42.667 42.667 0 0 1 54.187 55.04 433.493 433.493 0 0 1-99.84 154.88 438.613 438.613 0 0 1-311.467 128z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon light-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="light icon" name="light" style="display:none;"><path d="M952 552h-80a40 40 0 0 1 0-80h80a40 40 0 0 1 0 80zM801.88 280.08a41 41 0 0 1-57.96-57.96l57.96-58a41.04 41.04 0 0 1 58 58l-58 57.96zM512 752a240 240 0 1 1 0-480 240 240 0 0 1 0 480zm0-560a40 40 0 0 1-40-40V72a40 40 0 0 1 80 0v80a40 40 0 0 1-40 40zm-289.88 88.08-58-57.96a41.04 41.04 0 0 1 58-58l57.96 58a41 41 0 0 1-57.96 57.96zM192 512a40 40 0 0 1-40 40H72a40 40 0 0 1 0-80h80a40 40 0 0 1 40 40zm30.12 231.92a41 41 0 0 1 57.96 57.96l-57.96 58a41.04 41.04 0 0 1-58-58l58-57.96zM512 832a40 40 0 0 1 40 40v80a40 40 0 0 1-80 0v-80a40 40 0 0 1 40-40zm289.88-88.08 58 57.96a41.04 41.04 0 0 1-58 58l-57.96-58a41 41 0 0 1 57.96-57.96z"></path></svg></button></div><form class="search-box" role="search"><input type="search" placeholder="搜索" autocomplete="off" spellcheck="false" value><!----></form><!--]--><button type="button" class="vp-toggle-navbar-button" aria-label="Toggle Navbar" aria-expanded="false" aria-controls="nav-screen"><span><span class="vp-top"></span><span class="vp-middle"></span><span class="vp-bottom"></span></span></button></div></header><!----><!--]--><!----><div class="toggle-sidebar-wrapper"><span class="arrow start"></span></div><!----><!--[--><main id="main-content" class="vp-page"><!--[--><!----><!----><nav class="vp-breadcrumb disable"></nav><div class="vp-page-title"><h1><!---->Stable Diffusion-01-入门概览</h1><div class="page-info"><span class="page-author-info" aria-label="作者🖊" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon author-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="author icon" name="author"><path d="M649.6 633.6c86.4-48 147.2-144 147.2-249.6 0-160-128-288-288-288s-288 128-288 288c0 108.8 57.6 201.6 147.2 249.6-121.6 48-214.4 153.6-240 288-3.2 9.6 0 19.2 6.4 25.6 3.2 9.6 12.8 12.8 22.4 12.8h704c9.6 0 19.2-3.2 25.6-12.8 6.4-6.4 9.6-16 6.4-25.6-25.6-134.4-121.6-240-243.2-288z"></path></svg><span><a class="page-author-item" href="https://houbb.github.io" target="_blank" rel="noopener noreferrer">老马啸西风</a></span><span property="author" content="老马啸西风"></span></span><!----><span class="page-date-info" aria-label="写作日期📅" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon calendar-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="calendar icon" name="calendar"><path d="M716.4 110.137c0-18.753-14.72-33.473-33.472-33.473-18.753 0-33.473 14.72-33.473 33.473v33.473h66.993v-33.473zm-334.87 0c0-18.753-14.72-33.473-33.473-33.473s-33.52 14.72-33.52 33.473v33.473h66.993v-33.473zm468.81 33.52H716.4v100.465c0 18.753-14.72 33.473-33.472 33.473a33.145 33.145 0 01-33.473-33.473V143.657H381.53v100.465c0 18.753-14.72 33.473-33.473 33.473a33.145 33.145 0 01-33.473-33.473V143.657H180.6A134.314 134.314 0 0046.66 277.595v535.756A134.314 134.314 0 00180.6 947.289h669.74a134.36 134.36 0 00133.94-133.938V277.595a134.314 134.314 0 00-133.94-133.938zm33.473 267.877H147.126a33.145 33.145 0 01-33.473-33.473c0-18.752 14.72-33.473 33.473-33.473h736.687c18.752 0 33.472 14.72 33.472 33.473a33.145 33.145 0 01-33.472 33.473z"></path></svg><span data-allow-mismatch="text">2025/12/27</span><meta property="datePublished" content="2025-12-27T05:11:09.000Z"></span><!----><span class="page-reading-time-info" aria-label="阅读时间⌛" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon timer-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="timer icon" name="timer"><path d="M799.387 122.15c4.402-2.978 7.38-7.897 7.38-13.463v-1.165c0-8.933-7.38-16.312-16.312-16.312H256.33c-8.933 0-16.311 7.38-16.311 16.312v1.165c0 5.825 2.977 10.874 7.637 13.592 4.143 194.44 97.22 354.963 220.201 392.763-122.204 37.542-214.893 196.511-220.2 389.397-4.661 5.049-7.638 11.651-7.638 19.03v5.825h566.49v-5.825c0-7.379-2.849-13.981-7.509-18.9-5.049-193.016-97.867-351.985-220.2-389.527 123.24-37.67 216.446-198.453 220.588-392.892zM531.16 450.445v352.632c117.674 1.553 211.787 40.778 211.787 88.676H304.097c0-48.286 95.149-87.382 213.728-88.676V450.445c-93.077-3.107-167.901-81.297-167.901-177.093 0-8.803 6.99-15.793 15.793-15.793 8.803 0 15.794 6.99 15.794 15.793 0 80.261 63.69 145.635 142.01 145.635s142.011-65.374 142.011-145.635c0-8.803 6.99-15.793 15.794-15.793s15.793 6.99 15.793 15.793c0 95.019-73.789 172.82-165.96 177.093z"></path></svg><span>大约 6 分钟</span><meta property="timeRequired" content="PT6M"></span><span class="page-category-info" aria-label="分类🌈" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon category-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="category icon" name="category"><path d="M148.41 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H148.41c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.311-40.31zM147.556 553.478H429.73c22.263 0 40.311 18.048 40.311 40.31v282.176c0 22.263-18.048 40.312-40.31 40.312H147.555c-22.263 0-40.311-18.049-40.311-40.312V593.79c0-22.263 18.048-40.311 40.31-40.311zM593.927 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H593.927c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.31-40.31zM730.22 920.502H623.926c-40.925 0-74.22-33.388-74.22-74.425V623.992c0-41.038 33.387-74.424 74.425-74.424h222.085c41.038 0 74.424 33.226 74.424 74.067v114.233c0 10.244-8.304 18.548-18.547 18.548s-18.548-8.304-18.548-18.548V623.635c0-20.388-16.746-36.974-37.33-36.974H624.13c-20.585 0-37.331 16.747-37.331 37.33v222.086c0 20.585 16.654 37.331 37.126 37.331H730.22c10.243 0 18.547 8.304 18.547 18.547 0 10.244-8.304 18.547-18.547 18.547z"></path></svg><!--[--><span class="page-category-item color5 clickable" role="navigation">AI</span><!--]--><meta property="articleSection" content="AI"></span><span class="page-tag-info" aria-label="标签🏷" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon tag-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="tag icon" name="tag"><path d="M939.902 458.563L910.17 144.567c-1.507-16.272-14.465-29.13-30.737-30.737L565.438 84.098h-.402c-3.215 0-5.726 1.005-7.634 2.913l-470.39 470.39a10.004 10.004 0 000 14.164l365.423 365.424c1.909 1.908 4.42 2.913 7.132 2.913s5.223-1.005 7.132-2.913l470.39-470.39c2.01-2.11 3.014-5.023 2.813-8.036zm-240.067-72.121c-35.458 0-64.286-28.828-64.286-64.286s28.828-64.285 64.286-64.285 64.286 28.828 64.286 64.285-28.829 64.286-64.286 64.286z"></path></svg><!--[--><span class="page-tag-item color2 clickable" role="navigation">ai</span><span class="page-tag-item color1 clickable" role="navigation">aigc</span><span class="page-tag-item color7 clickable" role="navigation">sh</span><!--]--><meta property="keywords" content="ai,aigc,sh"></span></div><hr></div><!----><div class="" vp-content><!----><div id="markdown-content"><h1 id="稳定扩散版本2" tabindex="-1"><a class="header-anchor" href="#稳定扩散版本2"><span>稳定扩散版本2</span></a></h1><p>此仓库包含从头开始训练的<a href="https://github.com/CompVis/stable-diffusion" target="_blank" rel="noopener noreferrer">Stable Diffusion</a>模型，并将持续更新新的检查点。以下是当前可用模型的概述。更多内容即将发布。</p><h2 id="最新动态" tabindex="-1"><a class="header-anchor" href="#最新动态"><span>最新动态</span></a></h2><p><strong>2023年3月24日</strong></p><p><em>Stable UnCLIP 2.1</em></p><ul><li><p>基于SD2.1-768，在768x768分辨率下的新的稳定扩散微调（<em>Stable unCLIP 2.1</em>，<a href="https://huggingface.co/stabilityai/" target="_blank" rel="noopener noreferrer">Hugging Face</a>）。此模型允许进行图像变体和混合操作，如<a href="https://arxiv.org/abs/2204.06125" target="_blank" rel="noopener noreferrer"><em>使用CLIP潜在空间的层次文本条件图像生成</em></a>中所述，并且由于其模块化，可以与其他模型（如<a href="https://github.com/kakaobrain/karlo" target="_blank" rel="noopener noreferrer">KARLO</a>）结合使用。有两种变体：<a href="https://huggingface.co/stabilityai/stable-diffusion-2-1-unclip/blob/main/sd21-unclip-l.ckpt" target="_blank" rel="noopener noreferrer">Stable unCLIP-L</a>和<a href="https://huggingface.co/stabilityai/stable-diffusion-2-1-unclip/blob/main/sd21-unclip-h.ckpt" target="_blank" rel="noopener noreferrer">Stable unCLIP-H</a>，分别以CLIP ViT-L和ViT-H图像嵌入为条件。</p></li><li><p>SD-unCLIP的公开演示已在<a href="https://clipdrop.co/stable-diffusion-reimagine" target="_blank" rel="noopener noreferrer">clipdrop.co/stable-diffusion-reimagine</a>提供。</p></li></ul><p><strong>2022年12月7日</strong></p><p><em>版本 2.1</em></p><ul><li>基于相同参数数量和架构的新稳定扩散模型(<em>Stable Diffusion 2.1-v</em>，<a href="https://huggingface.co/stabilityai/stable-diffusion-2-1" target="_blank" rel="noopener noreferrer">Hugging Face</a>)在768x768分辨率和(<em>Stable Diffusion 2.1-base</em>，<a href="https://huggingface.co/stabilityai/stable-diffusion-2-1-base" target="_blank" rel="noopener noreferrer">HuggingFace</a>)在512x512分辨率上，均基于2.0并在2.0的基础上微调，使用较少限制的<a href="https://laion.ai/blog/laion-5b/" target="_blank" rel="noopener noreferrer">LAION-5B</a>数据集进行NSFW过滤。默认情况下，如果未安装<code>xformers</code>，模型的注意操作将在全精度下评估。要启用fp16（这可能会导致v2.1模型的普通注意模块出现数值不稳定），请使用<code>ATTN_PRECISION=fp16 python &lt;thescript.py&gt;</code>运行脚本。</li></ul><p><strong>2022年11月24日</strong></p><p><em>版本 2.0</em></p><ul><li><p>新的稳定扩散模型(<em>Stable Diffusion 2.0-v</em>)在768x768分辨率下。U-Net参数数量与1.5相同，但使用<a href="https://github.com/mlfoundations/open_clip" target="_blank" rel="noopener noreferrer">OpenCLIP-ViT/H</a>作为文本编码器并从头开始训练。_SD 2.0-v_是所谓的<a href="https://arxiv.org/abs/2202.00512" target="_blank" rel="noopener noreferrer">v-prediction</a>模型。</p></li><li><p>上述模型从_SF 2.0-base_微调而来，后者作为标准噪声预测模型在512x512图像上训练，也提供。</p></li><li><p>增加了x4上采样潜在文本引导扩散模型</p></li><li><p>新的深度引导稳定扩散模型，从_SD 2.0-base_微调而来。模型基于通过<a href="https://github.com/isl-org/MiDaS" target="_blank" rel="noopener noreferrer">MiDaS</a>推断的单目深度估计，可以用于保持结构的img2img和形状条件合成。</p></li><li><p>文本引导修复模型，从_SD 2.0-base_微调而来。</p></li></ul><p>我们遵循<a href="https://github.com/CompVis/stable-diffusion" target="_blank" rel="noopener noreferrer">原始仓库</a>并提供基础推理脚本来从模型中采样。</p><hr><p><em>原始的Stable Diffusion模型是与<a href="https://arxiv.org/abs/2202.00512" target="_blank" rel="noopener noreferrer">CompVis</a>和<a href="https://runwayml.com/" target="_blank" rel="noopener noreferrer">RunwayML</a>合作创建的，基于以下工作：</em></p><p><a href="https://ommer-lab.com/research/latent-diffusion-models/" target="_blank" rel="noopener noreferrer"><strong>高分辨率图像合成与潜在扩散模型</strong></a><br><br><a href="https://github.com/rromb" target="_blank" rel="noopener noreferrer">Robin Rombach</a>*，<br><a href="https://github.com/ablattmann" target="_blank" rel="noopener noreferrer">Andreas Blattmann</a>*，<br><a href="https://github.com/qp-qp" target="_blank" rel="noopener noreferrer">Dominik Lorenz</a>\，<br><a href="https://github.com/pesser" target="_blank" rel="noopener noreferrer">Patrick Esser</a>，<br><a href="https://hci.iwr.uni-heidelberg.de/Staff/bommer" target="_blank" rel="noopener noreferrer">Björn Ommer</a><br><br><em><a href="https://openaccess.thecvf.com/content/CVPR2022/html/Rombach_High-Resolution_Image_Synthesis_With_Latent_Diffusion_Models_CVPR_2022_paper.html" target="_blank" rel="noopener noreferrer">CVPR &#39;22 口头报告</a> |<br><a href="https://github.com/CompVis/latent-diffusion" target="_blank" rel="noopener noreferrer">GitHub</a> | <a href="https://arxiv.org/abs/2112.10752" target="_blank" rel="noopener noreferrer">arXiv</a> | <a href="https://ommer-lab.com/research/latent-diffusion-models/" target="_blank" rel="noopener noreferrer">项目页面</a></em></p><p>Stable Diffusion是一个潜在的文本到图像扩散模型。</p><hr><h2 id="要求" tabindex="-1"><a class="header-anchor" href="#要求"><span>要求</span></a></h2><p>您可以通过运行以下命令来更新现有的<a href="https://github.com/CompVis/latent-diffusion" target="_blank" rel="noopener noreferrer">潜在扩散</a>环境：</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-"><span class="line"><span>conda install pytorch==1.12.1 torchvision==0.13.1 -c pytorch</span></span>
<span class="line"><span>pip install transformers==4.19.2 diffusers invisible-watermark</span></span>
<span class="line"><span>pip install -e .</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h4 id="xformers高效注意" tabindex="-1"><a class="header-anchor" href="#xformers高效注意"><span>xformers高效注意</span></a></h4><p>为了提高GPU上的效率和速度，<br> 我们强烈推荐安装<a href="https://github.com/facebookresearch/xformers" target="_blank" rel="noopener noreferrer">xformers</a>库。</p><p>已在带CUDA 11.4的A100上测试。<br> 安装需要较新的nvcc和gcc/g++版本，可以通过以下命令获得：</p><div class="language-commandline line-numbers-mode" data-highlighter="shiki" data-ext="commandline" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-commandline"><span class="line"><span>export CUDA_HOME=/usr/local/cuda-11.4</span></span>
<span class="line"><span>conda install -c nvidia/label/cuda-11.4.0 cuda-nvcc</span></span>
<span class="line"><span>conda install -c conda-forge gcc</span></span>
<span class="line"><span>conda install -c conda-forge gxx_linux-64==9.5.0</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>然后，运行以下命令（编译可能需要长达30分钟）。</p><div class="language-commandline line-numbers-mode" data-highlighter="shiki" data-ext="commandline" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-commandline"><span class="line"><span>cd ..</span></span>
<span class="line"><span>git clone https://github.com/facebookresearch/xformers.git</span></span>
<span class="line"><span>cd xformers</span></span>
<span class="line"><span>git submodule update --init --recursive</span></span>
<span class="line"><span>pip install -r requirements.txt</span></span>
<span class="line"><span>pip install -e .</span></span>
<span class="line"><span>cd ../stablediffusion</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>成功安装后，代码将在U-Net和自动编码器中的自注意和交叉注意层自动使用<a href="https://github.com/facebookresearch/xformers" target="_blank" rel="noopener noreferrer">内存高效注意</a>。</p><h2 id="一般免责声明" tabindex="-1"><a class="header-anchor" href="#一般免责声明"><span>一般免责声明</span></a></h2><p>Stable Diffusion模型是通用的文本到图像扩散模型，因此反映了其训练数据中的偏见和（误）概念。尽管已经努力减少明确的色情内容，但<strong>我们不推荐在没有额外安全机制和考虑的情况下将提供的权重用于服务或产品。权重是研究成果，应如此对待。</strong><br> 有关训练过程和数据的详细信息，以及模型的预期用途，请参见相应的<a href="https://huggingface.co/stabilityai/stable-diffusion-2" target="_blank" rel="noopener noreferrer">模型卡</a>。<br> 权重可通过<a href="https://huggingface.co/StabilityAI" target="_blank" rel="noopener noreferrer">Hugging Face上的StabilityAI组织</a>根据<a href="LICENSE-MODEL">CreativeML Open RAIL++-M License</a>获得。</p><h2 id="稳定扩散v2" tabindex="-1"><a class="header-anchor" href="#稳定扩散v2"><span>稳定扩散v2</span></a></h2><p>稳定扩散v2指的是使用下采样因子8自动编码器、865M UNet和OpenCLIP ViT-H/14文本编码器的特定模型配置。_SD 2-v_模型生成768x768像素的输出。</p><p>在不同的无分类器指导比例（1.5, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0）和50个DDIM采样步骤下的评估显示了检查点的相对改进：</p><h3 id="文本到图像" tabindex="-1"><a class="header-anchor" href="#文本到图像"><span>文本到图像</span></a></h3><h4 id="用法" tabindex="-1"><a class="header-anchor" href="#用法"><span>用法</span></a></h4><p>以下展示了如何使用<a href="https://github.com/huggingface/diffusers" target="_blank" rel="noopener noreferrer">diffusers</a>库从_SF 2.0-v_模型中采样：</p><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-python"><span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> torch</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">from</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> diffusers </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> StableDiffusionPipeline</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">model_id </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &quot;stabilityai/stable-diffusion-2&quot;</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">device </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &quot;cuda&quot;</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">pipe </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> StableDiffusionPipeline.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">from_pretrained</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(model_id, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">torch_dtype</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">torch.float16)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">pipe </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> pipe.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">to</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(device)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">prompt </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &quot;the dog is walking&quot;</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">image </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;"> pipe</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(prompt).images[</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">0</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">]</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">image.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">save</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;dog.png&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>或者，可以使用我们提供的直接脚本：</p><div class="language-commandline line-numbers-mode" data-highlighter="shiki" data-ext="commandline" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-commandline"><span class="line"><span>python scripts/txt2img.py --prompt &quot;a beautiful cat&quot; --H 768 --W 768 --seed 27 --n_samples 1 --n_iter 1</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><h3 id="深度条件稳定扩散" tabindex="-1"><a class="header-anchor" href="#深度条件稳定扩散"><span>深度条件稳定扩散</span></a></h3><p><strong>Stable Diffusion 2 depth-conditioned model</strong>对形状和深度信息敏感。其使用方式与文本到图像模型相似，不同的是需要额外的单目深度图。<br> 我们提供了用于生成这种深度图的代码片段，可以集成到推理管道中。</p><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-python"><span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> torch</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">from</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> diffusers </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> StableDiffusionDepth2ImgPipeline</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">model_id </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &quot;stabilityai/stable-diffusion-2-depth&quot;</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">device </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &quot;cuda&quot;</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">pipe </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> StableDiffusionDepth2ImgPipeline.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">from_pretrained</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(model_id, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">torch_dtype</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">torch.float16)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">pipe </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> pipe.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">to</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(device)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">prompt </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &quot;a luxurious mansion&quot;</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">depth_map </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;"> get_depth_map</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;input_image.jpg&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)  </span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 生成深度图的函数</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">image </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;"> pipe</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(prompt, depth_map).images[</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">0</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">]</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">image.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">save</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;mansion.png&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="图片修复" tabindex="-1"><a class="header-anchor" href="#图片修复"><span>图片修复</span></a></h3><p><em>Stable Diffusion 2.0 inpainting model</em> 是一个专门用于图片修复任务的模型。其使用方法与其他模式相似，但需要额外的掩码信息。<br> 我们提供了生成这种掩码的代码片段，可以集成到推理管道中。</p><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-python"><span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> torch</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">from</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> diffusers </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> StableDiffusionInpaintPipeline</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">model_id </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &quot;stabilityai/stable-diffusion-2-inpainting&quot;</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">device </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &quot;cuda&quot;</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">pipe </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> StableDiffusionInpaintPipeline.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">from_pretrained</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(model_id, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">torch_dtype</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">torch.float16)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">pipe </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> pipe.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">to</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(device)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">prompt </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &quot;a beautiful beach&quot;</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">init_image </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &quot;path_to_image.png&quot;</span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">  # 初始图像</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">mask_image </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &quot;path_to_mask.png&quot;</span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">   # 掩码图像</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">image </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;"> pipe</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(prompt, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">init_image</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">init_image, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">mask_image</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">mask_image).images[</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">0</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">]</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">image.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">save</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;beach.png&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="图像上采样" tabindex="-1"><a class="header-anchor" href="#图像上采样"><span>图像上采样</span></a></h3><h4 id="用法-1" tabindex="-1"><a class="header-anchor" href="#用法-1"><span>用法</span></a></h4><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-python"><span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> torch</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">from</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> diffusers </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> StableDiffusionUpscalePipeline</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">model_id </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &quot;stabilityai/stable-diffusion-x4-upscaler&quot;</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">device </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &quot;cuda&quot;</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">pipe </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> StableDiffusionUpscalePipeline.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">from_pretrained</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(model_id, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">torch_dtype</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">torch.float16)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">pipe </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> pipe.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">to</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(device)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">prompt </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &quot;an ultra high resolution photo of a cat&quot;</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">low_res_image </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;"> get_low_res_image</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;path_to_image.png&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)  </span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 生成低分辨率图像的函数</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">image </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;"> pipe</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(prompt, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">image</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">low_res_image).images[</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">0</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">]</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">image.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">save</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;high_res_cat.png&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="参考" tabindex="-1"><a class="header-anchor" href="#参考"><span>参考</span></a></h3><ul><li>相关论文：<a href="https://arxiv.org/abs/2112.10752" target="_blank" rel="noopener noreferrer">高分辨率图像合成与潜在扩散模型</a></li><li>代码库：<a href="https://github.com/CompVis/stable-diffusion" target="_blank" rel="noopener noreferrer">https://github.com/CompVis/stable-diffusion</a></li><li>模型权重：<a href="https://huggingface.co/StabilityAI" target="_blank" rel="noopener noreferrer">Hugging Face上的StabilityAI组织</a></li></ul><h3 id="致谢" tabindex="-1"><a class="header-anchor" href="#致谢"><span>致谢</span></a></h3><p>我们对以下人和组织表示感谢：</p><ul><li><a href="https://ommer-lab.com/" target="_blank" rel="noopener noreferrer">CompVis组</a></li><li><a href="https://runwayml.com/" target="_blank" rel="noopener noreferrer">RunwayML</a></li><li><a href="https://github.com/mlfoundations/open_clip" target="_blank" rel="noopener noreferrer">OpenCLIP</a></li></ul><p>更多信息和更新，请访问我们的<a href="https://github.com/stabilityai/stable-diffusion" target="_blank" rel="noopener noreferrer">GitHub页面</a>和<a href="https://huggingface.co/stabilityai/stable-diffusion-2" target="_blank" rel="noopener noreferrer">Hugging Face页面</a>。</p><h2 id="快速入门" tabindex="-1"><a class="header-anchor" href="#快速入门"><span>快速入门</span></a></h2><p>Stable Diffusion是一个强大的工具，可以用来生成高质量的图像。以下是一个快速入门指南：</p><ol><li>安装必要的依赖库。</li><li>下载并加载模型。</li><li>输入提示词生成图像。</li></ol><p>更多详细信息，请参考上述每个部分的使用说明。祝您使用愉快！</p><h1 id="参考资料" tabindex="-1"><a class="header-anchor" href="#参考资料"><span>参考资料</span></a></h1><p><a href="https://github.com/Stability-AI/stablediffusion/blob/main/README.md" target="_blank" rel="noopener noreferrer">https://github.com/Stability-AI/stablediffusion/blob/main/README.md</a></p></div><!----><!----><!----></div><footer class="vp-page-meta"><div class="vp-meta-item edit-link"><a class="auto-link external-link vp-meta-label" href="https://github.com/bbhou/lmxxf-notes/edit/main/src/posts/aigc/2024-02-20-aigc-stable-diffusion-02-doc.md" aria-label="Edit this page on GitHub" rel="noopener noreferrer" target="_blank"><!--[--><svg xmlns="http://www.w3.org/2000/svg" class="icon edit-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="edit icon" name="edit"><path d="M430.818 653.65a60.46 60.46 0 0 1-50.96-93.281l71.69-114.012 7.773-10.365L816.038 80.138A60.46 60.46 0 0 1 859.225 62a60.46 60.46 0 0 1 43.186 18.138l43.186 43.186a60.46 60.46 0 0 1 0 86.373L588.879 565.55l-8.637 8.637-117.466 68.234a60.46 60.46 0 0 1-31.958 11.229z"></path><path d="M728.802 962H252.891A190.883 190.883 0 0 1 62.008 771.98V296.934a190.883 190.883 0 0 1 190.883-192.61h267.754a60.46 60.46 0 0 1 0 120.92H252.891a69.962 69.962 0 0 0-69.098 69.099V771.98a69.962 69.962 0 0 0 69.098 69.098h475.911A69.962 69.962 0 0 0 797.9 771.98V503.363a60.46 60.46 0 1 1 120.922 0V771.98A190.883 190.883 0 0 1 728.802 962z"></path></svg><!--]-->Edit this page on GitHub<!----></a></div><div class="vp-meta-item git-info"><div class="update-time"><span class="vp-meta-label">最近更新</span><time class="vp-meta-info" datetime="2025-12-27T05:14:38.000Z" data-allow-mismatch>2025/12/27 05:14</time></div><div class="contributors"><span class="vp-meta-label">贡献者: </span><!--[--><!--[--><span class="vp-meta-info" title="email: 1557740299@qq.com">bbhou</span><!--]--><!--]--></div></div></footer><!----><!----><!----><!--]--></main><!--]--><footer class="vp-footer-wrapper" vp-footer><div class="vp-footer">我是老马，期待与你的下次重逢</div><div class="vp-copyright">Copyright © 2025 老马啸西风 </div></footer></div><!--]--><!--[--><!----><!--[--><!--]--><!--]--><!--]--></div>
    <script type="module" src="/blog-thinking/assets/app-Dvf0wTTF.js" defer></script>
  </body>
</html>
