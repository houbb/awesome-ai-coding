<!doctype html>
<html lang="zh-CN" data-theme="light">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-rc.24" />
    <meta name="theme" content="VuePress Theme Hope 2.0.0-rc.94" />
    <style>
      :root {
        --vp-c-bg: #fff;
      }

      [data-theme="dark"] {
        --vp-c-bg: #1b1b1f;
      }

      html,
      body {
        background: var(--vp-c-bg);
      }
    </style>
    <script>
      const userMode = localStorage.getItem("vuepress-theme-hope-scheme");
      const systemDarkMode =
        window.matchMedia &&
        window.matchMedia("(prefers-color-scheme: dark)").matches;

      if (userMode === "dark" || (userMode !== "light" && systemDarkMode)) {
        document.documentElement.setAttribute("data-theme", "dark");
      }
    </script>
    <script type="application/ld+json">{"@context":"https://schema.org","@type":"Article","headline":"第4章　线性代数与矩阵运算","image":[""],"dateModified":"2025-12-27T05:14:38.000Z","author":[{"@type":"Person","name":"老马啸西风","url":"https://houbb.github.io"}]}</script><meta property="og:url" content="https://houbb.github.io/blog-thinking/posts/ml/2025-11-03-04-ml-book-matrix.html"><meta property="og:site_name" content="老马啸西风"><meta property="og:title" content="第4章　线性代数与矩阵运算"><meta property="og:description" content="🧭 标题备选 别被矩阵吓到：机器学习的底层，其实全是线性代数 线性代数是机器学习的语言：从向量到PCA，一次讲透 机器学习的灵魂不是AI，而是矩阵 当你看懂向量、矩阵和PCA，机器学习才真正入门 数学不抽象：一文讲透机器学习背后的线性世界 🖼 封面文案 所有的智能背后，都是线性代数在默默支撑。 理解矩阵，你就理解了机器学习的底层逻辑。 （配图建议：..."><meta property="og:type" content="article"><meta property="og:locale" content="zh-CN"><meta property="og:updated_time" content="2025-12-27T05:14:38.000Z"><meta property="article:tag" content="learn-note"><meta property="article:tag" content="ai"><meta property="article:modified_time" content="2025-12-27T05:14:38.000Z"><title>第4章　线性代数与矩阵运算 | 老马啸西风</title><meta name="description" content="🧭 标题备选 别被矩阵吓到：机器学习的底层，其实全是线性代数 线性代数是机器学习的语言：从向量到PCA，一次讲透 机器学习的灵魂不是AI，而是矩阵 当你看懂向量、矩阵和PCA，机器学习才真正入门 数学不抽象：一文讲透机器学习背后的线性世界 🖼 封面文案 所有的智能背后，都是线性代数在默默支撑。 理解矩阵，你就理解了机器学习的底层逻辑。 （配图建议：...">
    <link rel="preload" href="/blog-thinking/assets/style-Bb931w8d.css" as="style"><link rel="stylesheet" href="/blog-thinking/assets/style-Bb931w8d.css">
    <link rel="modulepreload" href="/blog-thinking/assets/app-Dvf0wTTF.js"><link rel="modulepreload" href="/blog-thinking/assets/2025-11-03-04-ml-book-matrix.html-BjRr9uL1.js"><link rel="modulepreload" href="/blog-thinking/assets/plugin-vue_export-helper-DlAUqK2U.js">
    <link rel="prefetch" href="/blog-thinking/assets/index.html-DJ916H6l.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/intro.html-CotTyzew.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-03-07-ai-learn-what-is-manus.html-Bbr7cHOx.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-04-03-ai-brower-agent-01-agentGPT.html-DwLiCRpL.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-04-03-ai-brower-agent-02-browser-use.html-BkTHNJ5g.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-20-ai-sdd-09-skills-zh.html-B11OWNR6.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-20-ai-sdd-10-skills-docs-gen.html-DxF_6tZB.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-20-ai-sdd-21-agent-skills-01-what-is.html-BHpJ9tyM.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-20-ai-sdd-21-agent-skills-02-specfication.html-Cr9d79eY.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-20-ai-sdd-21-agent-skills-03-integrate.html-DSOGLC9t.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2023-03-24-ai-code.html-GOIY7SzP.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2023-03-24-ai-text-to-image-web.html-C9yfiaP6.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2023-03-24-ai-text-to-image.html-91NmUEps.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2024-02-20-ai-01-autogpt-01-overview.html-CKeNjuQh.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2024-02-20-ai-02-openui-01-overview.html-CYNMoPZ0.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2024-02-20-ai-03-awesome-prompts.html-ByxgAzaX.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2024-02-20-ai-03-prompt-guide.html-BKgppnFn.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2024-02-20-ai-04-chatGPT-deploy.html-bzJDgNFr.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2024-02-20-ai-05-gpt4free.html-BypxYV82.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2024-02-20-ai-06-chatgpt-academic.html-B0-r-2On.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2024-02-20-ai-07-aigc-for-beginners.html-DG4CCk1I.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2024-02-20-ai-08-chatGPT-next-web.html-CS8B3aJc.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2024-02-20-ai-09-openai-cookbook.html-DXj4A5d4.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2024-02-20-ai-10-openai-assistant.html-X5lYwyEZ.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2024-02-20-ai-11-quivr.html-DFVqOQU6.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2024-02-20-ai-12-lobe-chat.html-BRlRJwyK.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2024-02-20-ai-13-langchain-chat.html-CcRtp-17.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2024-02-20-ai-14-wechatMSG.html-3LKnEeWH.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2024-02-20-ai-15-autogen.html-C9-EgDu5.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2024-02-20-ai-16-code-gen-devika-intro.html-CUJJobTQ.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2024-02-20-ai-17-chatgpt-on-wechat.html-WruO0aJH.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2024-02-20-ai-nlp-segment-01-overview.html-CvKmKE1Z.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2024-02-20-ai-overview.html-Dg_6Gtoq.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2024-02-20-ai-video-01-overview copy.html-oonELA_L.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2024-02-20-ai-video-01-overview.html-B_4Odx5Y.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2024-02-20-aigc-overview.html-4fLlgw0s.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2024-02-20-aigc-stable-diffusion-01-overview.html-GYPT1tzI.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2024-02-20-aigc-stable-diffusion-02-doc.html-DQLV39gR.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2024-02-20-openai-chatgpt-paper-01-intro.html-CJJkdcd9.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2024-02-20-openai-chatgpt-paper-02-tec.html-BsA1Z-c_.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2024-02-20-openai-chatgpt-paper-03-dall-e-3-simple.html-BspJRx9N.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2024-02-20-openai-chatgpt-paper-03-dall-e-3.html-oEF4t9aV.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2024-02-20-openai-chatgpt-paper-04-sora-tech.html-Cu3OB7d2.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2024-03-20-xai-org-gork-00-attention-is-all-you-need.html-BvnOs5j5.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2024-03-20-xai-org-gork-00-transformer-intro.html-BH1q0IzY.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2024-03-20-xai-org-gork-01-sourcecode-1.html-Dhk6YTix.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2024-03-20-xai-org-gork-01-sourcecode-2.html-UKOBBeSH.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2024-03-20-xai-org-gork-01-sourcecode-3.html-DmAKCdoF.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2024-03-20-xai-org-gork-01-sourcecode-4.html-va-G_YJT.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-12-27-ai-dev-roads.html-C8KGYUz6.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2022-12-06-ai-chatGPT.html-D5bs8nPN.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2022-12-06-ai-dell2-intro-01-overview.html-DeyQjEyh.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2024-02-20-aigc-overview.html-DOQ8ZBAj.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2024-02-20-aigc-stable-diffusion-01-overview.html-BLdoa86A.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2024-02-20-aigc-stable-diffusion-02-doc.html-DdSzvRaR.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-03-07-ai-ide-00-overview.html-CBtD4kvJ.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-03-07-ai-ide-01-trae-intro.html-CeMxDffk.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-20-ai-sdd-11-gemini-cli-use-inaction.html-DweDePLd.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-20-ai-sdd-12-gemini-cli-use-intro.html-BXs_VMOj.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-20-ai-sdd-13-gemini-cli-use-for-old-project-project-profile.html-DeqF0EAq.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-20-ai-sdd-13-gemini-cli-use-for-old-project.html-Dt3kYOaP.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-20-ai-sdd-14-gemini-cli-use-for-new-project-springboot.html-S7yWU7ba.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-20-ai-sdd-15-gemini-cli-use-for-new-project-vue3.html-K7FVT-8R.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-12-15-google-cli-text-to-image.html-OFmM1Zrj.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2023-04-14-ai-learn-01-overview.html-BVV_I_G_.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2023-04-14-ai-learn-02-basic.html-D3yGk_B1.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2023-04-14-ai-learn-03-math.html-CjfOGbBO.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2023-04-14-ai-learn-04-python-ai.html-DVl9uUol.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2023-04-14-ai-learn-05-deeplearing.html-CJ4757eX.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2023-04-14-ai-weka-01-overview.html-5qL7nXsk.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2023-04-14-ai-weka-02-java-hello-world.html-BOyh7uLR.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2023-04-14-ai-weka-03-java-letter-and-digits.html-DgbySiDH.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2023-04-14-ai-weka-04-mnist.html-CCB08bJ9.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2023-05-09-ai-jpmml-01-overview.html-C1gKWQGy.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-03-dive-into-llms-00-overview.html-DaNNfR-a.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-03-dive-into-llms-01-basic-python-intro.html-CNX6ajyV.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-03-dive-into-llms-02-basic-deep-learning-intro.html-B1ixiV1h.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-03-dive-into-llms-03-basic-nlp-big-model.html-C0i_AAdS.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-03-dive-into-llms-04-transformers-01-intro.html-Dj0ySpv3.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-03-dive-into-llms-05-pytorch-01-intro.html-CQ2wb0rA.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-03-dive-into-llms-06-transformers-02-quick-start-requirements.html-K7QqUoWC.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-03-dive-into-llms-06-transformers-03-pipeline.html-FiaQoxNA.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-03-dive-into-llms-06-transformers-04-pipeline-intro.html-D1UaxFss.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-03-dive-into-llms-100-ml-history.html-Qx0efQJ0.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-03-dive-into-llms-100-ml-intro.html-yqizlYG5.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-03-dive-into-llms-101-ml-vs-dl.html-CBGUnUWO.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-03-dive-into-llms-102-ml-nlp-usage.html-DP1BXQAx.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-03-dive-into-llms-103-ml-other-usage.html-Kf_SJY90.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-03-dive-into-llms-104-ml-sentiment-analysis.html-Bnv5geMX.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-03-dive-into-llms-11-chap01.html-BNAIxXLc.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-03-dive-into-llms-30-dl-intro.html-B4W1lGQE.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-03-dive-into-llms-31-dl-how-to-learn.html-CWDIIFdx.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-03-dive-into-llms-32-dl-write-minist.html-DF0Iasw0.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-03-dive-into-llms-33-dl-write-mnist-sequence.html-BsP6cUmO.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-03-dive-into-llms-34-dl-CNN-intro.html-tn630XsE.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-02-03-deepseek-r1-ai-model-compare.html-D37jlTC2.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-02-03-deepseek-r1-how-to-earn-money-by-ai.html-BXhahlhg.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-02-03-deepseek-r1-paper-intro.html-CLPkdbgo.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-04-15-ai-mcp-01-intro.html-pLcseMfT.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-04-15-ai-mcp-02-awesome-servers.html-u3XzGTgI.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-04-15-ai-mcp-03-open-webui.html-BnXxHhN-.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-04-15-ai-mcp-04-n8n.html-DjZHelJL.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-04-15-ai-mcp-05-anything-llm.html-C5kVfPer.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-04-15-ai-mcp-06-maxkb.html-1NqTnc0v.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-04-15-ai-mcp-07-dify-intro.html-CKtg1-VD.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-04-15-ai-mcp-08-awesome-dify-vs.html-uHmFq16X.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-04-15-ai-mcp-08-awesome-dify-workflow.html-5gUwEIRG.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-04-15-ai-mcp-09-difyaia.html-B7nB1HXF.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-04-15-ai-mcp-10-activepieces.html-BHEiQIXd.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-04-15-ai-mcp-11-playwright-mcp.html-CZNJIaQX.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-04-15-ai-mcp-12-aws-mcp.html-C7CrfBEf.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-04-15-ai-mcp-13-github-mcp.html-5HTEO9Us.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-04-15-ai-mcp-14-a2a-intro.html-MIynuyzf.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-04-15-ai-mcp-15-flow-control-opensource.html-eid9JrjD.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-09-16-mcp-01-intro-and-hello-world.html-BMSm2xzD.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-03-00-ml-book-index.html-D5d-x0zU.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-03-01-ml-book-history.html-CYNVwPvf.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-03-02-ml-book-core-thought.html-IV2acD0K.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-03-03-ml-book-rate-and-stat.html-B0MyA18W.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-03-05-ml-book-loss-and-val.html-D-_xQRLL.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-03-06-ml-book-line-model.html-DlxZ-fKd.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-03-07-ml-book-knn.html-l7TR5fcP.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-03-08-ml-book-decision-tree.html-TbnXm_93.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-03-09-ml-book-rate-model-stat-learn.html-D_PUoz0S.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-03-10-ml-book-k-means.html-mjCiE4h2.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-03-11-ml-book-feature.html-iJt-q1Jq.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-03-12-ml-book-model-eval-and-opt.html-B28bMmLk.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-03-13-ml-book-nlp-inaction.html-CtVYS9zH.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-03-14-ml-book-cv.html-BCiMTFYD.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-03-15-ml-book-time-series.html-Bz6s6fL4.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-03-16-ml-book-deeplearning.html-DEIapI9t.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-03-17-ml-book-CNN.html-D0ysH8y6.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-03-18-ml-book-LLM.html-xWYrPU7Z.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-03-19-ml-book-believe.html-ujX1yUCh.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-03-20-ml-book-think-model.html-CCXDoL6Q.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-03-21-ml-book-future.html-DVtAslDB.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-20-ai-sdd-01-overview.html-DA8W17vT.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-20-ai-sdd-02-sepc-kit-intro.html-nqk8gPlD.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-20-ai-sdd-03-opensepc-intro.html-Bhpsoxls.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-20-ai-sdd-04-kiro-intro.html-CU7AswuS.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-20-ai-sdd-05-sepc-kit-inaction.html-DtyMHS_d.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-20-ai-sdd-06-openspec-inaction.html-DcsmTs7E.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-20-ai-sdd-07-skills.html-MgOO_axH.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-20-ai-sdd-08-ali-taobao-best-practise.html-BFp-q5mv.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-20-ai-sdd-16-what-about-rules-design.html-WhjKJDx1.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-20-ai-sdd-17-ai-corp-paper.html-BmwXEMWh.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-20-ai-sdd-18-gemini-template.html-h-mWWoIm.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-20-ai-sdd-19-project-profile-template.html-BAMLWiZ-.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/2025-11-20-ai-sdd-20-design-template.html-BhM7AvF5.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/404.html-BK5oZxyf.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/index.html-C3-Oa4Q4.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/index.html-BBnO1GBe.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/index.html-B50XtgFq.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/index.html-bNsWizzc.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/index.html-BnvxU8H1.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/index.html-oHq67JwQ.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/index.html-mN0MmMhD.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/index.html-CXmVDF9j.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/index.html-CVASEOro.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/index.html-D2Vd0WXq.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/index.html-DDFTKWjR.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/index.html-mHA3wJmq.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/index.html-DdOuoQed.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/index.html-B3ktFRBf.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/index.html-CjEeKeLh.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/index.html-CfP7kdNG.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/index.html-DL_4KlzA.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/index.html-JxsLJ1hv.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/index.html-DhPaGt8D.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/index.html-B1sV4R5d.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/index.html-Cc4Oe9I_.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/index.html-B-_l2aEg.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/index.html-BwfKpv4b.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/index.html-JQ1sR7hl.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/index.html-em3-JA64.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/index.html-vwYW7S8m.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/index.html-BgaGPTxW.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/index.html-BMSPkyBH.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/index.html-CopRigQP.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/index.html-SnGb-ISj.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/index.html-TyR8su45.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/index.html-rP1xWCr3.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/index.html-C_jXk-p3.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/index.html-DL51r8Uu.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/index.html-J9ulgMIp.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/index.html-DJBwNVZ9.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/index.html-D3Agmo5I.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/photoswipe.esm-CKV1Bsxh.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/auto-BUYG9-ss.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/index-C1rb1p6e.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/flowchart-G1WAoCnn.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/index-DtWMYcbt.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/index-DMDrkyre.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/index-BPAdBlYL.js" as="script"><link rel="prefetch" href="/blog-thinking/assets/mermaid.esm.min-DbhK467j.js" as="script">
  </head>
  <body>
    <div id="app"><!--[--><!--[--><!--[--><span tabindex="-1"></span><a href="#main-content" class="vp-skip-link sr-only">跳至主要內容</a><!--]--><div class="theme-container no-sidebar external-link-icon has-toc" vp-container><!--[--><header id="navbar" class="vp-navbar" vp-navbar><div class="vp-navbar-start"><button type="button" class="vp-toggle-sidebar-button" title="Toggle Sidebar"><span class="icon"></span></button><!--[--><a class="route-link vp-brand" href="/blog-thinking/" aria-label="带我回家"><img class="vp-nav-logo" src="/blog-thinking/assets/images/lmxxf.png" alt><!----><span class="vp-site-name hide-in-pad">老马啸西风</span></a><!--]--></div><div class="vp-navbar-center"><!--[--><nav class="vp-nav-links"><div class="vp-nav-item hide-in-mobile"><div class="vp-dropdown-wrapper"><button type="button" class="vp-dropdown-title" aria-label="个人成长"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:user-graduate" sizing="height" height="1em"></iconify-icon>个人成长<!--]--><span class="arrow"></span><ul class="vp-dropdown"><li class="vp-dropdown-item"><a class="route-link auto-link" href="/blog-thinking/category/notes/" aria-label="老马随笔"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:pen-nib" sizing="both" width="1em" height="1em"></iconify-icon><!--]-->老马随笔<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/blog-thinking/category/company/" aria-label="职业发展"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:user-tie" sizing="both" width="1em" height="1em"></iconify-icon><!--]-->职业发展<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/blog-thinking/category/methodsandmodel/" aria-label="方法模型"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:diagram-project" sizing="both" width="1em" height="1em"></iconify-icon><!--]-->方法模型<!----></a></li></ul></button></div></div><div class="vp-nav-item hide-in-mobile"><div class="vp-dropdown-wrapper"><button type="button" class="vp-dropdown-title" aria-label="财务自由"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:sack-dollar" sizing="height" height="1em"></iconify-icon>财务自由<!--]--><span class="arrow"></span><ul class="vp-dropdown"><li class="vp-dropdown-item"><a class="route-link auto-link" href="/blog-thinking/category/money/" aria-label="财富自由"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:sack-dollar" sizing="both" width="1em" height="1em"></iconify-icon><!--]-->财富自由<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/blog-thinking/category/business/" aria-label="商业思考"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:briefcase" sizing="both" width="1em" height="1em"></iconify-icon><!--]-->商业思考<!----></a></li></ul></button></div></div><div class="vp-nav-item hide-in-mobile"><div class="vp-dropdown-wrapper"><button type="button" class="vp-dropdown-title" aria-label="推广营销"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:bullhorn" sizing="height" height="1em"></iconify-icon>推广营销<!--]--><span class="arrow"></span><ul class="vp-dropdown"><li class="vp-dropdown-item"><a class="route-link auto-link" href="/blog-thinking/category/marketing/" aria-label="市场营销"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:bullhorn" sizing="both" width="1em" height="1em"></iconify-icon><!--]-->市场营销<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/blog-thinking/category/fans/" aria-label="媒体运营"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:photo-film" sizing="both" width="1em" height="1em"></iconify-icon><!--]-->媒体运营<!----></a></li></ul></button></div></div><div class="vp-nav-item hide-in-mobile"><div class="vp-dropdown-wrapper"><button type="button" class="vp-dropdown-title" aria-label="生活兴趣"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:heart" sizing="height" height="1em"></iconify-icon>生活兴趣<!--]--><span class="arrow"></span><ul class="vp-dropdown"><li class="vp-dropdown-item"><a class="route-link auto-link" href="/blog-thinking/category/travel/" aria-label="环游世界"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:globe" sizing="both" width="1em" height="1em"></iconify-icon><!--]-->环游世界<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/blog-thinking/category/moive/" aria-label="电影影视"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:film" sizing="both" width="1em" height="1em"></iconify-icon><!--]-->电影影视<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/blog-thinking/category/reading/" aria-label="读书笔记"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:book-open" sizing="both" width="1em" height="1em"></iconify-icon><!--]-->读书笔记<!----></a></li></ul></button></div></div><div class="vp-nav-item hide-in-mobile"><a class="route-link route-link-active auto-link" href="/blog-thinking/posts/" aria-label="全部文章"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:pen-to-square" sizing="height" height="1em"></iconify-icon><!--]-->全部文章<!----></a></div></nav><!--]--></div><div class="vp-navbar-end"><!--[--><!----><div class="vp-nav-item vp-action"><a class="vp-action-link" href="https://github.com/bbhou/lmxxf-notes" target="_blank" rel="noopener noreferrer" aria-label="GitHub"><svg xmlns="http://www.w3.org/2000/svg" class="icon github-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="github icon" name="github" style="width:1.25rem;height:1.25rem;vertical-align:middle;"><path d="M511.957 21.333C241.024 21.333 21.333 240.981 21.333 512c0 216.832 140.544 400.725 335.574 465.664 24.49 4.395 32.256-10.07 32.256-23.083 0-11.69.256-44.245 0-85.205-136.448 29.61-164.736-64.64-164.736-64.64-22.315-56.704-54.4-71.765-54.4-71.765-44.587-30.464 3.285-29.824 3.285-29.824 49.195 3.413 75.179 50.517 75.179 50.517 43.776 75.008 114.816 53.333 142.762 40.79 4.523-31.66 17.152-53.377 31.19-65.537-108.971-12.458-223.488-54.485-223.488-242.602 0-53.547 19.114-97.323 50.517-131.67-5.035-12.33-21.93-62.293 4.779-129.834 0 0 41.258-13.184 134.912 50.346a469.803 469.803 0 0 1 122.88-16.554c41.642.213 83.626 5.632 122.88 16.554 93.653-63.488 134.784-50.346 134.784-50.346 26.752 67.541 9.898 117.504 4.864 129.834 31.402 34.347 50.474 78.123 50.474 131.67 0 188.586-114.73 230.016-224.042 242.09 17.578 15.232 33.578 44.672 33.578 90.454v135.85c0 13.142 7.936 27.606 32.854 22.87C862.25 912.597 1002.667 728.747 1002.667 512c0-271.019-219.648-490.667-490.71-490.667z"></path></svg></a></div><div class="vp-nav-item hide-in-mobile"><button type="button" class="vp-color-mode-switch" id="color-mode-switch"><svg xmlns="http://www.w3.org/2000/svg" class="icon auto-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="auto icon" name="auto" style="display:block;"><path d="M512 992C246.92 992 32 777.08 32 512S246.92 32 512 32s480 214.92 480 480-214.92 480-480 480zm0-840c-198.78 0-360 161.22-360 360 0 198.84 161.22 360 360 360s360-161.16 360-360c0-198.78-161.22-360-360-360zm0 660V212c165.72 0 300 134.34 300 300 0 165.72-134.28 300-300 300z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon dark-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="dark icon" name="dark" style="display:none;"><path d="M524.8 938.667h-4.267a439.893 439.893 0 0 1-313.173-134.4 446.293 446.293 0 0 1-11.093-597.334A432.213 432.213 0 0 1 366.933 90.027a42.667 42.667 0 0 1 45.227 9.386 42.667 42.667 0 0 1 10.24 42.667 358.4 358.4 0 0 0 82.773 375.893 361.387 361.387 0 0 0 376.747 82.774 42.667 42.667 0 0 1 54.187 55.04 433.493 433.493 0 0 1-99.84 154.88 438.613 438.613 0 0 1-311.467 128z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon light-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="light icon" name="light" style="display:none;"><path d="M952 552h-80a40 40 0 0 1 0-80h80a40 40 0 0 1 0 80zM801.88 280.08a41 41 0 0 1-57.96-57.96l57.96-58a41.04 41.04 0 0 1 58 58l-58 57.96zM512 752a240 240 0 1 1 0-480 240 240 0 0 1 0 480zm0-560a40 40 0 0 1-40-40V72a40 40 0 0 1 80 0v80a40 40 0 0 1-40 40zm-289.88 88.08-58-57.96a41.04 41.04 0 0 1 58-58l57.96 58a41 41 0 0 1-57.96 57.96zM192 512a40 40 0 0 1-40 40H72a40 40 0 0 1 0-80h80a40 40 0 0 1 40 40zm30.12 231.92a41 41 0 0 1 57.96 57.96l-57.96 58a41.04 41.04 0 0 1-58-58l58-57.96zM512 832a40 40 0 0 1 40 40v80a40 40 0 0 1-80 0v-80a40 40 0 0 1 40-40zm289.88-88.08 58 57.96a41.04 41.04 0 0 1-58 58l-57.96-58a41 41 0 0 1 57.96-57.96z"></path></svg></button></div><form class="search-box" role="search"><input type="search" placeholder="搜索" autocomplete="off" spellcheck="false" value><!----></form><!--]--><button type="button" class="vp-toggle-navbar-button" aria-label="Toggle Navbar" aria-expanded="false" aria-controls="nav-screen"><span><span class="vp-top"></span><span class="vp-middle"></span><span class="vp-bottom"></span></span></button></div></header><!----><!--]--><!----><div class="toggle-sidebar-wrapper"><span class="arrow start"></span></div><!----><!--[--><main id="main-content" class="vp-page"><!--[--><!----><!----><nav class="vp-breadcrumb disable"></nav><div class="vp-page-title"><h1><!---->第4章　线性代数与矩阵运算</h1><div class="page-info"><span class="page-author-info" aria-label="作者🖊" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon author-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="author icon" name="author"><path d="M649.6 633.6c86.4-48 147.2-144 147.2-249.6 0-160-128-288-288-288s-288 128-288 288c0 108.8 57.6 201.6 147.2 249.6-121.6 48-214.4 153.6-240 288-3.2 9.6 0 19.2 6.4 25.6 3.2 9.6 12.8 12.8 22.4 12.8h704c9.6 0 19.2-3.2 25.6-12.8 6.4-6.4 9.6-16 6.4-25.6-25.6-134.4-121.6-240-243.2-288z"></path></svg><span><a class="page-author-item" href="https://houbb.github.io" target="_blank" rel="noopener noreferrer">老马啸西风</a></span><span property="author" content="老马啸西风"></span></span><!----><span class="page-date-info" aria-label="写作日期📅" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon calendar-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="calendar icon" name="calendar"><path d="M716.4 110.137c0-18.753-14.72-33.473-33.472-33.473-18.753 0-33.473 14.72-33.473 33.473v33.473h66.993v-33.473zm-334.87 0c0-18.753-14.72-33.473-33.473-33.473s-33.52 14.72-33.52 33.473v33.473h66.993v-33.473zm468.81 33.52H716.4v100.465c0 18.753-14.72 33.473-33.472 33.473a33.145 33.145 0 01-33.473-33.473V143.657H381.53v100.465c0 18.753-14.72 33.473-33.473 33.473a33.145 33.145 0 01-33.473-33.473V143.657H180.6A134.314 134.314 0 0046.66 277.595v535.756A134.314 134.314 0 00180.6 947.289h669.74a134.36 134.36 0 00133.94-133.938V277.595a134.314 134.314 0 00-133.94-133.938zm33.473 267.877H147.126a33.145 33.145 0 01-33.473-33.473c0-18.752 14.72-33.473 33.473-33.473h736.687c18.752 0 33.472 14.72 33.472 33.473a33.145 33.145 0 01-33.472 33.473z"></path></svg><span data-allow-mismatch="text">2025/12/27</span><meta property="datePublished" content="2025-12-27T05:11:09.000Z"></span><!----><span class="page-reading-time-info" aria-label="阅读时间⌛" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon timer-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="timer icon" name="timer"><path d="M799.387 122.15c4.402-2.978 7.38-7.897 7.38-13.463v-1.165c0-8.933-7.38-16.312-16.312-16.312H256.33c-8.933 0-16.311 7.38-16.311 16.312v1.165c0 5.825 2.977 10.874 7.637 13.592 4.143 194.44 97.22 354.963 220.201 392.763-122.204 37.542-214.893 196.511-220.2 389.397-4.661 5.049-7.638 11.651-7.638 19.03v5.825h566.49v-5.825c0-7.379-2.849-13.981-7.509-18.9-5.049-193.016-97.867-351.985-220.2-389.527 123.24-37.67 216.446-198.453 220.588-392.892zM531.16 450.445v352.632c117.674 1.553 211.787 40.778 211.787 88.676H304.097c0-48.286 95.149-87.382 213.728-88.676V450.445c-93.077-3.107-167.901-81.297-167.901-177.093 0-8.803 6.99-15.793 15.793-15.793 8.803 0 15.794 6.99 15.794 15.793 0 80.261 63.69 145.635 142.01 145.635s142.011-65.374 142.011-145.635c0-8.803 6.99-15.793 15.794-15.793s15.793 6.99 15.793 15.793c0 95.019-73.789 172.82-165.96 177.093z"></path></svg><span>大约 10 分钟</span><meta property="timeRequired" content="PT10M"></span><span class="page-category-info" aria-label="分类🌈" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon category-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="category icon" name="category"><path d="M148.41 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H148.41c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.311-40.31zM147.556 553.478H429.73c22.263 0 40.311 18.048 40.311 40.31v282.176c0 22.263-18.048 40.312-40.31 40.312H147.555c-22.263 0-40.311-18.049-40.311-40.312V593.79c0-22.263 18.048-40.311 40.31-40.311zM593.927 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H593.927c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.31-40.31zM730.22 920.502H623.926c-40.925 0-74.22-33.388-74.22-74.425V623.992c0-41.038 33.387-74.424 74.425-74.424h222.085c41.038 0 74.424 33.226 74.424 74.067v114.233c0 10.244-8.304 18.548-18.547 18.548s-18.548-8.304-18.548-18.548V623.635c0-20.388-16.746-36.974-37.33-36.974H624.13c-20.585 0-37.331 16.747-37.331 37.33v222.086c0 20.585 16.654 37.331 37.126 37.331H730.22c10.243 0 18.547 8.304 18.547 18.547 0 10.244-8.304 18.547-18.547 18.547z"></path></svg><!--[--><span class="page-category-item color5 clickable" role="navigation">AI</span><!--]--><meta property="articleSection" content="AI"></span><span class="page-tag-info" aria-label="标签🏷" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon tag-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="tag icon" name="tag"><path d="M939.902 458.563L910.17 144.567c-1.507-16.272-14.465-29.13-30.737-30.737L565.438 84.098h-.402c-3.215 0-5.726 1.005-7.634 2.913l-470.39 470.39a10.004 10.004 0 000 14.164l365.423 365.424c1.909 1.908 4.42 2.913 7.132 2.913s5.223-1.005 7.132-2.913l470.39-470.39c2.01-2.11 3.014-5.023 2.813-8.036zm-240.067-72.121c-35.458 0-64.286-28.828-64.286-64.286s28.828-64.285 64.286-64.285 64.286 28.828 64.286 64.285-28.829 64.286-64.286 64.286z"></path></svg><!--[--><span class="page-tag-item color2 clickable" role="navigation">ai</span><span class="page-tag-item color5 clickable" role="navigation">learn-note</span><!--]--><meta property="keywords" content="ai,learn-note"></span></div><hr></div><!----><div class="" vp-content><!----><div id="markdown-content"><h2 id="🧭-标题备选" tabindex="-1"><a class="header-anchor" href="#🧭-标题备选"><span>🧭 标题备选</span></a></h2><ol><li><strong>别被矩阵吓到：机器学习的底层，其实全是线性代数</strong></li><li><strong>线性代数是机器学习的语言：从向量到PCA，一次讲透</strong></li><li><strong>机器学习的灵魂不是AI，而是矩阵</strong></li><li><strong>当你看懂向量、矩阵和PCA，机器学习才真正入门</strong></li><li><strong>数学不抽象：一文讲透机器学习背后的线性世界</strong></li></ol><hr><h2 id="🖼-封面文案" tabindex="-1"><a class="header-anchor" href="#🖼-封面文案"><span>🖼 封面文案</span></a></h2><blockquote><p>所有的智能背后，都是线性代数在默默支撑。<br> 理解矩阵，你就理解了机器学习的底层逻辑。</p></blockquote><p>（配图建议：矩阵格点、空间投影、线性几何感强的视觉）</p><hr><h2 id="✍️-摘要-引导点击" tabindex="-1"><a class="header-anchor" href="#✍️-摘要-引导点击"><span>✍️ 摘要（引导点击）</span></a></h2><blockquote><p>机器学习的底层不是代码，而是数学。<br> 而数学的核心语言，就是线性代数。<br> 本文带你从「向量」到「PCA」，一步步看清算法背后的几何世界。<br> 一旦看懂，你会发现：那些复杂模型，其实都在“算投影”。</p></blockquote><hr><h2 id="📖-正文-线性代数与机器学习的几何世界" tabindex="-1"><a class="header-anchor" href="#📖-正文-线性代数与机器学习的几何世界"><span>📖 正文：线性代数与机器学习的几何世界</span></a></h2><p>很多人学机器学习时，最困惑的部分就是线性代数。<br> 那一堆向量、矩阵、特征值、SVD，看似抽象又难以想象。</p><p>但等你深入一点，就会发现——<br> 几乎所有算法，从线性回归到神经网络，从推荐系统到图像压缩，<br> 底层全是线性代数在“操盘”。</p><hr><h3 id="一、向量-数据的最小单位" tabindex="-1"><a class="header-anchor" href="#一、向量-数据的最小单位"><span>一、向量：数据的最小单位</span></a></h3><p>在机器学习里，一个样本往往就表示成一个向量。<br> 比如一套房子的特征：</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-"><span class="line"><span>x = [面积, 卧室数, 楼层, 城区编码]</span></span>
<span class="line"><span>x = [120, 3, 2, 5]</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><p>这就是一个四维向量。</p><ul><li>每个数是一个特征</li><li>整个向量代表这个房子在“特征空间”中的位置</li></ul><p>可以这么理解：<br> 每个样本是一颗点，特征轴就是它所在的坐标系。<br> 所有样本组成的数据世界，就是一个高维空间。</p><hr><h3 id="二、特征空间-模型学习的战场" tabindex="-1"><a class="header-anchor" href="#二、特征空间-模型学习的战场"><span>二、特征空间：模型学习的战场</span></a></h3><p>“模型学习”这件事，其实就是在这个高维空间里，找一条分界线（或超平面）。</p><p>以逻辑回归为例，它学到的是：</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-"><span class="line"><span>w₁x₁ + w₂x₂ + b = 0</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>这条“超平面”把点分成两边：一边是正类，一边是负类。</p><p>所以你可以这样理解：</p><blockquote><p>向量 = 数据点，<br> 模型 = 空间中的一条线或一个面，<br> 学习 = 不断调整这条线的位置。</p></blockquote><hr><h3 id="三、矩阵-批量样本的集合" tabindex="-1"><a class="header-anchor" href="#三、矩阵-批量样本的集合"><span>三、矩阵：批量样本的集合</span></a></h3><p>如果一个样本是向量，那么多个样本就组成矩阵：</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-"><span class="line"><span>X =</span></span>
<span class="line"><span>[x₁₁ x₁₂ … x₁d</span></span>
<span class="line"><span> x₂₁ x₂₂ … x₂d</span></span>
<span class="line"><span> …</span></span>
<span class="line"><span> xn₁ xn₂ … xnd]</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>其中：</p><ul><li>n：样本数</li><li>d：特征数</li></ul><p>几乎所有机器学习算法，起点都是这个矩阵 X。</p><p>比如线性回归：</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-"><span class="line"><span>y = Xw + b</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>矩阵乘法在这里的意义非常直观：</p><blockquote><p>它在做「加权求和」——<br> 每个特征乘上权重，再把它们加起来，就是预测值。</p></blockquote><p>神经网络其实也是在不断地重复这个动作：<br> 线性变换 + 非线性激活。<br> 看似复杂，其实底层全是矩阵乘法。</p><hr><h3 id="四、矩阵的常见操作-它们各自干嘛的" tabindex="-1"><a class="header-anchor" href="#四、矩阵的常见操作-它们各自干嘛的"><span>四、矩阵的常见操作（它们各自干嘛的）</span></a></h3><table><thead><tr><th>操作</th><th>含义</th><th>用途</th></tr></thead><tbody><tr><td>转置 (A^T)</td><td>行列互换</td><td>求相似度、计算协方差</td></tr><tr><td>逆矩阵 (A^{-1})</td><td>方程求解</td><td>线性回归正规方程法</td></tr><tr><td>迹（Trace）</td><td>对角线之和</td><td>衡量方差总量</td></tr><tr><td>行列式（Det）</td><td>矩阵“体积”</td><td>判断是否可逆、PCA</td></tr></tbody></table><p>一句话总结：</p><blockquote><p>向量描述“点”，矩阵描述“变换”。</p></blockquote><hr><h3 id="五、特征值与特征向量-空间的-主方向" tabindex="-1"><a class="header-anchor" href="#五、特征值与特征向量-空间的-主方向"><span>五、特征值与特征向量：空间的“主方向”</span></a></h3><p>这一对概念听起来抽象，其实特别形象。</p><p>当矩阵 A 作用在一个向量 v 上，如果只改变长度，不改方向：</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-"><span class="line"><span>Av = λv</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>那这个 v 就是特征向量，λ 是特征值。</p><p>也就是说：</p><blockquote><p>特征向量是「不被扭曲方向的轴」；<br> 特征值是「沿这个方向被拉伸的倍数」。</p></blockquote><p>这就是为什么 PCA（主成分分析）要做特征值分解——<br> 它就是在找数据中“变化最明显的方向”。</p><hr><h3 id="六、svd-通用的矩阵分解神器" tabindex="-1"><a class="header-anchor" href="#六、svd-通用的矩阵分解神器"><span>六、SVD：通用的矩阵分解神器</span></a></h3><p>SVD（奇异值分解）是线性代数里最强大的工具之一：</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-"><span class="line"><span>A = U Σ Vᵀ</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>可以把它想象成：</p><blockquote><p>把任意矩阵拆成 “旋转 + 缩放 + 再旋转”。</p></blockquote><p>这玩意几乎无处不在：</p><ul><li>推荐系统：分解成“用户向量 × 商品向量”，预测偏好</li><li>图像压缩：保留前几个奇异值就能还原主要图像</li><li>NLP：潜在语义分析（LSA）</li><li>降噪：去掉小奇异值对应的“噪声维度”</li></ul><p>所以你能看到的很多“AI 应用”，本质都是矩阵分解的艺术。</p><hr><h3 id="七、pca-用最少维度保留最多信息" tabindex="-1"><a class="header-anchor" href="#七、pca-用最少维度保留最多信息"><span>七、PCA：用最少维度保留最多信息</span></a></h3><p>PCA（主成分分析）的目标很简单：</p><blockquote><p>把高维数据投影到低维空间，但尽量保留信息量。</p></blockquote><p>做法是：</p><ol><li>计算协方差矩阵</li><li>求出特征值和特征向量</li><li>选出前几个最大的方向</li><li>投影到这些方向上</li></ol><p>几何意义就一句话：</p><blockquote><p>把数据“旋转”到变化最明显的几个轴上。</p></blockquote><p>这样既能压缩维度，又能保留主要结构。<br> 在图像压缩、降噪、可视化里都用得上。</p><hr><h3 id="八、小结-所有智能都建立在线性世界之上" tabindex="-1"><a class="header-anchor" href="#八、小结-所有智能都建立在线性世界之上"><span>八、小结：所有智能都建立在线性世界之上</span></a></h3><table><thead><tr><th>概念</th><th>本质作用</th><th>在机器学习中的角色</th></tr></thead><tbody><tr><td>向量空间</td><td>表示样本与特征</td><td>特征表示、语义嵌入</td></tr><tr><td>矩阵运算</td><td>批量计算与线性变换</td><td>模型训练、预测</td></tr><tr><td>特征值分解</td><td>找主方向</td><td>PCA、稳定性分析</td></tr><tr><td>奇异值分解</td><td>通用矩阵分解</td><td>推荐、压缩、降噪</td></tr><tr><td>PCA</td><td>信息最大化投影</td><td>降维、特征提取</td></tr></tbody></table><p>机器学习离不开数学，而数学的底层，是线性代数。<br> 看懂矩阵和向量，你才真正理解模型背后的“逻辑结构”。<br> 那时你会发现：<br> 所有复杂的智能，其实都源自线性的优雅。</p><hr><h1 id="第4章-线性代数与矩阵运算" tabindex="-1"><a class="header-anchor" href="#第4章-线性代数与矩阵运算"><span>第4章　线性代数与矩阵运算</span></a></h1><p>非常好，这一章是很多人“入门机器学习”时最模糊、但“深入机器学习”后才恍然大悟的部分。</p><p>几乎所有的算法——从线性回归到神经网络，从聚类到推荐系统——底层都离不开 <strong>线性代数</strong>。</p><p>下面我会以「直观解释 + 数学形式 + 实际应用」的方式来系统讲解。</p><h2 id="_4-1-向量空间与特征表示" tabindex="-1"><a class="header-anchor" href="#_4-1-向量空间与特征表示"><span>4.1 向量空间与特征表示</span></a></h2><h3 id="🧩-向量-vector" tabindex="-1"><a class="header-anchor" href="#🧩-向量-vector"><span>🧩 向量（Vector）</span></a></h3><p>在机器学习中，<strong>向量 = 一个样本的特征集合</strong>。<br> 例如，一个房屋样本：<br> [<br> x = [\text{面积}, \text{卧室数}, \text{楼层}, \text{城区编码}]<br> ]<br> 可写作一个 4 维向量：<br> [<br> x = [120, 3, 2, 5]<br> ]</p><p>向量是机器学习中最基础的数据单位。</p><ul><li>每个维度表示一个特征（feature）</li><li>整个向量表示样本在特征空间中的位置</li></ul><hr><h3 id="🧠-向量空间-vector-space" tabindex="-1"><a class="header-anchor" href="#🧠-向量空间-vector-space"><span>🧠 向量空间（Vector Space）</span></a></h3><p>一组向量加上线性运算（加法、数乘）就构成一个向量空间。</p><p>例如，二维空间的所有点 ((x_1, x_2)) 构成一个二维向量空间。<br> 在机器学习中，这种空间常称为「<strong>特征空间（Feature Space）</strong>」。</p><hr><h3 id="📈-特征表示-feature-representation" tabindex="-1"><a class="header-anchor" href="#📈-特征表示-feature-representation"><span>📈 特征表示（Feature Representation）</span></a></h3><p>向量的几何意义非常重要：</p><ul><li>每个样本是一个点；</li><li>每个维度是一个特征轴；</li><li>模型的“学习”其实就是在高维空间中寻找“划分这些点的超平面”。</li></ul><p>例如，逻辑回归学习的其实就是一个超平面：<br> [<br> w_1x_1 + w_2x_2 + b = 0<br> ]<br> 它把空间分成“正类”和“负类”。</p><hr><h3 id="🧮-向量运算与几何意义" tabindex="-1"><a class="header-anchor" href="#🧮-向量运算与几何意义"><span>🧮 向量运算与几何意义</span></a></h3><table><thead><tr><th>运算</th><th>数学形式</th><th>含义</th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th></tr></thead><tbody><tr><td>点积（Dot Product）</td><td>( a \cdot b = \sum_i a_i b_i )</td><td>衡量相似度（方向是否一致）</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>范数（Norm）</td><td>(</td><td></td><td>a</td><td></td><td>= \sqrt{\sum_i a_i^2} )</td><td>向量长度</td><td></td><td></td><td></td><td></td></tr><tr><td>余弦相似度</td><td>( \cos\theta = \frac{a \cdot b}{</td><td></td><td>a</td><td></td><td>,</td><td></td><td>b</td><td></td><td>} )</td><td>两个样本相似度</td></tr><tr><td>线性组合</td><td>( c = \alpha a + \beta b )</td><td>新特征的组合方式</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr></tbody></table><p>💡 在推荐系统中，“用户向量”和“商品向量”的点积就代表偏好相似度（矩阵分解模型的核心）。</p><hr><h2 id="_4-2-矩阵运算在学习算法中的作用" tabindex="-1"><a class="header-anchor" href="#_4-2-矩阵运算在学习算法中的作用"><span>4.2 矩阵运算在学习算法中的作用</span></a></h2><h3 id="🧩-矩阵的定义" tabindex="-1"><a class="header-anchor" href="#🧩-矩阵的定义"><span>🧩 矩阵的定义</span></a></h3><p>矩阵就是一组向量的集合。<br> 如果每个样本是一个向量，那么所有样本组成的数据集就是一个矩阵：</p><p>[<br> X =<br> \begin{bmatrix}<br> x_{11} &amp; x_{12} &amp; \dots &amp; x_{1d} <br> x_{21} &amp; x_{22} &amp; \dots &amp; x_{2d} <br> \vdots &amp; \vdots &amp; \ddots &amp; \vdots <br> x_{n1} &amp; x_{n2} &amp; \dots &amp; x_{nd}<br> \end{bmatrix}<br> ]</p><p>其中：</p><ul><li>( n )：样本数</li><li>( d )：特征维度</li></ul><p>这是所有算法的起点。</p><hr><h3 id="🧮-矩阵乘法与模型训练" tabindex="-1"><a class="header-anchor" href="#🧮-矩阵乘法与模型训练"><span>🧮 矩阵乘法与模型训练</span></a></h3><p>矩阵乘法背后隐藏着「批量预测」与「特征加权」。</p><p>例如线性回归：<br> [<br> y = Xw + b<br> ]</p><ul><li>( X )：输入数据矩阵（n×d）</li><li>( w )：参数权重向量（d×1）</li><li>( y )：预测结果（n×1）</li></ul><p>矩阵乘法的几何意义：</p><blockquote><p>把原始数据投影到“权重方向”，得到模型输出。</p></blockquote><p>在神经网络中，权重层的计算其实就是不断地执行 ( XW + b ) 的线性变换，只是叠了很多层。</p><hr><h3 id="📘-矩阵的核心操作及意义" tabindex="-1"><a class="header-anchor" href="#📘-矩阵的核心操作及意义"><span>📘 矩阵的核心操作及意义</span></a></h3><table><thead><tr><th>操作</th><th>含义</th><th>实例</th></tr></thead><tbody><tr><td>转置（(A^T)）</td><td>行列互换</td><td>用于求相似度或协方差</td></tr><tr><td>逆矩阵（(A^{-1})）</td><td>线性方程求解</td><td>线性回归正规方程法</td></tr><tr><td>迹（Trace）</td><td>对角线和</td><td>协方差矩阵的方差和</td></tr><tr><td>行列式（Determinant）</td><td>矩阵体积（可逆性）</td><td>PCA、线性无关性判断</td></tr></tbody></table><p>💡 在优化算法中，矩阵求导（Jacobian/Hessian）决定了梯度下降的方向和收敛速度。</p><hr><h2 id="_4-3-特征值与奇异值分解" tabindex="-1"><a class="header-anchor" href="#_4-3-特征值与奇异值分解"><span>4.3 特征值与奇异值分解</span></a></h2><h3 id="🧠-特征值与特征向量-eigenvalue-eigenvector" tabindex="-1"><a class="header-anchor" href="#🧠-特征值与特征向量-eigenvalue-eigenvector"><span>🧠 特征值与特征向量（Eigenvalue &amp; Eigenvector）</span></a></h3><p>定义：<br> [<br> A v = \lambda v<br> ]</p><p>表示：矩阵 ( A ) 作用在向量 ( v ) 上，只改变它的长度（λ倍），不改变方向。</p><ul><li>( v )：特征向量（方向不变的向量）</li><li>( \lambda )：特征值（方向上的伸缩比例）</li></ul><p>📈 几何意义：<br> 矩阵（线性变换）会把空间拉伸/压缩，而特征向量就是那些「拉伸方向不变」的轴。</p><p>📘 应用：</p><ul><li>PCA 降维（找出方差最大方向）</li><li>图的谱聚类（Graph Laplacian 特征值分解）</li><li>动态系统稳定性分析（通过特征值判断系统是否收敛）</li></ul><hr><h3 id="🔹-奇异值分解-svd-singular-value-decomposition" tabindex="-1"><a class="header-anchor" href="#🔹-奇异值分解-svd-singular-value-decomposition"><span>🔹 奇异值分解（SVD, Singular Value Decomposition）</span></a></h3><p>SVD 是矩阵分解中最重要的一个：<br> [<br> A = U \Sigma V^T<br> ]</p><p>其中：</p><ul><li>( U )：左奇异向量（样本空间）</li><li>( V )：右奇异向量（特征空间）</li><li>( \Sigma )：奇异值（特征的重要性）</li></ul><p>💡 可以理解为：</p><blockquote><p>把任意矩阵分解成“旋转 + 缩放 + 再旋转”。</p></blockquote><p>📘 应用举例：</p><ul><li>信息检索中的 <strong>LSA（潜在语义分析）</strong></li><li>图像压缩（保留前几个奇异值即可）</li><li>推荐系统中的 <strong>矩阵分解（SVD）</strong></li><li>降维与噪声过滤（保留主要成分）</li></ul><hr><h2 id="_4-4-pca-的数学推导与降维本质" tabindex="-1"><a class="header-anchor" href="#_4-4-pca-的数学推导与降维本质"><span>4.4 PCA 的数学推导与降维本质</span></a></h2><h3 id="🎯-pca-主成分分析-的目标" tabindex="-1"><a class="header-anchor" href="#🎯-pca-主成分分析-的目标"><span>🎯 PCA（主成分分析）的目标</span></a></h3><blockquote><p>找到一组新的坐标轴，使数据在这些轴上的投影方差最大，同时维度尽量少。</p></blockquote><p>换句话说：</p><ul><li>我们希望在保留最多信息的同时，去掉冗余维度。</li></ul><hr><h3 id="🧮-pca-的数学推导" tabindex="-1"><a class="header-anchor" href="#🧮-pca-的数学推导"><span>🧮 PCA 的数学推导</span></a></h3><p>给定样本矩阵 ( X )（n×d），假设已中心化（均值为0）：</p><ol><li><p>计算协方差矩阵：<br> [<br> C = \frac{1}{n} X^T X<br> ]</p></li><li><p>对 ( C ) 做特征值分解：<br> [<br> C v_i = \lambda_i v_i<br> ]<br> 得到特征向量 ( v_i ) 与特征值 ( \lambda_i )。</p></li><li><p>选择前 k 个最大特征值对应的向量组成矩阵 ( V_k )。</p></li><li><p>降维后的数据为：<br> [<br> X&#39; = X V_k<br> ]</p></li></ol><p>📘 几何意义：</p><ul><li>特征向量 = 数据最大方差方向</li><li>特征值 = 每个方向的信息量</li><li>投影后 = 把高维数据“旋转”到信息最集中的轴上</li></ul><hr><h3 id="📈-应用举例" tabindex="-1"><a class="header-anchor" href="#📈-应用举例"><span>📈 应用举例</span></a></h3><table><thead><tr><th>应用场景</th><th>说明</th></tr></thead><tbody><tr><td>图像压缩</td><td>保留前 50 个主成分即可恢复主要轮廓</td></tr><tr><td>降噪</td><td>去掉小特征值对应的噪声维度</td></tr><tr><td>可视化</td><td>将高维数据降到 2D / 3D</td></tr><tr><td>特征提取</td><td>作为深度学习前的预处理</td></tr></tbody></table><hr><h3 id="🧠-pca-与-svd-的关系" tabindex="-1"><a class="header-anchor" href="#🧠-pca-与-svd-的关系"><span>🧠 PCA 与 SVD 的关系</span></a></h3><p>事实上，PCA 可以用 SVD 实现：</p><p>[<br> X = U \Sigma V^T<br> ]</p><p>则：</p><ul><li>协方差矩阵 ( C = X^T X = V \Sigma^2 V^T )</li><li>主成分方向就是 ( V ) 的列向量</li></ul><hr><h2 id="🌍-小结" tabindex="-1"><a class="header-anchor" href="#🌍-小结"><span>🌍 小结</span></a></h2><table><thead><tr><th>概念</th><th>本质作用</th><th>机器学习中的角色</th></tr></thead><tbody><tr><td>向量空间</td><td>表示样本与特征</td><td>特征表示、语义嵌入</td></tr><tr><td>矩阵运算</td><td>批量计算与变换</td><td>模型训练、线性预测</td></tr><tr><td>特征值分解</td><td>方向与方差信息</td><td>稳定性、PCA、聚类</td></tr><tr><td>奇异值分解</td><td>通用分解工具</td><td>推荐系统、压缩、降噪</td></tr><tr><td>PCA</td><td>信息最大化投影</td><td>降维、特征提取、可视化</td></tr></tbody></table></div><!----><!----><!----></div><footer class="vp-page-meta"><div class="vp-meta-item edit-link"><a class="auto-link external-link vp-meta-label" href="https://github.com/bbhou/lmxxf-notes/edit/main/src/posts/ml/2025-11-03-04-ml-book-matrix.md" aria-label="Edit this page on GitHub" rel="noopener noreferrer" target="_blank"><!--[--><svg xmlns="http://www.w3.org/2000/svg" class="icon edit-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="edit icon" name="edit"><path d="M430.818 653.65a60.46 60.46 0 0 1-50.96-93.281l71.69-114.012 7.773-10.365L816.038 80.138A60.46 60.46 0 0 1 859.225 62a60.46 60.46 0 0 1 43.186 18.138l43.186 43.186a60.46 60.46 0 0 1 0 86.373L588.879 565.55l-8.637 8.637-117.466 68.234a60.46 60.46 0 0 1-31.958 11.229z"></path><path d="M728.802 962H252.891A190.883 190.883 0 0 1 62.008 771.98V296.934a190.883 190.883 0 0 1 190.883-192.61h267.754a60.46 60.46 0 0 1 0 120.92H252.891a69.962 69.962 0 0 0-69.098 69.099V771.98a69.962 69.962 0 0 0 69.098 69.098h475.911A69.962 69.962 0 0 0 797.9 771.98V503.363a60.46 60.46 0 1 1 120.922 0V771.98A190.883 190.883 0 0 1 728.802 962z"></path></svg><!--]-->Edit this page on GitHub<!----></a></div><div class="vp-meta-item git-info"><div class="update-time"><span class="vp-meta-label">最近更新</span><time class="vp-meta-info" datetime="2025-12-27T05:14:38.000Z" data-allow-mismatch>2025/12/27 05:14</time></div><div class="contributors"><span class="vp-meta-label">贡献者: </span><!--[--><!--[--><span class="vp-meta-info" title="email: 1557740299@qq.com">bbhou</span><!--]--><!--]--></div></div></footer><!----><!----><!----><!--]--></main><!--]--><footer class="vp-footer-wrapper" vp-footer><div class="vp-footer">我是老马，期待与你的下次重逢</div><div class="vp-copyright">Copyright © 2025 老马啸西风 </div></footer></div><!--]--><!--[--><!----><!--[--><!--]--><!--]--><!--]--></div>
    <script type="module" src="/blog-thinking/assets/app-Dvf0wTTF.js" defer></script>
  </body>
</html>
