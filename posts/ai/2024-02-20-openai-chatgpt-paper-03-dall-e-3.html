<!doctype html>
<html lang="zh-CN" data-theme="light">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-rc.24" />
    <meta name="theme" content="VuePress Theme Hope 2.0.0-rc.94" />
    <style>
      :root {
        --vp-c-bg: #fff;
      }

      [data-theme="dark"] {
        --vp-c-bg: #1b1b1f;
      }

      html,
      body {
        background: var(--vp-c-bg);
      }
    </style>
    <script>
      const userMode = localStorage.getItem("vuepress-theme-hope-scheme");
      const systemDarkMode =
        window.matchMedia &&
        window.matchMedia("(prefers-color-scheme: dark)").matches;

      if (userMode === "dark" || (userMode !== "light" && systemDarkMode)) {
        document.documentElement.setAttribute("data-theme", "dark");
      }
    </script>
    <script type="application/ld+json">{"@context":"https://schema.org","@type":"Article","headline":"openai chatgpt paper-01-openai DALL-E 3 论文 Improving Image Generation with Better Captions  提升图像生成的关键：更好的图像描述","image":["https://images.openai.com/blob/54facbbb-c94c-4884-8c94-5b984b19749c/dalle-image-map.png?trim=0,0,0,0&width=2000"],"datePublished":"2024-02-20T00:00:00.000Z","dateModified":"2025-12-27T05:15:15.000Z","author":[{"@type":"Person","name":"老马啸西风","url":"https://houbb.github.io"}]}</script><meta property="og:url" content="https://houbb.github.io/awesome-ai-coding/posts/ai/2024-02-20-openai-chatgpt-paper-03-dall-e-3.html"><meta property="og:site_name" content="老马啸西风"><meta property="og:title" content="openai chatgpt paper-01-openai DALL-E 3 论文 Improving Image Generation with Better Captions  提升图像生成的关键：更好的图像描述"><meta property="og:description" content="摘要 我们展示了通过训练高度描述性的生成图像标题，可以显着改善文本到图像模型的提示跟随能力。 现有的文本到图像模型在跟随详细的图像描述方面存在困难，经常忽略单词或混淆提示的含义。 我们假设这个问题源于训练数据集中存在嘈杂和不准确的图像标题。我们通过训练定制的图像标题生成器来解决这个问题，并使用它重新为训练数据集生成标题。然后我们训练了几个文本到图像模型..."><meta property="og:type" content="article"><meta property="og:image" content="https://images.openai.com/blob/54facbbb-c94c-4884-8c94-5b984b19749c/dalle-image-map.png?trim=0,0,0,0&width=2000"><meta property="og:locale" content="zh-CN"><meta property="og:updated_time" content="2025-12-27T05:15:15.000Z"><meta property="article:tag" content="sh"><meta property="article:tag" content="paper"><meta property="article:tag" content="ai"><meta property="article:published_time" content="2024-02-20T00:00:00.000Z"><meta property="article:modified_time" content="2025-12-27T05:15:15.000Z"><title>openai chatgpt paper-01-openai DALL-E 3 论文 Improving Image Generation with Better Captions  提升图像生成的关键：更好的图像描述 | 老马啸西风</title><meta name="description" content="摘要 我们展示了通过训练高度描述性的生成图像标题，可以显着改善文本到图像模型的提示跟随能力。 现有的文本到图像模型在跟随详细的图像描述方面存在困难，经常忽略单词或混淆提示的含义。 我们假设这个问题源于训练数据集中存在嘈杂和不准确的图像标题。我们通过训练定制的图像标题生成器来解决这个问题，并使用它重新为训练数据集生成标题。然后我们训练了几个文本到图像模型...">
    <link rel="preload" href="/awesome-ai-coding/assets/style-Bb931w8d.css" as="style"><link rel="stylesheet" href="/awesome-ai-coding/assets/style-Bb931w8d.css">
    <link rel="modulepreload" href="/awesome-ai-coding/assets/app-B0et4AS6.js"><link rel="modulepreload" href="/awesome-ai-coding/assets/2024-02-20-openai-chatgpt-paper-03-dall-e-3.html-CnjP-hr0.js"><link rel="modulepreload" href="/awesome-ai-coding/assets/plugin-vue_export-helper-DlAUqK2U.js">
    <link rel="prefetch" href="/awesome-ai-coding/assets/index.html-C_w1V3XB.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/intro.html-C455LfSG.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2025-03-07-ai-learn-what-is-manus.html-W6OAejnr.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2025-04-03-ai-brower-agent-01-agentGPT.html-PyLKn_dz.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2025-04-03-ai-brower-agent-02-browser-use.html-BbcytEFn.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2025-11-20-ai-sdd-09-skills-zh.html-CNThJNki.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2025-11-20-ai-sdd-10-skills-docs-gen.html-C4Sqw7af.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2025-11-20-ai-sdd-21-agent-skills-01-what-is.html-BOCvL254.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2025-11-20-ai-sdd-21-agent-skills-02-specfication.html-DfWZl0Jl.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2025-11-20-ai-sdd-21-agent-skills-03-integrate.html-CgyShduo.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2023-03-24-ai-code.html-D8nQbR_x.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2023-03-24-ai-text-to-image-web.html-CWnZQVyV.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2023-03-24-ai-text-to-image.html-BqtDVAGj.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2024-02-20-ai-01-autogpt-01-overview.html-DokqxtZV.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2024-02-20-ai-02-openui-01-overview.html-69F9EFxh.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2024-02-20-ai-03-awesome-prompts.html-BJuyNYd8.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2024-02-20-ai-03-prompt-guide.html-DYEN1uXT.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2024-02-20-ai-04-chatGPT-deploy.html-B23NuyXT.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2024-02-20-ai-05-gpt4free.html-DWukcdvx.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2024-02-20-ai-06-chatgpt-academic.html-BBL-DB1a.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2024-02-20-ai-07-aigc-for-beginners.html-BMjl5i-U.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2024-02-20-ai-08-chatGPT-next-web.html-MmyBJoQv.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2024-02-20-ai-09-openai-cookbook.html-BiJJ90tA.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2024-02-20-ai-10-openai-assistant.html-2lo04HTo.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2024-02-20-ai-11-quivr.html-BXQobUdl.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2024-02-20-ai-12-lobe-chat.html-B7qCTKa_.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2024-02-20-ai-13-langchain-chat.html-Cs7fTCrm.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2024-02-20-ai-14-wechatMSG.html-Bx3DUdgG.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2024-02-20-ai-15-autogen.html-D41mwJPG.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2024-02-20-ai-16-code-gen-devika-intro.html-DV-au8NO.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2024-02-20-ai-17-chatgpt-on-wechat.html-DVVm6fY0.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2024-02-20-ai-nlp-segment-01-overview.html-DbvuOO0G.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2024-02-20-ai-overview.html-5e0pawEc.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2024-02-20-ai-video-01-overview copy.html-BKgGrH04.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2024-02-20-ai-video-01-overview.html-BS5uW5h4.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2024-02-20-aigc-overview.html-CqUu979S.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2024-02-20-aigc-stable-diffusion-01-overview.html-BCVOdsCg.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2024-02-20-aigc-stable-diffusion-02-doc.html-BVTx2Ohs.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2024-02-20-openai-chatgpt-paper-01-intro.html-uBfZoze5.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2024-02-20-openai-chatgpt-paper-02-tec.html-CxuSuuec.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2024-02-20-openai-chatgpt-paper-03-dall-e-3-simple.html-C6gknZ8i.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2024-02-20-openai-chatgpt-paper-04-sora-tech.html-BPxEe72F.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2024-03-20-xai-org-gork-00-attention-is-all-you-need.html-Dat1m_H4.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2024-03-20-xai-org-gork-00-transformer-intro.html-B0y7xsZ2.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2024-03-20-xai-org-gork-01-sourcecode-1.html-C-R1IH5H.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2024-03-20-xai-org-gork-01-sourcecode-2.html-P209WYU5.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2024-03-20-xai-org-gork-01-sourcecode-3.html-DHKafn6y.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2024-03-20-xai-org-gork-01-sourcecode-4.html-BOPbo6LA.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2025-12-27-ai-dev-roads.html-CiNFMSsJ.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2022-12-06-ai-chatGPT.html-C_tfiVdz.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2022-12-06-ai-dell2-intro-01-overview.html-CuRxTC57.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2024-02-20-aigc-overview.html-gtiMVicT.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2024-02-20-aigc-stable-diffusion-01-overview.html-Cs8lS9th.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2024-02-20-aigc-stable-diffusion-02-doc.html-C8Jh89T-.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2025-03-07-ai-ide-00-overview.html-JkHBVIAQ.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2025-03-07-ai-ide-01-trae-intro.html-Rp5Q5_0m.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2025-11-20-ai-sdd-11-gemini-cli-use-inaction.html-7GYJNBgM.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2025-11-20-ai-sdd-12-gemini-cli-use-intro.html-DtPTlKZQ.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2025-11-20-ai-sdd-13-gemini-cli-use-for-old-project-project-profile.html-C4w0X9sC.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2025-11-20-ai-sdd-13-gemini-cli-use-for-old-project.html-yiVg8Dj4.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2025-11-20-ai-sdd-14-gemini-cli-use-for-new-project-springboot.html-BS4XfGsj.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2025-11-20-ai-sdd-15-gemini-cli-use-for-new-project-vue3.html-BH7RTGoD.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2025-12-15-google-cli-text-to-image.html-JlKxZmgI.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2023-04-14-ai-learn-01-overview.html-CQqmLIXj.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2023-04-14-ai-learn-02-basic.html-GZNXmxEF.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2023-04-14-ai-learn-03-math.html-iSUBOav-.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2023-04-14-ai-learn-04-python-ai.html-DPhaFQ3i.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2023-04-14-ai-learn-05-deeplearing.html-DlBRl7eK.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2023-04-14-ai-weka-01-overview.html-KU-Ya3Ov.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2023-04-14-ai-weka-02-java-hello-world.html-qUEFOk8L.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2023-04-14-ai-weka-03-java-letter-and-digits.html-DoPGRXy9.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2023-04-14-ai-weka-04-mnist.html-D78TXpse.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2023-05-09-ai-jpmml-01-overview.html-BBBU37Pj.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2025-11-03-dive-into-llms-00-overview.html-DwddevVu.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2025-11-03-dive-into-llms-01-basic-python-intro.html-CC3QSPCV.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2025-11-03-dive-into-llms-02-basic-deep-learning-intro.html-DeLSQIBh.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2025-11-03-dive-into-llms-03-basic-nlp-big-model.html-CfCMfNij.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2025-11-03-dive-into-llms-04-transformers-01-intro.html-DoaTX4uA.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2025-11-03-dive-into-llms-05-pytorch-01-intro.html-UJAYxFcs.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2025-11-03-dive-into-llms-06-transformers-02-quick-start-requirements.html-Canw9Qfo.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2025-11-03-dive-into-llms-06-transformers-03-pipeline.html-sFb-H-I0.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2025-11-03-dive-into-llms-06-transformers-04-pipeline-intro.html-BTH9qhgN.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2025-11-03-dive-into-llms-100-ml-history.html-D_ztzrK4.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2025-11-03-dive-into-llms-100-ml-intro.html-CWh5BmQK.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2025-11-03-dive-into-llms-101-ml-vs-dl.html-bF947JuG.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2025-11-03-dive-into-llms-102-ml-nlp-usage.html-DmAv7eNr.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2025-11-03-dive-into-llms-103-ml-other-usage.html-CseLQxDx.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2025-11-03-dive-into-llms-104-ml-sentiment-analysis.html-AGwfQQjv.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2025-11-03-dive-into-llms-11-chap01.html-CvaWBnM_.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2025-11-03-dive-into-llms-30-dl-intro.html-x-angjDh.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2025-11-03-dive-into-llms-31-dl-how-to-learn.html-Cg7AWoBi.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2025-11-03-dive-into-llms-32-dl-write-minist.html-0u_vr5Nd.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2025-11-03-dive-into-llms-33-dl-write-mnist-sequence.html-CcxQkx8w.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2025-11-03-dive-into-llms-34-dl-CNN-intro.html-acgf23NV.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2025-02-03-deepseek-r1-ai-model-compare.html-FYgkFTiG.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2025-02-03-deepseek-r1-how-to-earn-money-by-ai.html-DzS_snU0.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2025-02-03-deepseek-r1-paper-intro.html-CR-LJtfY.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2025-04-15-ai-mcp-01-intro.html-Bzo14B_f.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2025-04-15-ai-mcp-02-awesome-servers.html-CMP0qvjc.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2025-04-15-ai-mcp-03-open-webui.html-DNeUEBiG.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2025-04-15-ai-mcp-04-n8n.html-P9DMLNMq.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2025-04-15-ai-mcp-05-anything-llm.html-Cs3QFyWr.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2025-04-15-ai-mcp-06-maxkb.html-Cpq8ooX6.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2025-04-15-ai-mcp-07-dify-intro.html-vfM8eQlH.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2025-04-15-ai-mcp-08-awesome-dify-vs.html-NF87B7cE.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2025-04-15-ai-mcp-08-awesome-dify-workflow.html-jxgjk3X0.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2025-04-15-ai-mcp-09-difyaia.html-Bhg-eJMo.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2025-04-15-ai-mcp-10-activepieces.html-CsBpHuic.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2025-04-15-ai-mcp-11-playwright-mcp.html-C5EwZaTf.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2025-04-15-ai-mcp-12-aws-mcp.html-R9TVIhvB.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2025-04-15-ai-mcp-13-github-mcp.html-Co0zUmKg.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2025-04-15-ai-mcp-14-a2a-intro.html-BKGthkwQ.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2025-04-15-ai-mcp-15-flow-control-opensource.html-CF7pL2an.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2025-09-16-mcp-01-intro-and-hello-world.html-w5tLMfxa.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2025-11-03-00-ml-book-index.html-DGzu4WjO.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2025-11-03-01-ml-book-history.html-CyOoI9Py.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2025-11-03-02-ml-book-core-thought.html-CEO4ZBeG.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2025-11-03-03-ml-book-rate-and-stat.html-54btDIIe.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2025-11-03-04-ml-book-matrix.html-DuZBO2PA.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2025-11-03-05-ml-book-loss-and-val.html-DSu6SZLF.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2025-11-03-06-ml-book-line-model.html-DcrESv6_.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2025-11-03-07-ml-book-knn.html-C0mrVSWt.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2025-11-03-08-ml-book-decision-tree.html-Cf3R3YJD.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2025-11-03-09-ml-book-rate-model-stat-learn.html-QTIWoObw.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2025-11-03-10-ml-book-k-means.html-CGGXzEZ7.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2025-11-03-11-ml-book-feature.html-CcsSTn8y.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2025-11-03-12-ml-book-model-eval-and-opt.html-BX3TowQq.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2025-11-03-13-ml-book-nlp-inaction.html-ChN0ZW2O.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2025-11-03-14-ml-book-cv.html-DOF_qgDF.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2025-11-03-15-ml-book-time-series.html-DvLfMyh4.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2025-11-03-16-ml-book-deeplearning.html-BmRhrbkV.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2025-11-03-17-ml-book-CNN.html-ByvhI4gb.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2025-11-03-18-ml-book-LLM.html-OL5YtBPs.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2025-11-03-19-ml-book-believe.html-lEbDXVim.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2025-11-03-20-ml-book-think-model.html-D50bflJ3.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2025-11-03-21-ml-book-future.html-ebvaxkVE.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2025-11-20-ai-sdd-01-overview.html-Dmkrg_TM.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2025-11-20-ai-sdd-02-sepc-kit-intro.html-nAxUk88k.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2025-11-20-ai-sdd-03-opensepc-intro.html-C5rPpjWq.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2025-11-20-ai-sdd-04-kiro-intro.html-mRqLSggg.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2025-11-20-ai-sdd-05-sepc-kit-inaction.html-eb5yxPX3.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2025-11-20-ai-sdd-06-openspec-inaction.html-E1ja3744.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2025-11-20-ai-sdd-07-skills.html-CBIV5JOq.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2025-11-20-ai-sdd-08-ali-taobao-best-practise.html-Dy4DzkQO.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2025-11-20-ai-sdd-16-what-about-rules-design.html-DufZJrGS.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2025-11-20-ai-sdd-17-ai-corp-paper.html-BVUkASJs.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2025-11-20-ai-sdd-18-gemini-template.html-CYFrtJL-.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2025-11-20-ai-sdd-19-project-profile-template.html-2Zv6p9A0.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/2025-11-20-ai-sdd-20-design-template.html--4WzCAT1.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/404.html-pLdCodht.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/index.html-D9NyMGt0.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/index.html-BSqxcnz5.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/index.html-BeCIiaHR.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/index.html-6kQ4vdVr.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/index.html-D_96TBv1.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/index.html-BFm0CsRS.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/index.html-Ctl4F69D.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/index.html-CmO3SOzC.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/index.html-B-WfBID9.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/index.html-BPm2Bwok.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/index.html-lge_YrS1.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/index.html-DqLWxznO.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/index.html-Bkmi3x49.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/index.html-YeD0akeb.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/index.html-BI2yR9tI.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/index.html-XzqoVXHw.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/index.html-BUpbgiYp.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/index.html-DYW0u6Jm.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/index.html-mALpmq-y.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/index.html-CCfNiZRe.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/index.html-BYK3nrMH.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/index.html-CzYDpXPr.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/index.html-CznUBLID.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/index.html-BWnN5riS.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/index.html-CXlWeuab.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/index.html-CY2Y6Shc.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/index.html-LJgE0hv4.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/index.html-DAjtMMaA.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/index.html-QrYHuPF7.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/index.html-DQ_0RR_t.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/index.html-DCDlWIh7.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/index.html-xGJKgh_Y.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/index.html-BDPyQJ74.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/index.html-BNwgs6kI.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/index.html-BDlOjtpJ.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/index.html-8wO7xi2i.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/index.html-BQyejX6t.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/photoswipe.esm-CKV1Bsxh.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/auto-BUYG9-ss.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/index-C1rb1p6e.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/flowchart-G1WAoCnn.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/index-DtWMYcbt.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/index-DMDrkyre.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/index-BPAdBlYL.js" as="script"><link rel="prefetch" href="/awesome-ai-coding/assets/mermaid.esm.min-BJ-Sb1ro.js" as="script">
  </head>
  <body>
    <div id="app"><!--[--><!--[--><!--[--><span tabindex="-1"></span><a href="#main-content" class="vp-skip-link sr-only">跳至主要內容</a><!--]--><div class="theme-container no-sidebar external-link-icon has-toc" vp-container><!--[--><header id="navbar" class="vp-navbar" vp-navbar><div class="vp-navbar-start"><button type="button" class="vp-toggle-sidebar-button" title="Toggle Sidebar"><span class="icon"></span></button><!--[--><a class="route-link vp-brand" href="/awesome-ai-coding/" aria-label="带我回家"><img class="vp-nav-logo" src="/awesome-ai-coding/assets/images/lmxxf.png" alt><!----><span class="vp-site-name hide-in-pad">老马啸西风</span></a><!--]--></div><div class="vp-navbar-center"><!--[--><nav class="vp-nav-links"><div class="vp-nav-item hide-in-mobile"><div class="vp-dropdown-wrapper"><button type="button" class="vp-dropdown-title" aria-label="AI 学习"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:brain" sizing="height" height="1em"></iconify-icon>AI 学习<!--]--><span class="arrow"></span><ul class="vp-dropdown"><li class="vp-dropdown-item"><a class="route-link auto-link" href="/awesome-ai-coding/posts/ml/" aria-label="机器学习"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:robot" sizing="both" width="1em" height="1em"></iconify-icon><!--]-->机器学习<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/awesome-ai-coding/posts/llm/" aria-label="大语言模型"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:comments" sizing="both" width="1em" height="1em"></iconify-icon><!--]-->大语言模型<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/awesome-ai-coding/posts/learn-llms/" aria-label="深度学习"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:network-wired" sizing="both" width="1em" height="1em"></iconify-icon><!--]-->深度学习<!----></a></li><li class="vp-dropdown-item"><a class="route-link route-link-active auto-link" href="/awesome-ai-coding/posts/ai/" aria-label="AI 综合"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:star" sizing="both" width="1em" height="1em"></iconify-icon><!--]-->AI 综合<!----></a></li></ul></button></div></div><div class="vp-nav-item hide-in-mobile"><div class="vp-dropdown-wrapper"><button type="button" class="vp-dropdown-title" aria-label="AI 工具"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:screwdriver-wrench" sizing="height" height="1em"></iconify-icon>AI 工具<!--]--><span class="arrow"></span><ul class="vp-dropdown"><li class="vp-dropdown-item"><a class="route-link auto-link" href="/awesome-ai-coding/posts/mcp/" aria-label="MCP 工具"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:plug" sizing="both" width="1em" height="1em"></iconify-icon><!--]-->MCP 工具<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/awesome-ai-coding/posts/agent/" aria-label="AI 代理"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:user-robot" sizing="both" width="1em" height="1em"></iconify-icon><!--]-->AI 代理<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/awesome-ai-coding/posts/agentskills/" aria-label="代理技能"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:gears" sizing="both" width="1em" height="1em"></iconify-icon><!--]-->代理技能<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/awesome-ai-coding/posts/client/" aria-label="客户端工具"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:computer" sizing="both" width="1em" height="1em"></iconify-icon><!--]-->客户端工具<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/awesome-ai-coding/posts/aigc/" aria-label="AIGC"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:image" sizing="both" width="1em" height="1em"></iconify-icon><!--]-->AIGC<!----></a></li></ul></button></div></div><div class="vp-nav-item hide-in-mobile"><div class="vp-dropdown-wrapper"><button type="button" class="vp-dropdown-title" aria-label="开发实践"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:code" sizing="height" height="1em"></iconify-icon>开发实践<!--]--><span class="arrow"></span><ul class="vp-dropdown"><li class="vp-dropdown-item"><a class="route-link auto-link" href="/awesome-ai-coding/posts/sdd/" aria-label="SDD 实践"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:diagram-project" sizing="both" width="1em" height="1em"></iconify-icon><!--]-->SDD 实践<!----></a></li></ul></button></div></div><div class="vp-nav-item hide-in-mobile"><a class="route-link route-link-active auto-link" href="/awesome-ai-coding/posts/" aria-label="全部文章"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:pen-to-square" sizing="height" height="1em"></iconify-icon><!--]-->全部文章<!----></a></div></nav><!--]--></div><div class="vp-navbar-end"><!--[--><!----><div class="vp-nav-item vp-action"><a class="vp-action-link" href="https://github.com/houbb/awesome-ai-coding" target="_blank" rel="noopener noreferrer" aria-label="GitHub"><svg xmlns="http://www.w3.org/2000/svg" class="icon github-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="github icon" name="github" style="width:1.25rem;height:1.25rem;vertical-align:middle;"><path d="M511.957 21.333C241.024 21.333 21.333 240.981 21.333 512c0 216.832 140.544 400.725 335.574 465.664 24.49 4.395 32.256-10.07 32.256-23.083 0-11.69.256-44.245 0-85.205-136.448 29.61-164.736-64.64-164.736-64.64-22.315-56.704-54.4-71.765-54.4-71.765-44.587-30.464 3.285-29.824 3.285-29.824 49.195 3.413 75.179 50.517 75.179 50.517 43.776 75.008 114.816 53.333 142.762 40.79 4.523-31.66 17.152-53.377 31.19-65.537-108.971-12.458-223.488-54.485-223.488-242.602 0-53.547 19.114-97.323 50.517-131.67-5.035-12.33-21.93-62.293 4.779-129.834 0 0 41.258-13.184 134.912 50.346a469.803 469.803 0 0 1 122.88-16.554c41.642.213 83.626 5.632 122.88 16.554 93.653-63.488 134.784-50.346 134.784-50.346 26.752 67.541 9.898 117.504 4.864 129.834 31.402 34.347 50.474 78.123 50.474 131.67 0 188.586-114.73 230.016-224.042 242.09 17.578 15.232 33.578 44.672 33.578 90.454v135.85c0 13.142 7.936 27.606 32.854 22.87C862.25 912.597 1002.667 728.747 1002.667 512c0-271.019-219.648-490.667-490.71-490.667z"></path></svg></a></div><div class="vp-nav-item hide-in-mobile"><button type="button" class="vp-color-mode-switch" id="color-mode-switch"><svg xmlns="http://www.w3.org/2000/svg" class="icon auto-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="auto icon" name="auto" style="display:block;"><path d="M512 992C246.92 992 32 777.08 32 512S246.92 32 512 32s480 214.92 480 480-214.92 480-480 480zm0-840c-198.78 0-360 161.22-360 360 0 198.84 161.22 360 360 360s360-161.16 360-360c0-198.78-161.22-360-360-360zm0 660V212c165.72 0 300 134.34 300 300 0 165.72-134.28 300-300 300z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon dark-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="dark icon" name="dark" style="display:none;"><path d="M524.8 938.667h-4.267a439.893 439.893 0 0 1-313.173-134.4 446.293 446.293 0 0 1-11.093-597.334A432.213 432.213 0 0 1 366.933 90.027a42.667 42.667 0 0 1 45.227 9.386 42.667 42.667 0 0 1 10.24 42.667 358.4 358.4 0 0 0 82.773 375.893 361.387 361.387 0 0 0 376.747 82.774 42.667 42.667 0 0 1 54.187 55.04 433.493 433.493 0 0 1-99.84 154.88 438.613 438.613 0 0 1-311.467 128z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon light-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="light icon" name="light" style="display:none;"><path d="M952 552h-80a40 40 0 0 1 0-80h80a40 40 0 0 1 0 80zM801.88 280.08a41 41 0 0 1-57.96-57.96l57.96-58a41.04 41.04 0 0 1 58 58l-58 57.96zM512 752a240 240 0 1 1 0-480 240 240 0 0 1 0 480zm0-560a40 40 0 0 1-40-40V72a40 40 0 0 1 80 0v80a40 40 0 0 1-40 40zm-289.88 88.08-58-57.96a41.04 41.04 0 0 1 58-58l57.96 58a41 41 0 0 1-57.96 57.96zM192 512a40 40 0 0 1-40 40H72a40 40 0 0 1 0-80h80a40 40 0 0 1 40 40zm30.12 231.92a41 41 0 0 1 57.96 57.96l-57.96 58a41.04 41.04 0 0 1-58-58l58-57.96zM512 832a40 40 0 0 1 40 40v80a40 40 0 0 1-80 0v-80a40 40 0 0 1 40-40zm289.88-88.08 58 57.96a41.04 41.04 0 0 1-58 58l-57.96-58a41 41 0 0 1 57.96-57.96z"></path></svg></button></div><form class="search-box" role="search"><input type="search" placeholder="搜索" autocomplete="off" spellcheck="false" value><!----></form><!--]--><button type="button" class="vp-toggle-navbar-button" aria-label="Toggle Navbar" aria-expanded="false" aria-controls="nav-screen"><span><span class="vp-top"></span><span class="vp-middle"></span><span class="vp-bottom"></span></span></button></div></header><!----><!--]--><!----><div class="toggle-sidebar-wrapper"><span class="arrow start"></span></div><!----><!--[--><main id="main-content" class="vp-page"><!--[--><!----><!----><nav class="vp-breadcrumb disable"></nav><div class="vp-page-title"><h1><!---->openai chatgpt paper-01-openai DALL-E 3 论文 Improving Image Generation with Better Captions  提升图像生成的关键：更好的图像描述</h1><div class="page-info"><span class="page-author-info" aria-label="作者🖊" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon author-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="author icon" name="author"><path d="M649.6 633.6c86.4-48 147.2-144 147.2-249.6 0-160-128-288-288-288s-288 128-288 288c0 108.8 57.6 201.6 147.2 249.6-121.6 48-214.4 153.6-240 288-3.2 9.6 0 19.2 6.4 25.6 3.2 9.6 12.8 12.8 22.4 12.8h704c9.6 0 19.2-3.2 25.6-12.8 6.4-6.4 9.6-16 6.4-25.6-25.6-134.4-121.6-240-243.2-288z"></path></svg><span><a class="page-author-item" href="https://houbb.github.io" target="_blank" rel="noopener noreferrer">老马啸西风</a></span><span property="author" content="老马啸西风"></span></span><!----><span class="page-date-info" aria-label="写作日期📅" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon calendar-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="calendar icon" name="calendar"><path d="M716.4 110.137c0-18.753-14.72-33.473-33.472-33.473-18.753 0-33.473 14.72-33.473 33.473v33.473h66.993v-33.473zm-334.87 0c0-18.753-14.72-33.473-33.473-33.473s-33.52 14.72-33.52 33.473v33.473h66.993v-33.473zm468.81 33.52H716.4v100.465c0 18.753-14.72 33.473-33.472 33.473a33.145 33.145 0 01-33.473-33.473V143.657H381.53v100.465c0 18.753-14.72 33.473-33.473 33.473a33.145 33.145 0 01-33.473-33.473V143.657H180.6A134.314 134.314 0 0046.66 277.595v535.756A134.314 134.314 0 00180.6 947.289h669.74a134.36 134.36 0 00133.94-133.938V277.595a134.314 134.314 0 00-133.94-133.938zm33.473 267.877H147.126a33.145 33.145 0 01-33.473-33.473c0-18.752 14.72-33.473 33.473-33.473h736.687c18.752 0 33.472 14.72 33.472 33.473a33.145 33.145 0 01-33.472 33.473z"></path></svg><span data-allow-mismatch="text">2024/2/20</span><meta property="datePublished" content="2024-02-20T00:00:00.000Z"></span><!----><span class="page-reading-time-info" aria-label="阅读时间⌛" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon timer-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="timer icon" name="timer"><path d="M799.387 122.15c4.402-2.978 7.38-7.897 7.38-13.463v-1.165c0-8.933-7.38-16.312-16.312-16.312H256.33c-8.933 0-16.311 7.38-16.311 16.312v1.165c0 5.825 2.977 10.874 7.637 13.592 4.143 194.44 97.22 354.963 220.201 392.763-122.204 37.542-214.893 196.511-220.2 389.397-4.661 5.049-7.638 11.651-7.638 19.03v5.825h566.49v-5.825c0-7.379-2.849-13.981-7.509-18.9-5.049-193.016-97.867-351.985-220.2-389.527 123.24-37.67 216.446-198.453 220.588-392.892zM531.16 450.445v352.632c117.674 1.553 211.787 40.778 211.787 88.676H304.097c0-48.286 95.149-87.382 213.728-88.676V450.445c-93.077-3.107-167.901-81.297-167.901-177.093 0-8.803 6.99-15.793 15.793-15.793 8.803 0 15.794 6.99 15.794 15.793 0 80.261 63.69 145.635 142.01 145.635s142.011-65.374 142.011-145.635c0-8.803 6.99-15.793 15.794-15.793s15.793 6.99 15.793 15.793c0 95.019-73.789 172.82-165.96 177.093z"></path></svg><span>大约 22 分钟</span><meta property="timeRequired" content="PT22M"></span><span class="page-category-info" aria-label="分类🌈" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon category-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="category icon" name="category"><path d="M148.41 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H148.41c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.311-40.31zM147.556 553.478H429.73c22.263 0 40.311 18.048 40.311 40.31v282.176c0 22.263-18.048 40.312-40.31 40.312H147.555c-22.263 0-40.311-18.049-40.311-40.312V593.79c0-22.263 18.048-40.311 40.31-40.311zM593.927 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H593.927c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.31-40.31zM730.22 920.502H623.926c-40.925 0-74.22-33.388-74.22-74.425V623.992c0-41.038 33.387-74.424 74.425-74.424h222.085c41.038 0 74.424 33.226 74.424 74.067v114.233c0 10.244-8.304 18.548-18.547 18.548s-18.548-8.304-18.548-18.548V623.635c0-20.388-16.746-36.974-37.33-36.974H624.13c-20.585 0-37.331 16.747-37.331 37.33v222.086c0 20.585 16.654 37.331 37.126 37.331H730.22c10.243 0 18.547 8.304 18.547 18.547 0 10.244-8.304 18.547-18.547 18.547z"></path></svg><!--[--><span class="page-category-item color5 clickable" role="navigation">AI</span><!--]--><meta property="articleSection" content="AI"></span><span class="page-tag-info" aria-label="标签🏷" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon tag-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="tag icon" name="tag"><path d="M939.902 458.563L910.17 144.567c-1.507-16.272-14.465-29.13-30.737-30.737L565.438 84.098h-.402c-3.215 0-5.726 1.005-7.634 2.913l-470.39 470.39a10.004 10.004 0 000 14.164l365.423 365.424c1.909 1.908 4.42 2.913 7.132 2.913s5.223-1.005 7.132-2.913l470.39-470.39c2.01-2.11 3.014-5.023 2.813-8.036zm-240.067-72.121c-35.458 0-64.286-28.828-64.286-64.286s28.828-64.285 64.286-64.285 64.286 28.828 64.286 64.285-28.829 64.286-64.286 64.286z"></path></svg><!--[--><span class="page-tag-item color2 clickable" role="navigation">ai</span><span class="page-tag-item color6 clickable" role="navigation">paper</span><span class="page-tag-item color7 clickable" role="navigation">sh</span><!--]--><meta property="keywords" content="ai,paper,sh"></span></div><hr></div><!----><div class="" vp-content><!----><div id="markdown-content"><h1 id="摘要" tabindex="-1"><a class="header-anchor" href="#摘要"><span>摘要</span></a></h1><p>我们展示了通过训练高度描述性的生成图像标题，可以显着改善文本到图像模型的提示跟随能力。</p><p>现有的文本到图像模型在跟随详细的图像描述方面存在困难，经常忽略单词或混淆提示的含义。</p><p>我们假设这个问题源于训练数据集中存在嘈杂和不准确的图像标题。我们通过训练定制的图像标题生成器来解决这个问题，并使用它重新为训练数据集生成标题。然后我们训练了几个文本到图像模型，并发现在这些合成标题上进行训练可靠地提高了提示跟随能力。</p><p>最后，我们利用这些发现构建了 DALL-E 3：一个新的文本到图像生成系统，并对其性能进行了基准测试，评估设计用于衡量提示跟随、连贯性和美感，发现它与竞争对手相比具有明显优势。我们发布了这些评估的样本和代码，以便未来的研究可以继续优化文本到图像系统的这一重要方面。</p><figure><img src="https://images.openai.com/blob/54facbbb-c94c-4884-8c94-5b984b19749c/dalle-image-map.png?trim=0,0,0,0&amp;width=2000" alt="view" tabindex="0" loading="lazy"><figcaption>view</figcaption></figure><h1 id="_1-引言" tabindex="-1"><a class="header-anchor" href="#_1-引言"><span>1 引言</span></a></h1><p>近年来生成建模的进展使得文本到图像生成模型实现了显著的性能提升。</p><p>特别是，通过采用基于采样的方法，如自回归生成建模[27, 2, 1, 20, 30]或使用扩散过程[25, 6, 11, 12, 19, 22]来解决问题，使我们能够将图像生成问题分解为小的、离散的步骤，这些步骤更容易被神经网络学习。</p><p>与此同时，研究人员还找到了利用自注意力层堆叠构建图像生成器的方法[15, 3, 4]。</p><p>通过将图像生成与卷积的隐含空间偏差分离开来，使文本到图像模型能够通过变压器的良好研究的缩放属性可靠地改进。</p><p>结合足够大的数据集，这些方法使得可以训练出大型的文本到图像模型，这些模型能够生成接近人类可以产生的照片和艺术品质量的图像。</p><p>该领域面临的一个重要挑战是图像生成系统的可控性，这些系统经常忽略给定标题中的单词、单词顺序或含义。我们用术语“提示跟随”来指代这些挑战。</p><p>在几项研究中已经指出了这个问题：Rassin等人（2022年）指出DALL-E 2没有强制要求每个单词只有一个含义。Saharia等人（2022年）提出通过对预训练语言模型进行条件化来改进它，并引入了一个名为Drawbench的评估，揭示了常见的提示跟随问题。与此同时，Yu等人（2022b年）引入了他们自己的基准测试Parti Prompts，并表明扩展自回归图像生成器是改进提示跟随的另一种替代方法。</p><p>在这项工作中，我们提出了一种解决提示跟随的新方法：标题改进。我们假设现有文本到图像模型的一个根本问题是它们所训练的数据集中文本和图像配对的质量较差，这个问题在其他作品中也被指出，比如Jia等人（2021年）。我们提出通过为数据集中的图像生成改进的标题来解决这个问题。我们首先学习一个强大的图像标题生成器，它能够产生图像的详细准确的描述。然后，我们将这个标题生成器应用于我们的数据集，以产生更详细的标题。最后，我们在改进后的数据集上训练文本到图像模型。</p><p>在合成数据上进行训练并不是一个新概念。例如，Yu等人（2022b年）提到他们在训练扩展自回归图像生成器时应用了这种技术。我们的贡献在于构建了一种新颖的、描述性的图像标题生成系统，并测量了在训练生成模型时使用合成标题的影响。我们还建立了一套可重现的基准性能档案，用于衡量提示跟随的一系列评估。</p><p>本文重点评估了DALL-E 3在训练高度描述性的生成标题时改进的提示跟随能力。它不涵盖DALL-E 3模型的训练或实现细节。我们在第2节中提供了一个训练图像标题生成器的高级概述，第3节评估了在原始标题与生成标题上训练的文本到图像模型，第4节评估了DALL-E 3，第5节讨论了限制和风险。</p><h1 id="_2-数据集重新生成标题" tabindex="-1"><a class="header-anchor" href="#_2-数据集重新生成标题"><span>2 数据集重新生成标题</span></a></h1><p>我们的文本到图像模型是在一个由大量配对 (t, i) 组成的数据集上进行训练的，其中 i 是一幅图像，t 是描述该图像的文本。</p><p>在大规模数据集中，t 通常是由人类作者衍生出来的，他们专注于简单描述图像的主题，省略了背景细节或图像中描绘的常识关系。通常从 t 中省略的重要细节可能包括：</p><ol><li>厨房中存在的水槽或人行道上的停车标志等对象以及这些对象的描述。</li><li>场景中对象的位置以及这些对象的数量。</li><li>场景中对象的颜色和大小等常识细节。</li><li>图像中显示的文字。</li></ol><p>更糟糕的是，在互联网上找到的标题往往是错误的；它们描述了图像的相关细节。例如，常见的情况是在用于生成图像标题的 alt-text 中发现广告或迷因。</p><p>我们推测所有这些缺陷都可以通过合成生成的标题来解决。在接下来的部分中，我们将讨论我们开发的测试这一理论的程序。</p><h2 id="_2-1-构建图像标题生成器" tabindex="-1"><a class="header-anchor" href="#_2-1-构建图像标题生成器"><span>2.1 构建图像标题生成器</span></a></h2><p>图像标题生成器与传统的语言模型非常相似，它预测文本。因此，我们首先提供对语言模型的简要描述。首先，使用分词器将文本字符串分解为离散的标记。一旦以这种方式分解，我们语料库中的文本部分可以表示为一个序列，t = [t1, t2, . . . , tn]。然后，我们可以通过最大化以下似然函数来构建一个语言模型：</p><p>L(t) = Σlog P(tj |tj−k, . . . , tj−1; Θ) (1)</p><p>其中 Θ 是要优化的标题生成器的参数。要将这个语言模型转换为一个标题生成器，你只需要对图像进行条件化。这里的挑战在于图像由成千上万个像素值组成。在我们当前的神经网络中，对所有这些信息进行条件化是非常低效的，因此我们需要一个压缩的表示空间。方便的是，CLIP[17]提供了这样的表示。因此，给定一个预训练的 CLIP 图像嵌入函数 F(i)，我们将我们的语言模型目标扩展如下：</p><p>L(t, i) = Σlog P(tj |tj−k, . . . , tj−1; zj ; F(i); Θ) (2)</p><p>我们遵循 Yu 等人 (2022a) 的方法，并使用上述公式在我们的 (t, i) 文本和图像对数据集上联合预训练我们的标题生成器与 CLIP 和语言建模目标。</p><p>得到的模型确实是一个良好的标题生成器，但表现出与我们在第2节描述的相同的问题，比如不愿描述细节。</p><h3 id="_2-1-1-微调图像标题生成器" tabindex="-1"><a class="header-anchor" href="#_2-1-1-微调图像标题生成器"><span>2.1.1 微调图像标题生成器</span></a></h3><p>为了改进我们图像生成数据集中的标题，我们希望偏向我们的标题生成器产生对学习文本到图像模型有用的图像描述。</p><p>在我们的第一次尝试中，我们构建了一个小数据集，其中的标题只描述图像的主要主题。然后，我们继续在这个数据集上训练我们的标题生成器。由此过程引起的 θ 的更新会导致一个偏向于描述图像主要主题的模型。</p><p>我们将这种微调生成的标题称为“简短的合成标题”。</p><p>我们再次重复这个过程，第二次创建一个数据集，其中包含描述我们微调数据集中每个图像内容的长、高度描述性的标题。这些标题不仅描述图像的主要主题，还描述了其周围环境、背景、图像中的文字、风格、着色等。然后，我们再次在这个数据集上微调我们的基础标题生成器。我们将由这个标题生成器生成的标题称为“描述性合成标题”。</p><p>图3显示了地面真实、简短合成和描述性合成标题的示例。</p><p>构建完成后，我们将应用我们的图像标题生成器微调到我们文本到图像数据集中的每个图像，从而得到一组合成标题，我们将用于后续实验。</p><h1 id="_3-评估重新生成的数据集" tabindex="-1"><a class="header-anchor" href="#_3-评估重新生成的数据集"><span>3 评估重新生成的数据集</span></a></h1><p>有了我们重新生成的数据集，我们开始评估在合成文本上训练模型的影响。</p><p>我们特别想回答两个问题：</p><ol><li><p>使用每种类型的合成标题的性能影响。</p></li><li><p>合成标题与地面真实标题的最佳混合比例。</p></li></ol><h2 id="_3-1-混合合成和地面真实标题-blending-synthetic-and-ground-truth-captions" tabindex="-1"><a class="header-anchor" href="#_3-1-混合合成和地面真实标题-blending-synthetic-and-ground-truth-captions"><span>3.1 混合合成和地面真实标题（Blending synthetic and ground-truth captions）</span></a></h2><p>像我们的文本到图像扩散模型这样的似然模型有一种臭名昭著的倾向，即过度拟合数据集中的分布规律。</p><p>例如，一个训练过的文本到图像模型，如果训练的文本总是以空格字符开头，那么如果尝试使用不以空格开头的提示进行推理，它就无法正常工作。</p><p>当涉及到在合成标题上训练时，我们需要考虑这个问题。我们的标题生成器模型可能有许多难以检测到的模态行为，但如果训练了这些标题，它们就会成为我们的文本到图像模型的偏差。可能发生这种情况的示例包括字母大小写，标题中是否出现标点符号（例如，它是否总是以句号结尾？），标题的长度，或者风格倾向，比如所有标题都以单词 &quot;a&quot; 或 &quot;an&quot; 开头。</p><p>克服这个问题的最佳方法是将我们的输入规范化为更接近人类可能使用的样式和格式的文本分布。</p><p>当使用地面真实标题时，你可以免费获得这个，因为这些标题实际上是从人类书写的文本分布中抽取出来的。为了在使用合成标题时在我们的模型训练中引入一些这种规范化，我们选择将合成标题与地面真实标题混合。</p><p>混合发生在数据采样时，我们随机选择地面真实标题或合成标题，并以固定的百分比机会。我们将在下一节中分析不同混合比例的性能影响。</p><h2 id="_3-2-评估方法" tabindex="-1"><a class="header-anchor" href="#_3-2-评估方法"><span>3.2 评估方法</span></a></h2><p>为了评估，我们在相同的图像数据集上训练了相同的 T5-条件化图像扩散模型。关于训练的模型的详细信息在附录 A 中描述。所有模型都训练了 500,000 个训练步骤，批量大小为 2048，对应总共 10 亿张训练图像。</p><p>训练完成后，我们使用评估数据集中的标题生成了每个模型的 50,000 张图像。然后，我们使用 Hessel 等人（2022年）中概述的 CLIP-S 评估度量对这些生成的图像进行评估。我们选择 CLIP 分数作为度量标准，因为它与文本-图像相似性有很强的相关性，这正是我们所追求的。作为一个快速回顾，这个度量标准的计算如下：</p><p>首先，我们使用公共的 CLIP ViT-B/32 图像编码器生成图像嵌入 zi，然后我们使用文本编码器为图像标题创建文本嵌入 zt。最后，我们计算 CLIP 分数作为余弦相似度 C：</p><p>C(zi, zt) = zi · zt / (∥zi∥∥zt∥) (3)</p><p>然后，该度量标准对所有 50,000 个文本/图像对计算得到的距离进行平均，并通过一个因子缩放为 100。我们在训练期间跨多个模型检查点执行此评估，始终使用模型学习权重的指数加权平均值进行评估。</p><p>在计算 CLIP 分数时，选择在上述计算中使用哪种标题是重要的。对于我们的测试，我们要么使用地面真实标题，要么使用描述性合成标题。在每个评估中都会注明使用了哪种类型的标题。</p><h2 id="_3-3-标题类型的结果" tabindex="-1"><a class="header-anchor" href="#_3-3-标题类型的结果"><span>3.3 标题类型的结果</span></a></h2><p>我们首先分析了在不同类型的标题上训练的模型之间的性能差异。</p><p>对于这个评估，我们训练了三个模型：</p><ol><li>只在地面真实标题上训练的文本到图像模型。</li><li>在 95% 的简短合成标题上训练的文本到图像模型。</li><li>在 95% 的描述性合成标题上训练的文本到图像模型。</li></ol><p>我们进行了两次这样的评估：一次使用地面真实标题计算的 zt，一次使用描述性合成标题计算的 zt。在这次评估中，我们不使用简短合成标题，因为它们在这个评估中与地面真实标题非常相似。</p><p>结果显示，在使用地面真实标题进行评估时，两个在合成标题上训练的模型的性能略优于基线模型，而在使用描述性合成标题进行评估时，它们的性能明显更好。这表明在训练文本到图像模型时使用合成标题没有任何不利之处。</p><p>有趣的是，合成标题上的评估曲线的方差要低得多。这加强了我们的理论，即重新生成标题可以看作是一种平均操作。在合成标题上评估的图像生成模型也在所有训练的模型中实现了更高的净 CLIP 分数，这支持了合成标题与其对应图像之间具有更好绑定的观点。</p><h2 id="_3-4-标题混合比例" tabindex="-1"><a class="header-anchor" href="#_3-4-标题混合比例"><span>3.4 标题混合比例</span></a></h2><p>为了评估标题混合比例，我们使用我们的描述性合成标题训练了四个图像生成模型，采用了不同的混合比例。</p><p>我们选择了 65%、80%、90% 和 95% 的合成标题混合。在实验进行到中途时，评估显示，65% 的混合在所有评估中远远落后于其他混合，因此我们将其排除。</p><h2 id="_3-5-高度描述性标题的实际用途" tabindex="-1"><a class="header-anchor" href="#_3-5-高度描述性标题的实际用途"><span>3.5 高度描述性标题的实际用途</span></a></h2><p>上述实验表明，通过训练大部分合成标题，我们可以最大限度地提高模型的性能。</p><p>然而，这样做会导致模型自然地适应由我们的标题生成器生成的长、高度描述性标题的分布。</p><p>众所周知，生成模型在从其训练分布中抽样时会产生较差的结果。因此，为了充分发挥我们模型的潜力，我们需要仅使用高度描述性标题从中抽样。幸运的是，最近大型语言模型的突破使得这个问题可以解决。像 GPT-4 这样的模型已经在需要想象力的任务中表现出色，比如讲故事和写诗。可以推断，它们也可能擅长提出图像描述中的合理细节。</p><p>实际上，给定一个类似于附录 C 中找到的提示，我们发现 GPT-4 可以轻松地将任何标题“上采样”为一个高度描述性的标题。为了演示这种方法可能有用的方式，我们对 drawbench 数据集中的标题执行此过程，并在表7中可视化结果。</p><p>正如图7所示，利用大型语言模型对标题进行“上采样”不仅可以添加缺失的细节，还可以消除相对较小的图像生成模型难以学习的复杂关系的歧义。最终结果是，模型通常会正确地呈现它本来会出错的图像。</p><h1 id="_4-dall-e-3" tabindex="-1"><a class="header-anchor" href="#_4-dall-e-3"><span>4 DALL-E 3</span></a></h1><p>为了大规模测试我们的合成标题，我们训练了 DALL-E 3，一个新的最先进的文本到图像生成器。</p><p>为了训练这个模型，我们使用了 95% 的合成标题和 5% 的地面真实标题的混合。</p><p>该模型本身是上述消融实验中使用的模型的放大版本，并进行了几项其他改进。</p><table><thead><tr><th>Metric</th><th>DALL-E 3</th><th>DALL-E 2</th><th>Stable Diffusion XL2</th></tr></thead><tbody><tr><td>MSCOCO Captions</td><td>CLIP Score ↑</td><td>32.0</td><td>31.4</td></tr><tr><td>Drawbench short (GPT-V) 3</td><td>↑</td><td>70.4%</td><td>49.0%</td></tr><tr><td>Drawbench long (GPT-V)</td><td>↑</td><td>81.0%</td><td>52.4%</td></tr><tr><td>T2I-C B-VQA Colors</td><td>↑</td><td>81.1%</td><td>59.2%</td></tr><tr><td>T2I-C B-VQA Shape</td><td>↑</td><td>67.5%</td><td>54.7%</td></tr><tr><td>T2I-C B-VQA Texture</td><td>↑</td><td>80.7%</td><td>63.7%</td></tr></tbody></table><p>表1 - 各种与提示跟随相关的文本到图像模型的比较评估</p><p>1 DALL-E 2 生产版本的图像于 2023 年 9 月 20 日发布。</p><p>2 稳定扩散 XL v1.0 使用了 refiner 模块。</p><p>3 这里的分数是根据 GPT-V 判断为具有“正确”标题的图像百分比。</p><h2 id="_4-1-自动评估" tabindex="-1"><a class="header-anchor" href="#_4-1-自动评估"><span>4.1 自动评估</span></a></h2><p>我们将 DALL-E 3 与 DALL-E 2 和 Stable Diffusion XL 1.0（带有 refiner 模块）进行比较。我们希望评估 DALL-E 3 在与提示跟随相关的任务上的</p><p>表现。我们描述下面的各个任务。</p><h3 id="_4-1-1-clip-分数" tabindex="-1"><a class="header-anchor" href="#_4-1-1-clip-分数"><span>4.1.1 CLIP 分数</span></a></h3><p>我们首先使用公共的 ViT-B/32 模型计算 CLIP 分数，如第 3.2 节所述。对于这个比较，我们使用了来自 MSCOCO 2014 评估数据集的 4,096 个标题来生成我们的图像。在这个评估中，我们使用简短的地面真实标题对模型进行推断。我们的模型在这个评估中的表现优于 DALL-E 2 和 Stable Diffusion XL。</p><h3 id="_4-1-2-drawbench" tabindex="-1"><a class="header-anchor" href="#_4-1-2-drawbench"><span>4.1.2 Drawbench</span></a></h3><p>接下来，我们对 drawbench 数据集的标题进行评估。对于这个测试，我们使用了基于 GPT-4 的经过指导的、视觉感知的大型语言模型 GPT-V 来评估我们的模型与其他模型的性能。对于 drawbench 中的每个提示，我们使用每个模型生成四幅图像。然后，我们使用图像和文本提示（见附录 D 中的提示）提示我们的视觉感知的大型语言模型。这导致一个结论（“正确”/“不正确”）和一个关于该结论的解释。</p><p>由于我们先前观察到我们的模型在给定语言模型的外推标题时表现更好，我们使用 GPT-4 来使用第 3.5 节中描述的过程对 drawbench 标题进行“上采样”。我们使用这些“上采样”标题从所有模型中采样图像时，再次执行以上自动化评估。在要求视觉感知的大型语言模型判断输出时，我们使用原始的地面真实 drawbench 提示。</p><p>在所有 drawbench 评估中，我们的模型都击败了 DALL-E 2 和 Stable Diffusion XL。当我们使用“上采样”标题时，差距显著扩大。</p><h3 id="_4-1-3-t2i-compbench" tabindex="-1"><a class="header-anchor" href="#_4-1-3-t2i-compbench"><span>4.1.3 T2I-CompBench</span></a></h3><p>最后，我们在黄等人（2023年）开发的 T2I-CompBench 评估套件的子集上进行评估。这个基准测试衡量了模型在组合提示上的表现。我们报告了颜色绑定、形状绑定和纹理绑定的分数。我们使用 Disentangled BLIP-VQA 模型来评估这些结果。在所有评估的基准测试中，DALL-E 3 都是最先进的。</p><h2 id="_4-2-人类评估" tabindex="-1"><a class="header-anchor" href="#_4-2-人类评估"><span>4.2 人类评估</span></a></h2><p>我们向人类评估员提交了来自 DALL-E 3 和可比较模型的样本。</p><p>对于这个评估，我们向评估员呈现了两个从相同标题生成的图像并排放置。然后，我们向评估员提出三个问题之一：</p><ol><li>提示跟随：评估员被呈现给文本到图像模型的完整上采样标题，并被要求“选择哪个图像更好地对应于标题”。</li><li>风格： “想象您正在使用一种计算机工具，该工具根据某些文本生成图像。如果您使用此工具，您会更喜欢看到哪个图像。”</li><li>一致性：“选择哪个图像包含更多一致的对象。‘一致’的对象是指可能存在的对象。仔细观察人体部位、面部和姿势、物体的摆放以及场景中的文本，以作出您的判断。提示：计算每个图像的不一致实例，并选择问题较少的图像。”</li></ol><p>对于提示跟随和风格，我们为这次评估组装了一个小型数据集，其中包含 170 个标题，针对的是生产文本到图像系统的典型用法。这些标题涵盖了广泛的实际用例，如生成人物、产品和地点，概念混合，文本渲染和艺术品。我们将这个评估集称为“DALL-E 3 Eval”。这些标题将随着我们的评估样本发布（见第 4.3 节）。对于一致性，我们观察到评估员会对描述虚构场景的图像进行惩罚。因此，我们从 MSCOCO 中随机抽取了 250 个标题，以确保评估提示描述的场景可能存在。请注意，对于风格和一致性评估，我们不向评估员显示用于生成图像的标题，以确保他们将注意力集中在风格或一致性上，而不是提示跟随。对于每对图像和问题，我们从评估员那里收集 3 个答案，每个模型和问题总共有 2040 个评分。人类评估界面显示在第 E 节。</p><p>我们将 DALL-E 3 与带有 refiner 模块的 Stable Diffusion XL 和 Midjourney v5.2 进行比较。在表2中，我们报告使用与 Nichol 等人（2022年）概述的相同计算方法的 ELO 分数。</p><p>正如结果显示的那样，DALL-E 3 生成的图像在所有三个方面，特别是在提示跟随方面，大多数时间都被人类评估员更喜欢，超过了所有竞争对手。</p><table><thead><tr><th>Dataset</th><th>DALL-E 3</th><th>Midjourney 5.2</th><th>Stable Diffusion XL</th><th>DALL-E 2</th></tr></thead><tbody><tr><td>DALL-E 3 Eval (prompt following)</td><td>153.3</td><td>-104.8</td><td>-189.5</td><td>-</td></tr><tr><td>DALL-E 3 Eval (style)</td><td>74.0</td><td>30.9</td><td>-95.7</td><td>-</td></tr><tr><td>MSCOCO (coherence)</td><td>71.0</td><td>48.9</td><td>-84.2</td><td>-</td></tr><tr><td>Drawbench</td><td>61.7</td><td>-</td><td>-34.0</td><td>-79.3</td></tr></tbody></table><h3 id="_4-2-1-drawbench-人类评估" tabindex="-1"><a class="header-anchor" href="#_4-2-1-drawbench-人类评估"><span>4.2.1 Drawbench 人类评估</span></a></h3><p>在前面的部分中，我们使用了 GPT-V 对 drawbench 进行了评估。我们注意到，在某些类型的测试中，GPT-V 在判断提示跟随方面并没有表现出优于随机的性能。特别是，在涉及计算图像中对象数量的任务中。为了更好地覆盖 drawbench 的性能，我们使用了前面部分描述的程序，向人类评估员提交了图像和标题进行评估。与我们的 GPT-V drawbench 评估一样，我们仅比较了 DALL-E 3、带有 refiner 模块的 Stable Diffusion XL 和 DALL-E 2。</p><h2 id="_4-3-可重现性" tabindex="-1"><a class="header-anchor" href="#_4-3-可重现性"><span>4.3 可重现性</span></a></h2><p>我们已将所有以上比较中所有模型生成的所有样本和提示上传到了 GitHub。</p><h1 id="_5-限制与风险" tabindex="-1"><a class="header-anchor" href="#_5-限制与风险"><span>5 限制与风险</span></a></h1><h2 id="_5-1-空间意识" tabindex="-1"><a class="header-anchor" href="#_5-1-空间意识"><span>5.1 空间意识</span></a></h2><p>尽管 DALL-E 3 在提示跟随方面取得了重大进展，但仍然在对象放置和空间意识方面存在困难。</p><p>例如，使用诸如“在左侧”，“在下方”，“在背后”等词语是相当不可靠的。这是因为我们的合成标题生成器也具有这个弱点：它在陈述对象位置方面不可靠，在我们的下游模型中也反映出来。</p><h2 id="_5-2-文本渲染" tabindex="-1"><a class="header-anchor" href="#_5-2-文本渲染"><span>5.2 文本渲染</span></a></h2><p>在构建我们的标题生成器时，我们特别注意确保它能够在生成的标题中包含图像中的突出词语。</p><p>因此，DALL-E 3 可以在提示时生成文本。在测试过程中，我们注意到这种能力是不可靠的，因为单词可能存在缺失或额外的字符。我们怀疑这可能与我们使用的 T5 文本编码器有关：当模型遇到提示中的文本时，它实际上看到代表整个单词的标记，并且必须将其映射到图像中的字母。在未来的工作中，我们希望探索在字符级别的语言模型上进行条件设置，以帮助改善这种行为。</p><h2 id="_5-3-具体性" tabindex="-1"><a class="header-anchor" href="#_5-3-具体性"><span>5.3 具体性</span></a></h2><p>我们观察到我们的合成标题容易产生关于图像的重要细节的幻觉。</p><p>例如，给定一幅植物花卉的图画，标题生成器经常会幻觉出一个植物属和种，并将其放入标题中，即使这些细节在图像中以文本形式提供。当描述鸟类的图片时，我们观察到类似的行为：种类被幻觉出来或根本没有提到。</p><p>这对我们的文本到图像模型产生了下游影响：DALL-E 3 在为上述特定术语生成图像方面不可靠。我们相信对标题生成器的进一步改进应该能够进一步改善我们的文本到图像模型。</p><h2 id="_5-4-安全性和偏见缓解" tabindex="-1"><a class="header-anchor" href="#_5-4-安全性和偏见缓解"><span>5.4 安全性和偏见缓解</span></a></h2><p>我们对部署 DALL-E 3 所引起的安全问题进行了深入分析，包括模型偏见可能带来的风险。这些评估的结果可以在 DALL-E 3 系统卡中找到。</p><h1 id="参考资料" tabindex="-1"><a class="header-anchor" href="#参考资料"><span>参考资料</span></a></h1><p><a href="https://cdn.openai.com/papers/dall-e-3.pdf" target="_blank" rel="noopener noreferrer">https://cdn.openai.com/papers/dall-e-3.pdf</a></p></div><!----><!----><!----></div><footer class="vp-page-meta"><div class="vp-meta-item edit-link"><a class="auto-link external-link vp-meta-label" href="https://github.com/houbb/awesome-ai-coding/edit/main/src/posts/ai/2024-02-20-openai-chatgpt-paper-03-dall-e-3.md" aria-label="Edit this page on GitHub" rel="noopener noreferrer" target="_blank"><!--[--><svg xmlns="http://www.w3.org/2000/svg" class="icon edit-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="edit icon" name="edit"><path d="M430.818 653.65a60.46 60.46 0 0 1-50.96-93.281l71.69-114.012 7.773-10.365L816.038 80.138A60.46 60.46 0 0 1 859.225 62a60.46 60.46 0 0 1 43.186 18.138l43.186 43.186a60.46 60.46 0 0 1 0 86.373L588.879 565.55l-8.637 8.637-117.466 68.234a60.46 60.46 0 0 1-31.958 11.229z"></path><path d="M728.802 962H252.891A190.883 190.883 0 0 1 62.008 771.98V296.934a190.883 190.883 0 0 1 190.883-192.61h267.754a60.46 60.46 0 0 1 0 120.92H252.891a69.962 69.962 0 0 0-69.098 69.099V771.98a69.962 69.962 0 0 0 69.098 69.098h475.911A69.962 69.962 0 0 0 797.9 771.98V503.363a60.46 60.46 0 1 1 120.922 0V771.98A190.883 190.883 0 0 1 728.802 962z"></path></svg><!--]-->Edit this page on GitHub<!----></a></div><div class="vp-meta-item git-info"><div class="update-time"><span class="vp-meta-label">最近更新</span><time class="vp-meta-info" datetime="2025-12-27T05:15:15.000Z" data-allow-mismatch>2025/12/27 05:15</time></div><div class="contributors"><span class="vp-meta-label">贡献者: </span><!--[--><!--[--><span class="vp-meta-info" title="email: 1557740299@qq.com">bbhou</span><!--]--><!--]--></div></div></footer><!----><!----><!----><!--]--></main><!--]--><footer class="vp-footer-wrapper" vp-footer><div class="vp-footer">我是老马，期待与你的下次重逢</div><div class="vp-copyright">Copyright © 2025 老马啸西风 </div></footer></div><!--]--><!--[--><!----><!--[--><!--]--><!--]--><!--]--></div>
    <script type="module" src="/awesome-ai-coding/assets/app-B0et4AS6.js" defer></script>
  </body>
</html>
