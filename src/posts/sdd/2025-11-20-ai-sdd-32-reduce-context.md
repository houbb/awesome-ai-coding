---
title: AI SDD 开发规范-32-AI编程有一个问题，如何减少上下文。提升 ai 专注力？
tags: [ai, sdd, sh]
published: true
---


# AI编程有一个问题，如何减少上下文。提升 ai 专注力？

这是 **AI 编程实践里一个“核心但常被低估”的问题**。

本质上你问的不是“上下文怎么少”，而是：

> **如何把“对当前任务真正有用的信息密度”拉到极高，同时把无关噪音降到极低，从而让模型在有限注意力预算内保持专注。**

下面我从**原理 → 方法 → 可操作机制 → 你当前实践的进阶建议**四个层面系统回答。

---

## 一、先说清本质：为什么“上下文多”反而让 AI 变笨

LLM 的注意力并不是“越多越好”，而是：

* 有 **固定的注意力预算**
* 上下文越长 → **每一条信息分到的权重越低**
* 模型会自动做“概率性取舍”，而不是“逻辑筛选”

因此当你给 AI：

* README
* DESIGN.md
* 历史代码
* 一堆无关但“看起来相关”的文件

模型实际上会进入一种状态：

> **“我知道很多，但我不知道现在最重要的是什么”**

结果就是你看到的：

* 实现发散
* 忽略关键约束
* 自作主张补逻辑

---

## 二、减少上下文 ≠ 删文件，而是「上下文分层 + 权重化」

一个非常关键的认知转变：

> ❌ 少给上下文
> ✅ **让上下文有“层级、角色和优先级”**

### 1️⃣ 把上下文分成 4 层（强烈推荐）

| 层级           | 作用            | 是否常驻    |
| ------------ | ------------- | ------- |
| **L0：执行指令层** | 当前任务“必须遵守的规则” | ✅ 必须    |
| **L1：任务输入层** | 当前要做的事情       | ✅ 必须    |
| **L2：参考理解层** | 帮助理解，但不直接执行   | ⚠️ 按需   |
| **L3：历史背景层** | 仅用于回溯         | ❌ 默认不加载 |

**绝大多数 AI 编程失败，是 L2 / L3 抢了 L0 / L1 的注意力。**

---

## 三、实战方法：如何让 AI“只看该看的”

### 方法一：用「显式上下文裁剪指令」

在 system / prompt 开头直接声明：

```text
上下文注意力规则：
1. 仅将【L0 执行约束】与【L1 当前任务】作为强约束
2. README / DESIGN / 历史代码仅用于理解，不得引入未明确声明的新行为
3. 若信息冲突，以 L0 > L1 > L2 的优先级处理
```

**这不是废话**，这是在“教模型如何分配注意力权重”。

---

### 方法二：把“上下文”变成“索引”，而不是全文

❌ 常见错误：

> 把 DESIGN.md 整个贴进去

✅ 正确做法：

```text
可参考文档索引：
- DESIGN.md
  - 2.3 数据流（仅用于理解字段含义）
  - 4.1 错误处理原则（仅在涉及异常时使用）
```

👉 **你是在告诉 AI：哪些信息“可能被用到”，而不是“全部要用”。**

---

### 方法三：使用「上下文冻结（Context Freeze）」机制

在任务中段明确声明：

```text
从现在开始：
- 你只能基于已确认的设计和当前代码修改
- 不允许引入新的概念、字段、流程
- 若发现信息不足，必须停下来提出问题
```

这一步对 **防止中后段发散** 极其有效。

---

### 方法四：拆“一个任务”为“多个注意力窗口”

与其一次性让 AI：

> 理解系统 + 设计方案 + 写代码

不如强制它分阶段：

1. **理解阶段**

   * 输出：`我对系统的理解清单`
2. **澄清阶段**

   * 输出：`不确定点 / 歧义点`
3. **执行阶段**

   * 输入：`确认后的最小执行上下文`
4. **校验阶段**

   * 对照清单逐条检查

这本质是在**人为模拟“多次注意力聚焦”**。

---

## 四、你当前实践的“进阶优化建议”（结合你之前的做法）

你现在的体系里已经有非常好的基础：

* `GEMINI.md` → **全局约束**
* `PROJECT_PROFILE.md` → **系统认知**
* `DESIGN.md（AI 可执行版）` → **结构化任务输入**

问题只剩一个：

> **这些文件现在对 AI 来说“权重是相同的”**

### 建议你再加 2 个“专门用来降噪”的文件

---

### 1️⃣ `AI_EXECUTION_CONTEXT.md`（最小执行上下文）

只允许包含：

* 本次要改的模块
* 明确允许修改的文件列表
* 禁止触碰的边界
* 成功 / 失败判定标准

> **这是每一次执行真正要喂给模型的“主食”**

其他文档都变成“参考链接”。

---

### 2️⃣ `AI_ATTENTION_RULES.md`（注意力分配规则）

示例核心内容：

```text
注意力优先级：
P0：本文件 + 当前指令
P1：明确标注为【强约束】的设计
P2：历史设计，仅供理解
P3：历史代码，仅在无歧义时参考

禁止行为：
- 基于历史代码推断新需求
- 为“看起来合理”而补充逻辑
```

**这是在显式“管控模型的自由度”。**

---

## 五、一句话总结（给你一个可复用原则）

> **AI 编程不是“喂更多上下文”，而是“设计注意力分配机制”。**
> 真正高质量的 AI 编程系统，核心能力不是生成代码，而是：
>
> **让模型在任何时刻都清楚：**
>
> * 我现在在干什么
> * 哪些信息最重要
> * 哪些我不能擅自决定



# 参考资料

