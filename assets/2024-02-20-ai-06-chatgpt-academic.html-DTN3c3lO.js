import{_ as h}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as p,a as n,b as s,f as e,d as a,w as r,r as o,o as d}from"./app-eR0lnyjc.js";const c={};function g(k,i){const t=o("RouteLink"),l=o("Mermaid");return d(),p("div",null,[i[28]||(i[28]=n('<h1 id="chat" tabindex="-1"><a class="header-anchor" href="#chat"><span>chat</span></a></h1><h2 id="详细介绍一下-gpt-学术优化-gpt-academic" tabindex="-1"><a class="header-anchor" href="#详细介绍一下-gpt-学术优化-gpt-academic"><span>详细介绍一下 GPT 学术优化 (GPT Academic)</span></a></h2><hr><h1 id="gpt-academic" tabindex="-1"><a class="header-anchor" href="#gpt-academic"><span>GPT Academic</span></a></h1><p><strong>如果喜欢这个项目，请给它一个Star；如果您发明了好用的快捷键或插件，欢迎发pull requests！</strong></p>',5)),s("p",null,[i[5]||(i[5]=a("If you like this project, please give it a Star.",-1)),i[6]||(i[6]=s("br",null,null,-1)),i[7]||(i[7]=a(" Read this in ",-1)),e(t,{to:"/posts/ai/docs/README.English.html"},{default:r(()=>[...i[0]||(i[0]=[a("English",-1)])]),_:1}),i[8]||(i[8]=a(" | ",-1)),e(t,{to:"/posts/ai/docs/README.Japanese.html"},{default:r(()=>[...i[1]||(i[1]=[a("日本語",-1)])]),_:1}),i[9]||(i[9]=a(" | ",-1)),e(t,{to:"/posts/ai/docs/README.Korean.html"},{default:r(()=>[...i[2]||(i[2]=[a("한국어",-1)])]),_:1}),i[10]||(i[10]=a(" | ",-1)),e(t,{to:"/posts/ai/docs/README.Russian.html"},{default:r(()=>[...i[3]||(i[3]=[a("Русский",-1)])]),_:1}),i[11]||(i[11]=a(" | ",-1)),e(t,{to:"/posts/ai/docs/README.French.html"},{default:r(()=>[...i[4]||(i[4]=[a("Français",-1)])]),_:1}),i[12]||(i[12]=a(". All translations have been provided by the project itself. To translate this project to arbitrary language with GPT, read and run ",-1)),i[13]||(i[13]=s("a",{href:"multi_language.py"},[s("code",null,"multi_language.py")],-1)),i[14]||(i[14]=a(" (experimental).",-1))]),i[29]||(i[29]=n('<blockquote><p>[!NOTE]<br> 1.本项目中每个文件的功能都在<a href="https://github.com/binary-husky/gpt_academic/wiki/GPT%E2%80%90Academic%E9%A1%B9%E7%9B%AE%E8%87%AA%E8%AF%91%E8%A7%A3%E6%8A%A5%E5%91%8A" target="_blank" rel="noopener noreferrer">自译解报告</a><code>self_analysis.md</code>详细说明。随着版本的迭代，您也可以随时自行点击相关函数插件，调用GPT重新生成项目的自我解析报告。常见问题请查阅wiki。<br><a href="#installation"><img src="https://img.shields.io/static/v1?label=&amp;message=常规安装方法&amp;color=gray" alt="常规安装方法" loading="lazy"></a> <a href="https://github.com/binary-husky/gpt_academic/releases" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/static/v1?label=&amp;message=一键安装脚本&amp;color=gray" alt="一键安装脚本" loading="lazy"></a> <a href="https://github.com/binary-husky/gpt_academic/wiki/%E9%A1%B9%E7%9B%AE%E9%85%8D%E7%BD%AE%E8%AF%B4%E6%98%8E" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/static/v1?label=&amp;message=配置说明&amp;color=gray" alt="配置说明" loading="lazy"></a> <a href="%5Bhttps://github.com/binary-husky/gpt_academic/wiki/%E9%A1%B9%E7%9B%AE%E9%85%8D%E7%BD%AE%E8%AF%B4%E6%98%8E%5D(https://github.com/binary-husky/gpt_academic/wiki)"><img src="https://img.shields.io/static/v1?label=&amp;message=wiki&amp;color=gray" alt="wiki" loading="lazy"></a></p><p>2.本项目兼容并鼓励尝试国内中文大语言基座模型如通义千问，智谱GLM等。支持多个api-key共存，可在配置文件中填写如<code>API_KEY=&quot;openai-key1,openai-key2,azure-key3,api2d-key4&quot;</code>。需要临时更换<code>API_KEY</code>时，在输入区输入临时的<code>API_KEY</code>然后回车键提交即可生效。</p></blockquote><table><thead><tr><th>功能（⭐= 近期新增功能）</th><th>描述</th></tr></thead><tbody><tr><td>⭐<a href="https://github.com/binary-husky/gpt_academic/wiki/%E5%A6%82%E4%BD%95%E5%88%87%E6%8D%A2%E6%A8%A1%E5%9E%8B" target="_blank" rel="noopener noreferrer">接入新模型</a></td><td>百度<a href="https://cloud.baidu.com/doc/WENXINWORKSHOP/s/Nlks5zkzu" target="_blank" rel="noopener noreferrer">千帆</a>与文心一言, 通义千问<a href="https://modelscope.cn/models/qwen/Qwen-7B-Chat/summary" target="_blank" rel="noopener noreferrer">Qwen</a>，上海AI-Lab<a href="https://github.com/InternLM/InternLM" target="_blank" rel="noopener noreferrer">书生</a>，讯飞<a href="https://xinghuo.xfyun.cn/" target="_blank" rel="noopener noreferrer">星火</a>，<a href="https://huggingface.co/meta-llama/Llama-2-7b-chat-hf" target="_blank" rel="noopener noreferrer">LLaMa2</a>，<a href="https://open.bigmodel.cn/" target="_blank" rel="noopener noreferrer">智谱GLM4</a>，DALLE3, <a href="https://coder.deepseek.com/" target="_blank" rel="noopener noreferrer">DeepseekCoder</a></td></tr><tr><td>⭐支持mermaid图像渲染</td><td>支持让GPT生成<a href="https://www.bilibili.com/video/BV18c41147H9/" target="_blank" rel="noopener noreferrer">流程图</a>、状态转移图、甘特图、饼状图、GitGraph等等（3.7版本）</td></tr><tr><td>⭐Arxiv论文精细翻译 (<a href="https://github.com/binary-husky/gpt_academic/pkgs/container/gpt_academic_with_latex" target="_blank" rel="noopener noreferrer">Docker</a>)</td><td>[插件] 一键<a href="https://www.bilibili.com/video/BV1dz4y1v77A/" target="_blank" rel="noopener noreferrer">以超高质量翻译arxiv论文</a>，目前最好的论文翻译工具</td></tr><tr><td>⭐<a href="https://github.com/binary-husky/gpt_academic/blob/master/docs/use_audio.md" target="_blank" rel="noopener noreferrer">实时语音对话输入</a></td><td>[插件] 异步<a href="https://www.bilibili.com/video/BV1AV4y187Uy/" target="_blank" rel="noopener noreferrer">监听音频</a>，自动断句，自动寻找回答时机</td></tr><tr><td>⭐AutoGen多智能体插件</td><td>[插件] 借助微软AutoGen，探索多Agent的智能涌现可能！</td></tr><tr><td>⭐虚空终端插件</td><td>[插件] 能够使用自然语言直接调度本项目其他插件</td></tr><tr><td>润色、翻译、代码解释</td><td>一键润色、翻译、查找论文语法错误、解释代码</td></tr><tr><td><a href="https://www.bilibili.com/video/BV14s4y1E7jN" target="_blank" rel="noopener noreferrer">自定义快捷键</a></td><td>支持自定义快捷键</td></tr><tr><td>模块化设计</td><td>支持自定义强大的<a href="https://github.com/binary-husky/gpt_academic/tree/master/crazy_functions" target="_blank" rel="noopener noreferrer">插件</a>，插件支持<a href="https://github.com/binary-husky/gpt_academic/wiki/%E5%87%BD%E6%95%B0%E6%8F%92%E4%BB%B6%E6%8C%87%E5%8D%97" target="_blank" rel="noopener noreferrer">热更新</a></td></tr><tr><td><a href="https://www.bilibili.com/video/BV1cj411A7VW" target="_blank" rel="noopener noreferrer">程序剖析</a></td><td>[插件] 一键剖析Python/C/C++/Java/Lua/...项目树 或 <a href="https://www.bilibili.com/video/BV1cj411A7VW" target="_blank" rel="noopener noreferrer">自我剖析</a></td></tr><tr><td>读论文、<a href="https://www.bilibili.com/video/BV1KT411x7Wn" target="_blank" rel="noopener noreferrer">翻译</a>论文</td><td>[插件] 一键解读latex/pdf论文全文并生成摘要</td></tr><tr><td>Latex全文<a href="https://www.bilibili.com/video/BV1nk4y1Y7Js/" target="_blank" rel="noopener noreferrer">翻译</a>、<a href="https://www.bilibili.com/video/BV1FT411H7c5/" target="_blank" rel="noopener noreferrer">润色</a></td><td>[插件] 一键翻译或润色latex论文</td></tr><tr><td>批量注释生成</td><td>[插件] 一键批量生成函数注释</td></tr><tr><td>Markdown<a href="https://www.bilibili.com/video/BV1yo4y157jV/" target="_blank" rel="noopener noreferrer">中英互译</a></td><td>[插件] 看到上面5种语言的<a href="https://github.com/binary-husky/gpt_academic/blob/master/docs/README_EN.md" target="_blank" rel="noopener noreferrer">README</a>了吗？就是出自他的手笔</td></tr><tr><td><a href="https://www.bilibili.com/video/BV1KT411x7Wn" target="_blank" rel="noopener noreferrer">PDF论文全文翻译功能</a></td><td>[插件] PDF论文提取题目&amp;摘要+翻译全文（多线程）</td></tr><tr><td><a href="https://www.bilibili.com/video/BV1LM4y1279X" target="_blank" rel="noopener noreferrer">Arxiv小助手</a></td><td>[插件] 输入arxiv文章url即可一键翻译摘要+下载PDF</td></tr><tr><td>Latex论文一键校对</td><td>[插件] 仿Grammarly对Latex文章进行语法、拼写纠错+输出对照PDF</td></tr><tr><td><a href="https://www.bilibili.com/video/BV19L411U7ia" target="_blank" rel="noopener noreferrer">谷歌学术统合小助手</a></td><td>[插件] 给定任意谷歌学术搜索页面URL，让gpt帮你<a href="https://www.bilibili.com/video/BV1GP411U7Az/" target="_blank" rel="noopener noreferrer">写relatedworks</a></td></tr><tr><td>互联网信息聚合+GPT</td><td>[插件] 一键<a href="https://www.bilibili.com/video/BV1om4y127ck" target="_blank" rel="noopener noreferrer">让GPT从互联网获取信息</a>回答问题，让信息永不过时</td></tr><tr><td>公式/图片/表格显示</td><td>可以同时显示公式的<a href="https://user-images.githubusercontent.com/96192199/230598842-1d7fcddd-815d-40ee-af60-baf488a199df.png" target="_blank" rel="noopener noreferrer">tex形式和渲染形式</a>，支持公式、代码高亮</td></tr><tr><td>启动暗色<a href="https://github.com/binary-husky/gpt_academic/issues/173" target="_blank" rel="noopener noreferrer">主题</a></td><td>在浏览器url后面添加<code>/?__theme=dark</code>可以切换dark主题</td></tr><tr><td><a href="https://www.bilibili.com/video/BV1wT411p7yf" target="_blank" rel="noopener noreferrer">多LLM模型</a>支持</td><td>同时被GPT3.5、GPT4、<a href="https://github.com/THUDM/ChatGLM2-6B" target="_blank" rel="noopener noreferrer">清华ChatGLM2</a>、<a href="https://github.com/OpenLMLab/MOSS" target="_blank" rel="noopener noreferrer">复旦MOSS</a>伺候的感觉一定会很不错吧？</td></tr><tr><td>更多LLM模型接入，支持<a href="https://huggingface.co/spaces/qingxu98/gpt-academic" target="_blank" rel="noopener noreferrer">huggingface部署</a></td><td>加入Newbing接口(新必应)，引入清华<a href="https://github.com/Jittor/JittorLLMs" target="_blank" rel="noopener noreferrer">Jittorllms</a>支持<a href="https://github.com/facebookresearch/llama" target="_blank" rel="noopener noreferrer">LLaMA</a>和<a href="https://openi.org.cn/pangu/" target="_blank" rel="noopener noreferrer">盘古α</a></td></tr><tr><td>⭐<a href="https://github.com/binary-husky/void-terminal" target="_blank" rel="noopener noreferrer">void-terminal</a> pip包</td><td>脱离GUI，在Python中直接调用本项目的所有函数插件（开发中）</td></tr><tr><td>更多新功能展示 (图像生成等) ……</td><td>见本文档结尾处 ……</td></tr></tbody></table><ul><li><p><strong>新界面</strong><br> （修改 <code>config.py</code> 中的 <code>LAYOUT</code> 选项即可实现「左右布局」和「上下布局」的切换）</p><figure><img src="https://user-images.githubusercontent.com/96192199/279702205-d81137c3-affd-4cd1-bb5e-b15610389762.gif" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><figure><img src="https://github.com/binary-husky/gpt_academic/assets/96192199/70ff1ec5-e589-4561-a29e-b831079b37fb.gif" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure></li></ul><hr><ul><li><p><strong>所有按钮通过 <code>functional.py</code> 动态生成</strong><br> 可随意添加自定义功能，解放剪贴板</p><figure><img src="https://user-images.githubusercontent.com/96192199/231975334-b4788e91-4887-412f-8b43-2b9c5f41d248.gif" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure></li></ul><hr><ul><li><p><strong>润色 / 纠错</strong></p><figure><img src="https://user-images.githubusercontent.com/96192199/231980294-f374bdcb-3309-4560-b424-38ef39f04ebd.gif" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure></li></ul><hr><ul><li><p><strong>公式双显示模式</strong><br> 若输出包含公式，将同时显示 TeX 源码与渲染结果，便于复制与阅读</p><figure><img src="https://user-images.githubusercontent.com/96192199/230598842-1d7fcddd-815d-40ee-af60-baf488a199df.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure></li></ul><hr><ul><li><p><strong>懒得读项目代码？</strong><br> 直接将整个工程喂给 ChatGPT</p><figure><img src="https://user-images.githubusercontent.com/96192199/226935232-6b6a73ce-8900-4aee-93f9-733c7e6fef53.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure></li></ul><hr><ul><li><p><strong>多种大语言模型混合调用</strong><br> ChatGLM + OpenAI GPT-3.5 + GPT-4</p><figure><img src="https://user-images.githubusercontent.com/96192199/232537274-deca0563-7aa6-4b5d-94a2-b7c453c47794.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure></li></ul><h1 id="installation" tabindex="-1"><a class="header-anchor" href="#installation"><span>Installation</span></a></h1>',14)),e(l,{code:"eJx9kc1KAlEYhvddxcesimxCcx1EQQVGgZILaTGMvygz4g8aEQg6kWk2gbpQK6SiWaSLrMjUvJeYM2dc2SV0nDMLM2pWc+B73vM+5/NHxBQf5GIJcG3MAfnWjhjUzuu3klbtap0KcwxLS6vgts4z2yx83ZQvcf1ZK93rQ1lvFmHeHRK8YipuAUdISKZBjMEOx+86F5gFI81tNXGrh7GysHeYCIoCRENRVJRwu4nlE/XjSn+pMgc/x20exsbCmsDxouDlZobH/VOtpOjn8mdLHvfzhKXNKUvQbaOq3FEHQ1xWNkQ+7Iv9U9Xk3TYjIEyrjrIKHjyNml1cbyNJIUc9O0BndVzLobuHUaWBshe/i0znUAe1J6GGgt+HmtJE1wWCbO65LLDp2LHjVp5QNGqGXfEwKyxMg7AIDi7hS0/fP2NuJ+b7E/NaBkmvaq9KHcxFmhfYjdl1Kmk+ybLxEKC+ZUblNt0+3a+eq2mNxz80zSSquZUMBEJCwM/xPgs4fVxEjOvDBlYKtMMMQ5oSPZYlikbRyS8Z+QaTCRv/"}),i[30]||(i[30]=n(`<h3 id="安装方法i-直接运行-windows-linux-or-macos" tabindex="-1"><a class="header-anchor" href="#安装方法i-直接运行-windows-linux-or-macos"><span>安装方法I：直接运行 (Windows, Linux or MacOS)</span></a></h3><ol><li><p>下载项目</p><div class="language-sh line-numbers-mode" data-highlighter="shiki" data-ext="sh" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-sh"><span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">git</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> clone</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> --depth=1</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> https://github.com/binary-husky/gpt_academic.git</span></span>
<span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">cd</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> gpt_academic</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div></li><li><p>配置API_KEY等变量</p><p>在<code>config.py</code>中，配置API KEY等变量。<a href="https://github.com/binary-husky/gpt_academic/issues/1" target="_blank" rel="noopener noreferrer">特殊网络环境设置方法</a>、<a href="https://github.com/binary-husky/gpt_academic/wiki/%E9%A1%B9%E7%9B%AE%E9%85%8D%E7%BD%AE%E8%AF%B4%E6%98%8E" target="_blank" rel="noopener noreferrer">Wiki-项目配置说明</a>。</p><p>「 程序会优先检查是否存在名为<code>config_private.py</code>的私密配置文件，并用其中的配置覆盖<code>config.py</code>的同名配置。如您能理解以上读取逻辑，我们强烈建议您在<code>config.py</code>同路径下创建一个名为<code>config_private.py</code>的新配置文件，并使用<code>config_private.py</code>配置项目，从而确保自动更新时不会丢失配置 」。</p><p>「 支持通过<code>环境变量</code>配置项目，环境变量的书写格式参考<code>docker-compose.yml</code>文件或者我们的<a href="https://github.com/binary-husky/gpt_academic/wiki/%E9%A1%B9%E7%9B%AE%E9%85%8D%E7%BD%AE%E8%AF%B4%E6%98%8E" target="_blank" rel="noopener noreferrer">Wiki页面</a>。配置读取优先级: <code>环境变量</code> &gt; <code>config_private.py</code> &gt; <code>config.py</code> 」。</p></li><li><p>安装依赖</p><div class="language-sh line-numbers-mode" data-highlighter="shiki" data-ext="sh" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-sh"><span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># （选择I: 如熟悉python, python推荐版本 3.9 ~ 3.11）备注：使用官方pip源或者阿里pip源, 临时换源方法：python -m pip install -r requirements.txt -i https://mirrors.aliyun.com/pypi/simple/</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">python</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> -m</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> pip</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> install</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> -r</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> requirements.txt</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># （选择II: 使用Anaconda）步骤也是类似的 (https://www.bilibili.com/video/BV1rc411W7Dr)：</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">conda</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> create</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> -n</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> gptac_venv</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> python=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">3.11</span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">    # 创建anaconda环境</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">conda</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> activate</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> gptac_venv</span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">                 # 激活anaconda环境</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">python</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> -m</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> pip</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> install</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> -r</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> requirements.txt</span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"> # 这个步骤和pip安装一样的步骤</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li></ol><details><summary>如果需要支持清华ChatGLM2/复旦MOSS/RWKV作为后端，请点击展开此处</summary><p><p>【可选步骤】如果需要支持清华ChatGLM3/复旦MOSS作为后端，需要额外安装更多依赖（前提条件：熟悉Python + 用过Pytorch + 电脑配置够强）：</p><div class="language-sh line-numbers-mode" data-highlighter="shiki" data-ext="sh" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-sh"><span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 【可选步骤I】支持清华ChatGLM3。清华ChatGLM备注：如果遇到&quot;Call ChatGLM fail 不能正常加载ChatGLM的参数&quot; 错误，参考如下： 1：以上默认安装的为torch+cpu版，使用cuda需要卸载torch重新安装torch+cuda； 2：如因本机配置不够无法加载模型，可以修改request_llm/bridge_chatglm.py中的模型精度, 将 AutoTokenizer.from_pretrained(&quot;THUDM/chatglm-6b&quot;, trust_remote_code=True) 都修改为 AutoTokenizer.from_pretrained(&quot;THUDM/chatglm-6b-int4&quot;, trust_remote_code=True)</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">python</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> -m</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> pip</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> install</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> -r</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> request_llms/requirements_chatglm.txt</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 【可选步骤II】支持复旦MOSS</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">python</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> -m</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> pip</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> install</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> -r</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> request_llms/requirements_moss.txt</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">git</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> clone</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> --depth=1</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> https://github.com/OpenLMLab/MOSS.git</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> request_llms/moss</span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">  # 注意执行此行代码时，必须处于项目根路径</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 【可选步骤III】支持RWKV Runner</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">参考wiki：https://github.com/binary-husky/gpt_academic/wiki/%E9%80%82%E9%85%8DRWKV-Runner</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 【可选步骤IV】确保config.py配置文件的AVAIL_LLM_MODELS包含了期望的模型，目前支持的全部模型如下(jittorllms系列目前仅支持docker方案)：</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">AVAIL_LLM_MODELS</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> =</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> [</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;gpt-3.5-turbo&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;api2d-gpt-3.5-turbo&quot;,</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &quot;gpt-4&quot;,</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &quot;api2d-gpt-4&quot;,</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &quot;chatglm&quot;,</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &quot;moss&quot;]</span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"> # + [&quot;jittorllms_rwkv&quot;, &quot;jittorllms_pangualpha&quot;, &quot;jittorllms_llama&quot;]</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 【可选步骤V】支持本地模型INT8,INT4量化（这里所指的模型本身不是量化版本，目前deepseek-coder支持，后面测试后会加入更多模型量化选择）</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">pip</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> install</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> bitsandbyte</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># windows用户安装bitsandbytes需要使用下面bitsandbytes-windows-webui</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">python</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> -m</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> pip</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> install</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> bitsandbytes</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> --prefer-binary</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> --extra-index-url=https://jllllll.github.io/bitsandbytes-windows-webui</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">pip</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> install</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> -U</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> git+https://github.com/huggingface/transformers.git</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">pip</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> install</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> -U</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> git+https://github.com/huggingface/accelerate.git</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">pip</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> install</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> peft</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></p></details><ol start="4"><li>运行<div class="language-sh line-numbers-mode" data-highlighter="shiki" data-ext="sh" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-sh"><span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">python</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> main.py</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div></li></ol><h3 id="安装方法ii-使用docker" tabindex="-1"><a class="header-anchor" href="#安装方法ii-使用docker"><span>安装方法II：使用Docker</span></a></h3><ol start="0"><li><p>部署项目的全部能力（这个是包含cuda和latex的大型镜像。但如果您网速慢、硬盘小，则不推荐该方法部署完整项目）<br><a href="https://github.com/binary-husky/gpt_academic/actions/workflows/build-with-all-capacity.yml" target="_blank" rel="noopener noreferrer"><img src="https://github.com/binary-husky/gpt_academic/actions/workflows/build-with-all-capacity.yml/badge.svg?branch=master" alt="fullcapacity" loading="lazy"></a></p><div class="language-sh line-numbers-mode" data-highlighter="shiki" data-ext="sh" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-sh"><span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 修改docker-compose.yml，保留方案0并删除其他方案。然后运行：</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">docker-compose</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> up</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div></li><li><p>仅ChatGPT + GLM4 + 文心一言+spark等在线模型（推荐大多数人选择）<br><a href="https://github.com/binary-husky/gpt_academic/actions/workflows/build-without-local-llms.yml" target="_blank" rel="noopener noreferrer"><img src="https://github.com/binary-husky/gpt_academic/actions/workflows/build-without-local-llms.yml/badge.svg?branch=master" alt="basic" loading="lazy"></a><br><a href="https://github.com/binary-husky/gpt_academic/actions/workflows/build-with-latex.yml" target="_blank" rel="noopener noreferrer"><img src="https://github.com/binary-husky/gpt_academic/actions/workflows/build-with-latex.yml/badge.svg?branch=master" alt="basiclatex" loading="lazy"></a><br><a href="https://github.com/binary-husky/gpt_academic/actions/workflows/build-with-audio-assistant.yml" target="_blank" rel="noopener noreferrer"><img src="https://github.com/binary-husky/gpt_academic/actions/workflows/build-with-audio-assistant.yml/badge.svg?branch=master" alt="basicaudio" loading="lazy"></a></p><div class="language-sh line-numbers-mode" data-highlighter="shiki" data-ext="sh" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-sh"><span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 修改docker-compose.yml，保留方案1并删除其他方案。然后运行：</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">docker-compose</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> up</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div></li></ol><p>P.S. 如果需要依赖Latex的插件功能，请见Wiki。另外，您也可以直接使用方案4或者方案0获取Latex功能。</p><ol start="2"><li><p>ChatGPT + GLM3 + MOSS + LLAMA2 + 通义千问（需要熟悉<a href="https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html#installing-on-ubuntu-and-debian" target="_blank" rel="noopener noreferrer">Nvidia Docker</a>运行时）<br><a href="https://github.com/binary-husky/gpt_academic/actions/workflows/build-with-chatglm.yml" target="_blank" rel="noopener noreferrer"><img src="https://github.com/binary-husky/gpt_academic/actions/workflows/build-with-chatglm.yml/badge.svg?branch=master" alt="chatglm" loading="lazy"></a></p><div class="language-sh line-numbers-mode" data-highlighter="shiki" data-ext="sh" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-sh"><span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 修改docker-compose.yml，保留方案2并删除其他方案。然后运行：</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">docker-compose</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> up</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div></li></ol><h3 id="安装方法iii-其他部署方法" tabindex="-1"><a class="header-anchor" href="#安装方法iii-其他部署方法"><span>安装方法III：其他部署方法</span></a></h3>`,9)),s("ol",null,[i[22]||(i[22]=n('<li><p><strong>Windows一键运行脚本</strong>。<br> 完全不熟悉python环境的Windows用户可以下载<a href="https://github.com/binary-husky/gpt_academic/releases" target="_blank" rel="noopener noreferrer">Release</a>中发布的一键运行脚本安装无本地模型的版本。脚本贡献来源：<a href="https://github.com/oobabooga/one-click-installers" target="_blank" rel="noopener noreferrer">oobabooga</a>。</p></li><li><p>使用第三方API、Azure等、文心一言、星火等，见<a href="https://github.com/binary-husky/gpt_academic/wiki/%E9%A1%B9%E7%9B%AE%E9%85%8D%E7%BD%AE%E8%AF%B4%E6%98%8E" target="_blank" rel="noopener noreferrer">Wiki页面</a></p></li><li><p>云服务器远程部署避坑指南。<br> 请访问<a href="https://github.com/binary-husky/gpt_academic/wiki/%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%BF%9C%E7%A8%8B%E9%83%A8%E7%BD%B2%E6%8C%87%E5%8D%97" target="_blank" rel="noopener noreferrer">云服务器远程部署wiki</a></p></li>',3)),s("li",null,[i[21]||(i[21]=s("p",null,"在其他平台部署&二级网址部署",-1)),s("ul",null,[i[19]||(i[19]=s("li",null,[a("使用Sealos"),s("a",{href:"https://github.com/binary-husky/gpt_academic/issues/993",target:"_blank",rel:"noopener noreferrer"},"一键部署"),a("。")],-1)),i[20]||(i[20]=s("li",null,[a("使用WSL2（Windows Subsystem for Linux 子系统）。请访问"),s("a",{href:"https://github.com/binary-husky/gpt_academic/wiki/%E4%BD%BF%E7%94%A8WSL2%EF%BC%88Windows-Subsystem-for-Linux-%E5%AD%90%E7%B3%BB%E7%BB%9F%EF%BC%89%E9%83%A8%E7%BD%B2",target:"_blank",rel:"noopener noreferrer"},"部署wiki-2")],-1)),s("li",null,[i[16]||(i[16]=a("如何在二级网址（如",-1)),i[17]||(i[17]=s("code",null,"http://localhost/subpath",-1)),i[18]||(i[18]=a("）下运行。请访问",-1)),e(t,{to:"/posts/ai/docs/WithFastapi.html"},{default:r(()=>[...i[15]||(i[15]=[a("FastAPI运行说明",-1)])]),_:1})])])])]),i[31]||(i[31]=n(`<h1 id="advanced-usage" tabindex="-1"><a class="header-anchor" href="#advanced-usage"><span>Advanced Usage</span></a></h1><h3 id="i-自定义新的便捷按钮-学术快捷键" tabindex="-1"><a class="header-anchor" href="#i-自定义新的便捷按钮-学术快捷键"><span>I：自定义新的便捷按钮（学术快捷键）</span></a></h3><p>现在已可以通过UI中的<code>界面外观</code>菜单中的<code>自定义菜单</code>添加新的便捷按钮。如果需要在代码中定义，请使用任意文本编辑器打开<code>core_functional.py</code>，添加如下条目即可：</p><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-python"><span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;超级英译中&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">: {</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">    # 前缀，会被加在你的输入之前。例如，用来描述你的要求，例如翻译、解释代码、润色等等</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">    &quot;Prefix&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;请翻译把下面一段内容成中文，然后用一个markdown表格逐一解释文中出现的专有名词：</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">\\n\\n</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">    # 后缀，会被加在你的输入之后。例如，配合前缀可以把你的输入内容用引号圈起来。</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">    &quot;Suffix&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">},</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><figure><img src="https://user-images.githubusercontent.com/96192199/226899272-477c2134-ed71-4326-810c-29891fe4a508.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><h3 id="ii-自定义函数插件" tabindex="-1"><a class="header-anchor" href="#ii-自定义函数插件"><span>II：自定义函数插件</span></a></h3><p>编写强大的函数插件来执行任何你想得到的和想不到的任务。<br> 本项目的插件编写、调试难度很低，只要您具备一定的python基础知识，就可以仿照我们提供的模板实现自己的插件功能。<br> 详情请参考<a href="https://github.com/binary-husky/gpt_academic/wiki/%E5%87%BD%E6%95%B0%E6%8F%92%E4%BB%B6%E6%8C%87%E5%8D%97" target="_blank" rel="noopener noreferrer">函数插件指南</a>。</p><h1 id="updates" tabindex="-1"><a class="header-anchor" href="#updates"><span>Updates</span></a></h1><h3 id="i-动态" tabindex="-1"><a class="header-anchor" href="#i-动态"><span>I：动态</span></a></h3><ol><li>对话保存功能。在函数插件区调用 <code>保存当前的对话</code> 即可将当前对话保存为可读+可复原的html文件，<br> 另外在函数插件区（下拉菜单）调用 <code>载入对话历史存档</code> ，即可还原之前的会话。<br> Tip：不指定文件直接点击 <code>载入对话历史存档</code> 可以查看历史html存档缓存。</li></ol><figure><img src="https://user-images.githubusercontent.com/96192199/235222390-24a9acc0-680f-49f5-bc81-2f3161f1e049.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><ol start="2"><li>⭐Latex/Arxiv论文翻译功能⭐</li></ol><figure><img src="https://github.com/binary-husky/gpt_academic/assets/96192199/002a1a75-ace0-4e6a-94e2-ec1406a746f1" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><figure><img src="https://github.com/binary-husky/gpt_academic/assets/96192199/9fdcc391-f823-464f-9322-f8719677043b" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><ol start="3"><li>虚空终端（从自然语言输入中，理解用户意图+自动调用其他插件）</li></ol><ul><li>步骤一：输入 “ 请调用插件翻译PDF论文，地址为<a href="https://openreview.net/pdf?id=rJl0r3R9KX" target="_blank" rel="noopener noreferrer">https://openreview.net/pdf?id=rJl0r3R9KX</a> ”</li><li>步骤二：点击“虚空终端”</li></ul><figure><img src="https://github.com/binary-husky/gpt_academic/assets/96192199/66f1b044-e9ff-4eed-9126-5d4f3668f1ed" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><ol start="4"><li><p><strong>模块化功能设计</strong><br> 简单的接口却能支持强大的功能</p><p><img src="https://user-images.githubusercontent.com/96192199/229288270-093643c1-0018-487a-81e6-1d7809b6e90f.png" alt="" loading="lazy"><br><img src="https://user-images.githubusercontent.com/96192199/227504931-19955f78-45cd-4d1c-adac-e71e50957915.png" alt="" loading="lazy"></p></li><li><p><strong>译解其他开源项目</strong></p><p><img src="https://user-images.githubusercontent.com/96192199/226935232-6b6a73ce-8900-4aee-93f9-733c7e6fef53.png" alt="" loading="lazy"><br><img src="https://user-images.githubusercontent.com/96192199/226969067-968a27c1-1b9c-486b-8b81-ab2de8d3f88a.png" alt="" loading="lazy"></p></li><li><p><strong>装饰 <a href="https://github.com/fghrsh/live2d_demo" target="_blank" rel="noopener noreferrer">live2d</a> 的小功能</strong><br> （默认关闭，需要修改 <code>config.py</code>）</p><figure><img src="https://user-images.githubusercontent.com/96192199/236432361-67739153-73e8-43fe-8111-b61296edabd9.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure></li><li><p><strong>OpenAI 图像生成</strong></p><figure><img src="https://github.com/binary-husky/gpt_academic/assets/96192199/bc7ab234-ad90-48a0-8d62-f703d9e74665" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure></li><li><p><strong>基于 Mermaid 的流程图 / 脑图绘制</strong></p><figure><img src="https://github.com/binary-husky/gpt_academic/assets/96192199/c518b82f-bd53-46e2-baf5-ad1b081c1da4" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure></li><li><p><strong>LaTeX 全文校对纠错</strong></p><p><img src="https://github.com/binary-husky/gpt_academic/assets/96192199/651ccd98-02c9-4464-91e1-77a6b7d1b033" alt="" loading="lazy"><br> ⇒<br><img src="https://github.com/binary-husky/gpt_academic/assets/96192199/476f66d9-7716-4537-b5c1-735372c25adb" alt="" loading="lazy"></p></li><li><p><strong>语言 / 主题切换</strong></p></li></ol><figure><img src="https://github.com/binary-husky/gpt_academic/assets/96192199/b6799499-b6fb-4f0c-9c8e-1b441872f4e8" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><h3 id="ii-版本" tabindex="-1"><a class="header-anchor" href="#ii-版本"><span>II：版本:</span></a></h3><ul><li>version 3.80(TODO): 优化AutoGen插件主题并设计一系列衍生插件</li><li>version 3.70: 引入Mermaid绘图，实现GPT画脑图等功能</li><li>version 3.60: 引入AutoGen作为新一代插件的基石</li><li>version 3.57: 支持GLM3，星火v3，文心一言v4，修复本地模型的并发BUG</li><li>version 3.56: 支持动态追加基础功能按钮，新汇报PDF汇总页面</li><li>version 3.55: 重构前端界面，引入悬浮窗口与菜单栏</li><li>version 3.54: 新增动态代码解释器（Code Interpreter）（待完善）</li><li>version 3.53: 支持动态选择不同界面主题，提高稳定性&amp;解决多用户冲突问题</li><li>version 3.50: 使用自然语言调用本项目的所有函数插件（虚空终端），支持插件分类，改进UI，设计新主题</li><li>version 3.49: 支持百度千帆平台和文心一言</li><li>version 3.48: 支持阿里达摩院通义千问，上海AI-Lab书生，讯飞星火</li><li>version 3.46: 支持完全脱手操作的实时语音对话</li><li>version 3.45: 支持自定义ChatGLM2微调模型</li><li>version 3.44: 正式支持Azure，优化界面易用性</li><li>version 3.4: +arxiv论文翻译、latex论文批改功能</li><li>version 3.3: +互联网信息综合功能</li><li>version 3.2: 函数插件支持更多参数接口 (保存对话功能, 解读任意语言代码+同时询问任意的LLM组合)</li><li>version 3.1: 支持同时问询多个gpt模型！支持api2d，支持多个apikey负载均衡</li><li>version 3.0: 对chatglm和其他小型llm的支持</li><li>version 2.6: 重构了插件结构，提高了交互性，加入更多插件</li><li>version 2.5: 自更新，解决总结大工程源代码时文本过长、token溢出的问题</li><li>version 2.4: 新增PDF全文翻译功能; 新增输入区切换位置的功能</li><li>version 2.3: 增强多线程交互性</li><li>version 2.2: 函数插件支持热重载</li><li>version 2.1: 可折叠式布局</li><li>version 2.0: 引入模块化函数插件</li><li>version 1.0: 基础功能</li></ul><p>GPT Academic开发者QQ群：<code>610599535</code></p><ul><li>已知问题 <ul><li>某些浏览器翻译插件干扰此软件前端的运行</li><li>官方Gradio目前有很多兼容性问题，请<strong>务必使用<code>requirement.txt</code>安装Gradio</strong></li></ul></li></ul>`,23)),e(l,{code:"eJxtVN1y2lYQvs9T6KrTzjSMA03Scuc2U09m8CTTSR6AOpqUKXYyLvG4vehAwAgwWMYGGxsDBuwE20HC8U+QBOhltOccvUVWOhZRfrixtbvn22+//c5JxBbFeGxJFCJ/3BLwl4gl4qIw9/jJ7dmF6DNxMbZgtzVaV0Auw3kVNrK0t+4W/iMuJGIvloRgYNX9dn53AjP/BwPBsAAtnbaTUGix9Bi/RlVYOya9NjR2obgD0phUB0TesoxrTMoqKdRAPoSRDMM0nCcx5qsgFZUUUzTdt6USG4+nvYKBEPa6i8WdJox0ONqnuonkLP3I0rdI8m1YIDsDTD5+8Dus9ciORE2DqWWPFE+yyTZSg6IOOYmUOta4RMcK3c94VUw6JfVLrPX1vRcWkAtpZiw9yzlSYxs/EVPetM9qGPaRgMKhM3z9Ehny6s/kC/nkC6F8ocAdPKNqC39FE8/ji3x6NwJr15axAwMZmuvxTxn+FzaLZPfa3lWY2sFG1vD0+cuEo3hzfVrihqMvY3+L/7LLFmoJDYm12772QWwf+pb8nD7Ir534xjHI3bBgmQ3o15AYUxtTud52mWpYhkEyMlP7rJe0jC49dAZwCSI75MjzqHIkMk+NDGzmEE3fYqkKHZcts01SKjVGGOawPoI/eXpGl1djK0zRp2v1EvFoQlzlCZLXSEX7GgNBSL+LduOzzf73allEAqMaepNWi3ajQ2rbtNLD9fmP4drRDaDsW1r+N9zOXGQ+CBOFDdKezqA03Rn7duuC6+I//4u3CLtm2lKRTSakfGLvdeykgwilNCqDNIYFcvVh9uHtSPRPS3tDKy1sq6h2t0lqLZo680Do3gT0N3gKhlnQLkAeCN+hpyUw09YwicL7Wt+dQYy9fXqiUyNHz1QPg28Ycll6bjgxjZn1pw+dfhOmtNH01tCwOzU/kuOOAiqTspN5sn5iDUu4WC4aL/YuAe1doFTuDUBTQPbCuaCoae4DZN/T0xQO+wW0c5VdaG4ZPGVLBdjrebcN8iXkzntN35TX78iVQk930ZHWcIPJB1CqkkPZj4t747jMHDse8T1NpJi3t1B0HJWcS6RwjG+F80/SsNtX2MYPcz8s4MZDPwp8DyuoxI2KPtFX0FuWqcBRiRy8g4MBd4bznmjX+IL++nTOB3kP18LHmH2VeDEnLvly96e5eXF5MRp7Ro0a1Ceux+jGAN9nWjFYpowx2s9/5fGfZ75/8ujBox88W9804Av3FsXXzNolNNnNy3TrI6vvVro="}),i[32]||(i[32]=n('<h3 id="iii-主题" tabindex="-1"><a class="header-anchor" href="#iii-主题"><span>III：主题</span></a></h3><p>可以通过修改<code>THEME</code>选项（<a href="http://config.py" target="_blank" rel="noopener noreferrer">config.py</a>）变更主题</p><ol><li><code>Chuanhu-Small-and-Beautiful</code> <a href="https://github.com/GaiZhenbiao/ChuanhuChatGPT/" target="_blank" rel="noopener noreferrer">网址</a></li></ol><h3 id="iv-本项目的开发分支" tabindex="-1"><a class="header-anchor" href="#iv-本项目的开发分支"><span>IV：本项目的开发分支</span></a></h3>',4)),s("ol",null,[i[25]||(i[25]=s("li",null,[s("code",null,"master"),a(" 分支: 主分支，稳定版")],-1)),i[26]||(i[26]=s("li",null,[s("code",null,"frontier"),a(" 分支: 开发分支，测试版")],-1)),s("li",null,[i[24]||(i[24]=a("如何",-1)),e(t,{to:"/posts/ai/request_llms/"},{default:r(()=>[...i[23]||(i[23]=[a("接入其他大模型",-1)])]),_:1})]),i[27]||(i[27]=s("li",null,[a("访问GPT-Academic的"),s("a",{href:"https://github.com/binary-husky/gpt_academic/wiki/online",target:"_blank",rel:"noopener noreferrer"},"在线服务并支持我们")],-1))]),i[33]||(i[33]=n(`<h3 id="v-参考与学习" tabindex="-1"><a class="header-anchor" href="#v-参考与学习"><span>V：参考与学习</span></a></h3><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-"><span class="line"><span>代码中参考了很多其他优秀项目中的设计，顺序不分先后：</span></span>
<span class="line"><span></span></span>
<span class="line"><span># 清华ChatGLM2-6B:</span></span>
<span class="line"><span>https://github.com/THUDM/ChatGLM2-6B</span></span>
<span class="line"><span></span></span>
<span class="line"><span># 清华JittorLLMs:</span></span>
<span class="line"><span>https://github.com/Jittor/JittorLLMs</span></span>
<span class="line"><span></span></span>
<span class="line"><span># ChatPaper:</span></span>
<span class="line"><span>https://github.com/kaixindelele/ChatPaper</span></span>
<span class="line"><span></span></span>
<span class="line"><span># Edge-GPT:</span></span>
<span class="line"><span>https://github.com/acheong08/EdgeGPT</span></span>
<span class="line"><span></span></span>
<span class="line"><span># ChuanhuChatGPT:</span></span>
<span class="line"><span>https://github.com/GaiZhenbiao/ChuanhuChatGPT</span></span>
<span class="line"><span></span></span>
<span class="line"><span># Oobabooga one-click installer:</span></span>
<span class="line"><span>https://github.com/oobabooga/one-click-installers</span></span>
<span class="line"><span></span></span>
<span class="line"><span># More：</span></span>
<span class="line"><span>https://github.com/gradio-app/gradio</span></span>
<span class="line"><span>https://github.com/fghrsh/live2d_demo</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h1 id="参考资料" tabindex="-1"><a class="header-anchor" href="#参考资料"><span>参考资料</span></a></h1><p><a href="https://github.com/binary-husky/gpt_academic" target="_blank" rel="noopener noreferrer">https://github.com/binary-husky/gpt_academic</a></p>`,4))])}const m=h(c,[["render",g]]),y=JSON.parse('{"path":"/posts/ai/2024-02-20-ai-06-chatgpt-academic.html","title":"AI-06-GPT 学术优化 (GPT Academic)","lang":"zh-CN","frontmatter":{"title":"AI-06-GPT 学术优化 (GPT Academic)","date":"2024-02-20T00:00:00.000Z","categories":["AI"],"tags":["ai","aigc","chatgpt","gpt","sh"],"published":true,"description":"chat 详细介绍一下 GPT 学术优化 (GPT Academic) GPT Academic 如果喜欢这个项目，请给它一个Star；如果您发明了好用的快捷键或插件，欢迎发pull requests！ If you like this project, please give it a Star. Read this in | | | | . All...","head":[["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"AI-06-GPT 学术优化 (GPT Academic)\\",\\"image\\":[\\"https://img.shields.io/static/v1?label=&message=常规安装方法&color=gray\\",\\"https://img.shields.io/static/v1?label=&message=一键安装脚本&color=gray\\",\\"https://img.shields.io/static/v1?label=&message=配置说明&color=gray\\",\\"https://img.shields.io/static/v1?label=&message=wiki&color=gray\\",\\"https://user-images.githubusercontent.com/96192199/279702205-d81137c3-affd-4cd1-bb5e-b15610389762.gif\\",\\"https://github.com/binary-husky/gpt_academic/assets/96192199/70ff1ec5-e589-4561-a29e-b831079b37fb.gif\\",\\"https://user-images.githubusercontent.com/96192199/231975334-b4788e91-4887-412f-8b43-2b9c5f41d248.gif\\",\\"https://user-images.githubusercontent.com/96192199/231980294-f374bdcb-3309-4560-b424-38ef39f04ebd.gif\\",\\"https://user-images.githubusercontent.com/96192199/230598842-1d7fcddd-815d-40ee-af60-baf488a199df.png\\",\\"https://user-images.githubusercontent.com/96192199/226935232-6b6a73ce-8900-4aee-93f9-733c7e6fef53.png\\",\\"https://user-images.githubusercontent.com/96192199/232537274-deca0563-7aa6-4b5d-94a2-b7c453c47794.png\\",\\"https://github.com/binary-husky/gpt_academic/actions/workflows/build-with-all-capacity.yml/badge.svg?branch=master\\",\\"https://github.com/binary-husky/gpt_academic/actions/workflows/build-without-local-llms.yml/badge.svg?branch=master\\",\\"https://github.com/binary-husky/gpt_academic/actions/workflows/build-with-latex.yml/badge.svg?branch=master\\",\\"https://github.com/binary-husky/gpt_academic/actions/workflows/build-with-audio-assistant.yml/badge.svg?branch=master\\",\\"https://github.com/binary-husky/gpt_academic/actions/workflows/build-with-chatglm.yml/badge.svg?branch=master\\",\\"https://user-images.githubusercontent.com/96192199/226899272-477c2134-ed71-4326-810c-29891fe4a508.png\\",\\"https://user-images.githubusercontent.com/96192199/235222390-24a9acc0-680f-49f5-bc81-2f3161f1e049.png\\",\\"https://github.com/binary-husky/gpt_academic/assets/96192199/002a1a75-ace0-4e6a-94e2-ec1406a746f1\\",\\"https://github.com/binary-husky/gpt_academic/assets/96192199/9fdcc391-f823-464f-9322-f8719677043b\\",\\"https://github.com/binary-husky/gpt_academic/assets/96192199/66f1b044-e9ff-4eed-9126-5d4f3668f1ed\\",\\"https://user-images.githubusercontent.com/96192199/229288270-093643c1-0018-487a-81e6-1d7809b6e90f.png\\",\\"https://user-images.githubusercontent.com/96192199/227504931-19955f78-45cd-4d1c-adac-e71e50957915.png\\",\\"https://user-images.githubusercontent.com/96192199/226935232-6b6a73ce-8900-4aee-93f9-733c7e6fef53.png\\",\\"https://user-images.githubusercontent.com/96192199/226969067-968a27c1-1b9c-486b-8b81-ab2de8d3f88a.png\\",\\"https://user-images.githubusercontent.com/96192199/236432361-67739153-73e8-43fe-8111-b61296edabd9.png\\",\\"https://github.com/binary-husky/gpt_academic/assets/96192199/bc7ab234-ad90-48a0-8d62-f703d9e74665\\",\\"https://github.com/binary-husky/gpt_academic/assets/96192199/c518b82f-bd53-46e2-baf5-ad1b081c1da4\\",\\"https://github.com/binary-husky/gpt_academic/assets/96192199/651ccd98-02c9-4464-91e1-77a6b7d1b033\\",\\"https://github.com/binary-husky/gpt_academic/assets/96192199/476f66d9-7716-4537-b5c1-735372c25adb\\",\\"https://github.com/binary-husky/gpt_academic/assets/96192199/b6799499-b6fb-4f0c-9c8e-1b441872f4e8\\"],\\"datePublished\\":\\"2024-02-20T00:00:00.000Z\\",\\"dateModified\\":\\"2025-12-27T05:15:15.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"老马啸西风\\",\\"url\\":\\"https://houbb.github.io\\"}]}"],["meta",{"property":"og:url","content":"https://houbb.github.io/awesome-ai-coding/posts/ai/2024-02-20-ai-06-chatgpt-academic.html"}],["meta",{"property":"og:site_name","content":"老马啸西风"}],["meta",{"property":"og:title","content":"AI-06-GPT 学术优化 (GPT Academic)"}],["meta",{"property":"og:description","content":"chat 详细介绍一下 GPT 学术优化 (GPT Academic) GPT Academic 如果喜欢这个项目，请给它一个Star；如果您发明了好用的快捷键或插件，欢迎发pull requests！ If you like this project, please give it a Star. Read this in | | | | . All..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:image","content":"https://img.shields.io/static/v1?label=&message=常规安装方法&color=gray"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2025-12-27T05:15:15.000Z"}],["meta",{"property":"article:tag","content":"sh"}],["meta",{"property":"article:tag","content":"gpt"}],["meta",{"property":"article:tag","content":"chatgpt"}],["meta",{"property":"article:tag","content":"aigc"}],["meta",{"property":"article:tag","content":"ai"}],["meta",{"property":"article:published_time","content":"2024-02-20T00:00:00.000Z"}],["meta",{"property":"article:modified_time","content":"2025-12-27T05:15:15.000Z"}]]},"git":{"createdTime":1766812269000,"updatedTime":1766812515000,"contributors":[{"name":"bbhou","username":"bbhou","email":"1557740299@qq.com","commits":3,"url":"https://github.com/bbhou"}]},"readingTime":{"minutes":15.22,"words":4567},"filePathRelative":"posts/ai/2024-02-20-ai-06-chatgpt-academic.md","excerpt":"\\n<h2>详细介绍一下 GPT 学术优化 (GPT Academic)</h2>\\n<hr>\\n<h1>GPT Academic</h1>\\n<p><strong>如果喜欢这个项目，请给它一个Star；如果您发明了好用的快捷键或插件，欢迎发pull requests！</strong></p>\\n<p>If you like this project, please give it a Star.<br>\\nRead this in <a href=\\"/awesome-ai-coding/posts/ai/docs/README.English.html\\" target=\\"_blank\\">English</a> | <a href=\\"/awesome-ai-coding/posts/ai/docs/README.Japanese.html\\" target=\\"_blank\\">日本語</a> | <a href=\\"/awesome-ai-coding/posts/ai/docs/README.Korean.html\\" target=\\"_blank\\">한국어</a> | <a href=\\"/awesome-ai-coding/posts/ai/docs/README.Russian.html\\" target=\\"_blank\\">Русский</a> | <a href=\\"/awesome-ai-coding/posts/ai/docs/README.French.html\\" target=\\"_blank\\">Français</a>. All translations have been provided by the project itself. To translate this project to arbitrary language with GPT, read and run <a href=\\"multi_language.py\\"><code>multi_language.py</code></a> (experimental).</p>","autoDesc":true}');export{m as comp,y as data};
