import{_ as i}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as a,a as s,o as r}from"./app-D4koU7iK.js";const e={};function n(l,t){return r(),a("div",null,[...t[0]||(t[0]=[s(`<h1 id="第12章-模型评估与调优" tabindex="-1"><a class="header-anchor" href="#第12章-模型评估与调优"><span>第12章　模型评估与调优</span></a></h1><p>再好的算法，也需要科学的评估与精细的调优。</p><p>机器学习模型不是一劳永逸的“公式”，而是一个需要不断验证、优化、取舍的系统。</p><p>本章将系统介绍：如何评价模型好坏、如何合理分配数据、如何找到最优参数组合，以及如何理解模型的“可靠性”。</p><h2 id="_12-1-交叉验证与数据划分策略" tabindex="-1"><a class="header-anchor" href="#_12-1-交叉验证与数据划分策略"><span><strong>12.1 交叉验证与数据划分策略</strong></span></a></h2><h3 id="🎯-1-为什么要划分数据" tabindex="-1"><a class="header-anchor" href="#🎯-1-为什么要划分数据"><span>🎯 1. 为什么要划分数据？</span></a></h3><p>机器学习的核心是“<strong>从已知数据学习规律，以预测未知数据</strong>”。<br> 如果用同一批数据训练又评估，就会出现“自我欣赏式高分”，无法反映真实能力。</p><p>因此要划分为不同集：</p><ul><li><strong>训练集（Train）</strong>：用于学习模型参数。</li><li><strong>验证集（Validation）</strong>：用于调参与模型选择。</li><li><strong>测试集（Test）</strong>：仅在最后评估模型泛化能力。</li></ul><p>常见比例：6:2:2 或 7:1.5:1.5。</p><hr><h3 id="🔁-2-交叉验证-cross-validation" tabindex="-1"><a class="header-anchor" href="#🔁-2-交叉验证-cross-validation"><span>🔁 2. 交叉验证（Cross-Validation）</span></a></h3><p>当数据量有限时，简单划分可能不稳定，这时我们用交叉验证。</p><p><strong>K 折交叉验证（K-Fold CV）</strong></p><ul><li>将数据分为 K 份；</li><li>每次用其中 1 份作验证集，剩下 K-1 份训练；</li><li>重复 K 次，取平均性能。</li></ul><p>示意：</p><table><thead><tr><th>轮次</th><th>训练集</th><th>验证集</th></tr></thead><tbody><tr><td>1</td><td>折 2~K</td><td>折 1</td></tr><tr><td>2</td><td>折 1,3~K</td><td>折 2</td></tr><tr><td>…</td><td>…</td><td>…</td></tr><tr><td>K</td><td>折 1~K-1</td><td>折 K</td></tr></tbody></table><p><strong>优点：</strong></p><ul><li>有效利用全部样本；</li><li>结果更稳定、泛化性强。</li></ul><p><strong>变体：</strong></p><ul><li><strong>Stratified K-Fold</strong>：保持类别比例一致（分类任务推荐）；</li><li><strong>Leave-One-Out (LOO)</strong>：每次留一个样本验证，适用于极少样本任务；</li><li><strong>Time Series Split</strong>：时间序列任务中按时间顺序分割，防止“未来信息泄露”。</li></ul><hr><h2 id="_12-2-分类指标-准确率、召回率、f1、auc" tabindex="-1"><a class="header-anchor" href="#_12-2-分类指标-准确率、召回率、f1、auc"><span><strong>12.2 分类指标（准确率、召回率、F1、AUC）</strong></span></a></h2><p>模型性能不止“一个数字”，尤其在不平衡数据集（如欺诈检测、医疗诊断）中，<strong>选择正确指标比高分更重要。</strong></p><hr><h3 id="📊-1-混淆矩阵-confusion-matrix" tabindex="-1"><a class="header-anchor" href="#📊-1-混淆矩阵-confusion-matrix"><span>📊 1. 混淆矩阵（Confusion Matrix）</span></a></h3><table><thead><tr><th>实际\\预测</th><th>正类</th><th>负类</th></tr></thead><tbody><tr><td>正类</td><td>TP（真正）</td><td>FN（假负）</td></tr><tr><td>负类</td><td>FP（假正）</td><td>TN（真负）</td></tr></tbody></table><hr><h3 id="✅-2-准确率-accuracy" tabindex="-1"><a class="header-anchor" href="#✅-2-准确率-accuracy"><span>✅ 2. 准确率（Accuracy）</span></a></h3><p>[<br> Accuracy = \\frac{TP + TN}{TP + TN + FP + FN}<br> ]<br> 适合类别平衡的数据；不平衡数据时会误导。</p><hr><h3 id="🔍-3-精确率-precision-与召回率-recall" tabindex="-1"><a class="header-anchor" href="#🔍-3-精确率-precision-与召回率-recall"><span>🔍 3. 精确率（Precision）与召回率（Recall）</span></a></h3><p>[<br> Precision = \\frac{TP}{TP + FP} \\quad<br> Recall = \\frac{TP}{TP + FN}<br> ]</p><ul><li><strong>Precision 高</strong> → 模型输出的“正例”更可信；</li><li><strong>Recall 高</strong> → 模型漏掉的“正例”更少。</li></ul><p>两者通常存在权衡。</p><hr><h3 id="⚖️-4-f1-分数-f1-score" tabindex="-1"><a class="header-anchor" href="#⚖️-4-f1-分数-f1-score"><span>⚖️ 4. F1 分数（F1-Score）</span></a></h3><p>综合 Precision 和 Recall：<br> [<br> F1 = 2 \\times \\frac{Precision \\times Recall}{Precision + Recall}<br> ]<br> 常用于二分类的综合指标。</p><hr><h3 id="💡-5-roc-曲线与-auc-area-under-curve" tabindex="-1"><a class="header-anchor" href="#💡-5-roc-曲线与-auc-area-under-curve"><span>💡 5. ROC 曲线与 AUC（Area Under Curve）</span></a></h3><ul><li><strong>ROC 曲线</strong>：以假正率 (FPR) 为横轴、真正率 (TPR) 为纵轴。</li><li><strong>AUC</strong>：ROC 曲线下的面积，越大代表模型越稳定。</li></ul><p><strong>直观理解：</strong></p><ul><li>AUC = 0.5 → 完全随机；</li><li>AUC = 1.0 → 完美分类器；</li><li>AUC &gt; 0.9 → 极佳模型。</li></ul><hr><h3 id="📈-6-其他指标补充" tabindex="-1"><a class="header-anchor" href="#📈-6-其他指标补充"><span>📈 6. 其他指标补充</span></a></h3><table><thead><tr><th>场景</th><th>指标</th><th>说明</th></tr></thead><tbody><tr><td>不平衡数据</td><td>PR 曲线、AUC-PR</td><td>正例稀少时比 ROC 更稳定</td></tr><tr><td>多分类</td><td>Macro / Micro F1</td><td>平均多个二分类结果</td></tr><tr><td>回归</td><td>MSE、MAE、R²</td><td>均方误差、绝对误差、拟合度</td></tr></tbody></table><hr><h2 id="_12-3-超参数调优-grid-search、bayesian-optimization" tabindex="-1"><a class="header-anchor" href="#_12-3-超参数调优-grid-search、bayesian-optimization"><span><strong>12.3 超参数调优（Grid Search、Bayesian Optimization）</strong></span></a></h2><p>模型有两种参数：</p><ul><li><strong>可学习参数</strong>（weights、bias）：模型通过训练自动学；</li><li><strong>超参数</strong>（hyperparameters）：人手动设定，如学习率、正则系数、树深度。</li></ul><p>调优的目标是：<strong>找到最优超参数组合，让验证集表现最佳。</strong></p><hr><h3 id="🔢-1-网格搜索-grid-search" tabindex="-1"><a class="header-anchor" href="#🔢-1-网格搜索-grid-search"><span>🔢 1. 网格搜索（Grid Search）</span></a></h3><p>遍历所有参数组合，选出最优。</p><p><strong>优点：</strong></p><ul><li>简单直接；</li><li>结果稳定。</li></ul><p><strong>缺点：</strong></p><ul><li>计算量爆炸；</li><li>无法处理连续参数。</li></ul><p><strong>示例：</strong></p><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-python"><span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">from</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> sklearn.model_selection </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> GridSearchCV</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">params </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> {</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;C&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">: [</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">0.1</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">1</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">10</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">], </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;kernel&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">: [</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;linear&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;rbf&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">]}</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">grid </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;"> GridSearchCV</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">SVC</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(), params, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">cv</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">5</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">grid.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">fit</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(X_train, y_train)</span></span>
<span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">print</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(grid.best_params_)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><hr><h3 id="🎲-2-随机搜索-random-search" tabindex="-1"><a class="header-anchor" href="#🎲-2-随机搜索-random-search"><span>🎲 2. 随机搜索（Random Search）</span></a></h3><p>随机抽样参数组合，往往能更快找到好结果。</p><blockquote><p>在高维空间中，随机 &gt; 穷举。</p></blockquote><hr><h3 id="🧠-3-贝叶斯优化-bayesian-optimization" tabindex="-1"><a class="header-anchor" href="#🧠-3-贝叶斯优化-bayesian-optimization"><span>🧠 3. 贝叶斯优化（Bayesian Optimization）</span></a></h3><p>通过**概率模型（如高斯过程）**建模“参数 → 性能”的关系，智能地选择下一个最有潜力的参数。</p><p>核心思想：</p><ol><li>用已有实验结果建一个 surrogate model；</li><li>计算“期望改进”（Expected Improvement）；</li><li>选出最可能带来性能提升的参数点；</li><li>迭代更新。</li></ol><p>代表工具：</p><ul><li>Optuna</li><li>Hyperopt</li><li>SMAC</li><li>Ray Tune</li></ul><p>💡 <em>Grid Search 像蛮力搜索，Bayesian Optimization 像聪明的科学实验。</em></p><hr><h2 id="_12-4-模型稳定性与可解释性" tabindex="-1"><a class="header-anchor" href="#_12-4-模型稳定性与可解释性"><span><strong>12.4 模型稳定性与可解释性</strong></span></a></h2><h3 id="🧩-1-模型稳定性-model-robustness" tabindex="-1"><a class="header-anchor" href="#🧩-1-模型稳定性-model-robustness"><span>🧩 1. 模型稳定性（Model Robustness）</span></a></h3><p>模型在不同样本、噪声、时间分布变化下的表现是否一致。</p><p><strong>常见问题：</strong></p><ul><li>训练集与生产环境分布漂移（Data Drift）</li><li>噪声敏感</li><li>对特征小扰动反应过度</li></ul><p><strong>提升方法：</strong></p><ul><li>使用正则化（L2、Dropout）</li><li>数据增强（Data Augmentation）</li><li>模型集成（Ensemble）</li><li>持续监控模型性能（ML Monitoring）</li></ul><hr><h3 id="🔍-2-模型可解释性-interpretability" tabindex="-1"><a class="header-anchor" href="#🔍-2-模型可解释性-interpretability"><span>🔍 2. 模型可解释性（Interpretability）</span></a></h3><p>在现实场景中（尤其是金融、医疗、法律），模型必须“能解释自己”。</p><p><strong>可解释性维度：</strong></p><ul><li><strong>全局解释</strong>：模型整体如何决策<br> （如特征重要性、决策路径）</li><li><strong>局部解释</strong>：单个样本为什么被预测为某类<br> （如 LIME、SHAP）</li></ul><p><strong>工具：</strong></p><ul><li>Feature Importance（基于树模型）</li><li>LIME（Local Interpretable Model-Agnostic Explanations）</li><li>SHAP（Shapley Additive Explanations）</li></ul><p>💡 <em>黑盒模型能预测，但白盒模型能赢得信任。</em></p><hr><h2 id="✅-本章小结" tabindex="-1"><a class="header-anchor" href="#✅-本章小结"><span>✅ 本章小结</span></a></h2><table><thead><tr><th>模块</th><th>目标</th><th>常见方法</th><th>关键意义</th></tr></thead><tbody><tr><td>数据划分</td><td>防止过拟合</td><td>Train/Val/Test, CV</td><td>评估真实泛化</td></tr><tr><td>分类指标</td><td>评价分类性能</td><td>Accuracy, F1, AUC</td><td>衡量优劣</td></tr><tr><td>超参调优</td><td>找到最优配置</td><td>Grid, Random, Bayesian</td><td>提升性能</td></tr><tr><td>稳定与解释</td><td>提高可靠性</td><td>LIME, SHAP, Drift检测</td><td>工业可用性</td></tr></tbody></table>`,91)])])}const p=i(e,[["render",n]]),o=JSON.parse('{"path":"/posts/ml/2025-11-03-12-ml-book-model-eval-and-opt.html","title":"第12章　模型评估与调优","lang":"zh-CN","frontmatter":{"title":"第12章　模型评估与调优","date":"2025-11-03T00:00:00.000Z","categories":["AI"],"tags":["ai","learn-note"],"published":true,"description":"第12章 模型评估与调优 再好的算法，也需要科学的评估与精细的调优。 机器学习模型不是一劳永逸的“公式”，而是一个需要不断验证、优化、取舍的系统。 本章将系统介绍：如何评价模型好坏、如何合理分配数据、如何找到最优参数组合，以及如何理解模型的“可靠性”。 12.1 交叉验证与数据划分策略 🎯 1. 为什么要划分数据？ 机器学习的核心是“从已知数据学习规...","head":[["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"第12章　模型评估与调优\\",\\"image\\":[\\"\\"],\\"datePublished\\":\\"2025-11-03T00:00:00.000Z\\",\\"dateModified\\":\\"2025-12-27T05:15:15.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"老马啸西风\\",\\"url\\":\\"https://houbb.github.io\\"}]}"],["meta",{"property":"og:url","content":"https://houbb.github.io/awesome-ai-coding/posts/ml/2025-11-03-12-ml-book-model-eval-and-opt.html"}],["meta",{"property":"og:site_name","content":"老马啸西风"}],["meta",{"property":"og:title","content":"第12章　模型评估与调优"}],["meta",{"property":"og:description","content":"第12章 模型评估与调优 再好的算法，也需要科学的评估与精细的调优。 机器学习模型不是一劳永逸的“公式”，而是一个需要不断验证、优化、取舍的系统。 本章将系统介绍：如何评价模型好坏、如何合理分配数据、如何找到最优参数组合，以及如何理解模型的“可靠性”。 12.1 交叉验证与数据划分策略 🎯 1. 为什么要划分数据？ 机器学习的核心是“从已知数据学习规..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2025-12-27T05:15:15.000Z"}],["meta",{"property":"article:tag","content":"learn-note"}],["meta",{"property":"article:tag","content":"ai"}],["meta",{"property":"article:published_time","content":"2025-11-03T00:00:00.000Z"}],["meta",{"property":"article:modified_time","content":"2025-12-27T05:15:15.000Z"}]]},"git":{"createdTime":1766812269000,"updatedTime":1766812515000,"contributors":[{"name":"bbhou","username":"bbhou","email":"1557740299@qq.com","commits":3,"url":"https://github.com/bbhou"}]},"readingTime":{"minutes":4.65,"words":1394},"filePathRelative":"posts/ml/2025-11-03-12-ml-book-model-eval-and-opt.md","excerpt":"\\n<p>再好的算法，也需要科学的评估与精细的调优。</p>\\n<p>机器学习模型不是一劳永逸的“公式”，而是一个需要不断验证、优化、取舍的系统。</p>\\n<p>本章将系统介绍：如何评价模型好坏、如何合理分配数据、如何找到最优参数组合，以及如何理解模型的“可靠性”。</p>\\n<h2><strong>12.1 交叉验证与数据划分策略</strong></h2>\\n<h3>🎯 1. 为什么要划分数据？</h3>\\n<p>机器学习的核心是“<strong>从已知数据学习规律，以预测未知数据</strong>”。<br>\\n如果用同一批数据训练又评估，就会出现“自我欣赏式高分”，无法反映真实能力。</p>\\n<p>因此要划分为不同集：</p>","autoDesc":true}');export{p as comp,o as data};
