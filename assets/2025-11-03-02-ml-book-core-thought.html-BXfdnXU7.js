import{_ as i}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as e,a as t,o as n}from"./app-C3GE2GkA.js";const l={};function s(r,a){return n(),e("div",null,[...a[0]||(a[0]=[t('<h1 id="机器学习的核心思想-从-人写规则-到-机器自己学" tabindex="-1"><a class="header-anchor" href="#机器学习的核心思想-从-人写规则-到-机器自己学"><span>机器学习的核心思想：从“人写规则”到“机器自己学”</span></a></h1><p>很多人第一次听到“机器学习”，脑子里都会浮现一个念头——这是不是某种黑盒魔法？</p><p>其实不是。</p><p>机器学习的本质是一种新的“做事方式”：它不靠人一条条写规则，而是让机器<strong>自己从数据里学规律</strong>。</p><p>理解了这个核心转变，你在做任何和 AI 有关的项目时，都会更清楚地知道，自己到底在调什么、该先解决什么。</p><hr><h2 id="一、从-规则编程-到-经验学习" tabindex="-1"><a class="header-anchor" href="#一、从-规则编程-到-经验学习"><span>一、从“规则编程”到“经验学习”</span></a></h2><p><strong>规则编程</strong>是老派思路。我们告诉计算机所有判断逻辑，比如：</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-"><span class="line"><span>如果 体温 &gt; 38°C 且 咳嗽，则 疑似感冒。</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>这类系统在规则清晰、情况有限的场景下很准，但问题是：<br> 现实世界的情况太多、太模糊，写不完、调不动。<br> 一个规则生效，另一个场景就崩了。</p><p>于是出现了<strong>经验学习</strong>。<br> 它的思路很简单：不再靠专家写规则，而是让模型从样本中自己归纳。<br> 你给它成千上万个“输入和结果”，它自己去学两者之间的关系。</p><p>说白了，机器学习不是让机器听命令，而是让机器“见多识广，自己悟道”。</p><p>为什么要做这个转变？<br> 因为当数据爆炸、算力充足后，让机器自己学，反而成了更高效的路径。<br> 它能自动捕捉复杂的模式，对噪声和变化的适应力也更强。</p><hr><h2 id="二、机器学习系统的五个基本构件" tabindex="-1"><a class="header-anchor" href="#二、机器学习系统的五个基本构件"><span>二、机器学习系统的五个基本构件</span></a></h2><p>一个成功的机器学习系统，通常由五块“地基”组成：</p><h3 id="_1-数据-data" tabindex="-1"><a class="header-anchor" href="#_1-数据-data"><span>1. 数据（Data）</span></a></h3><p>数据是模型的燃料。质量远比数量更重要。<br> 收集、清洗、标注、划分训练集和测试集——这些都决定了后续的上限。<br> 如果标签成本高，就考虑弱监督、半监督或者主动学习。</p><p>一句话：<strong>别盲目堆模型，先盯紧数据。</strong></p><h3 id="_2-表示-representation" tabindex="-1"><a class="header-anchor" href="#_2-表示-representation"><span>2. 表示（Representation）</span></a></h3><p>表示决定了机器“怎么看世界”。<br> 传统机器学习靠人工特征工程（例如统计量、TF-IDF），<br> 深度学习则让模型自动学特征（embedding、多层抽象）。</p><p>好的表示要能“抓住本质”——既区分得开，又不被噪声干扰。<br> 实际做法：先用简单特征跑个基线，再看是否值得上复杂模型。</p><h3 id="_3-目标-objective-loss" tabindex="-1"><a class="header-anchor" href="#_3-目标-objective-loss"><span>3. 目标（Objective / Loss）</span></a></h3><p>模型该学什么？要明确。<br> 分类问题用交叉熵、回归问题用 MSE，但关键是目标得符合业务逻辑。<br> 比如“错杀一个用户”和“放过一个坏单”代价不同，那 loss 函数就不能一刀切。</p><h3 id="_4-优化-optimization" tabindex="-1"><a class="header-anchor" href="#_4-优化-optimization"><span>4. 优化（Optimization）</span></a></h3><p>优化是训练模型的“发动机”。<br> 常见的优化器（SGD、Adam 等）都差不多，真正决定效果的是学习率和正则化。<br> 调学习率的过程，就像调咖啡浓度——太淡没劲，太浓苦得受不了。</p><h3 id="_5-评估-evaluation" tabindex="-1"><a class="header-anchor" href="#_5-评估-evaluation"><span>5. 评估（Evaluation）</span></a></h3><p>模型好不好，不看“准确率”这一个数。<br> 要根据任务选指标，比如 AUC、F1、Recall、RMSE。<br> 另外，建议每个模型都留一份“模型卡”：记录数据来源、参数、结果、局限性。<br> 以后出了问题，这张卡能救命。</p><hr><h2 id="三、偏差-方差权衡-模型的性格平衡术" tabindex="-1"><a class="header-anchor" href="#三、偏差-方差权衡-模型的性格平衡术"><span>三、偏差-方差权衡：模型的性格平衡术</span></a></h2><p>偏差和方差，是机器学习里最关键的一对概念。</p><ul><li><strong>偏差大</strong>：模型太死板，学不动（欠拟合）；</li><li><strong>方差大</strong>：模型太敏感，见啥都信（过拟合）。</li></ul><p>你可以把它想成学生：</p><ul><li>死记硬背、不会变通 → 偏差大；</li><li>临场乱发挥、看风使舵 → 方差大。</li></ul><p>好模型就像好学生：既能理解知识点，又不会乱套。</p><p>实操上：</p><ul><li>欠拟合就加特征、换复杂模型；</li><li>过拟合就加正则、早停、扩数据；</li><li>如果还不行，用集成方法（bagging）来降低方差。</li></ul><hr><h2 id="四、泛化与过拟合-别只在训练集里当学霸" tabindex="-1"><a class="header-anchor" href="#四、泛化与过拟合-别只在训练集里当学霸"><span>四、泛化与过拟合：别只在训练集里当学霸</span></a></h2><p>模型的真正水平，看的是“泛化能力”——<br> 也就是它在没见过的数据上表现如何。</p><p><strong>过拟合</strong>的模型，在训练集上是学霸，在新数据上就翻车。<br> 它把训练数据的噪声都背下来了，结果一换环境就不行。</p><p>常见识别方法：</p><ul><li>训练损失一路降，但验证损失反而升；</li><li>训练集表现太好，测试集惨不忍睹；</li><li>数据少、模型太复杂时尤其明显。</li></ul><p>防过拟合的常用做法：</p><ol><li>多收数据；</li><li>数据增强（旋转、替换、抖动等）；</li><li>正则化（L1/L2、dropout、early stopping）；</li><li>模型简化；</li><li>集成学习；</li><li>定期监控“概念漂移”——数据分布随时间变了，模型也要更新。</li></ol><h2 id="五、小结" tabindex="-1"><a class="header-anchor" href="#五、小结"><span>五、小结</span></a></h2><p>机器学习的核心逻辑，其实就这几条：</p><ol><li>从“人写规则”到“机器自己学经验”，这是本质的范式转变；</li><li>数据、表示、目标、优化、评估，是任何模型的五根支柱；</li><li>偏差和方差的平衡，决定模型的最终水平；</li><li>过拟合是常态，学会识别和控制它；</li><li>向人类学习的方向发展——少样本、会迁移、有常识——是机器学习的未来。</li></ol><h1 id="第2章-机器学习的核心思想" tabindex="-1"><a class="header-anchor" href="#第2章-机器学习的核心思想"><span>第2章 机器学习的核心思想</span></a></h1><p>机器学习不是一堆黑盒魔法，而是一套明确的工程与科学范式。</p><p>掌握其核心思想，能让你在复杂项目中少走弯路、把握正确设计与调试的优先级。</p><p>本章讨论从“规则编程”到“经验学习”的范式转变，揭示一套通用的建模五要素，讲清偏差-方差权衡、泛化与过拟合，并把机器学习与人类学习做对比，帮助读者建立直观且可操作的思维框架。</p><hr><h2 id="_2-1-从-规则编程-到-经验学习" tabindex="-1"><a class="header-anchor" href="#_2-1-从-规则编程-到-经验学习"><span>2.1 从“规则编程”到“经验学习”</span></a></h2><h3 id="什么是规则编程" tabindex="-1"><a class="header-anchor" href="#什么是规则编程"><span>什么是规则编程？</span></a></h3><p>规则编程（Rule-based programming）指由人类专家直接编写“如果——那么”规则来处理问题。例如：</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-"><span class="line"><span>如果 体温 &gt; 38°C 且 咳嗽，则 疑似感冒。</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>优点：解释性强、对已知、确定的规则非常准确；缺点：穷举困难、遇到模糊/噪声数据很脆弱、无法自适应新情况。</p><h3 id="什么是经验学习-数据驱动" tabindex="-1"><a class="header-anchor" href="#什么是经验学习-数据驱动"><span>什么是经验学习（数据驱动）？</span></a></h3><p>经验学习把“规则”替换为从数据中统计和归纳出来的映射。目标不是写规则，而是给模型大量“示例”，让模型学出隐含规则：</p><ul><li>输入：历史样本（features）</li><li>输出：观察到的标签或信号（targets）</li><li>学习目标：找到一个在未见样本上也能做出合理预测的映射函数 (f: X \\to Y)。</li></ul><h3 id="两者的对比-直观" tabindex="-1"><a class="header-anchor" href="#两者的对比-直观"><span>两者的对比（直观）</span></a></h3><ul><li>规则编程：明确、可控、昂贵（需要专家）</li><li>经验学习：可扩展、适应力强、依赖数据质量</li></ul><h3 id="为什么会发生范式转变" tabindex="-1"><a class="header-anchor" href="#为什么会发生范式转变"><span>为什么会发生范式转变？</span></a></h3><ul><li>规则方法随问题复杂度爆炸性增加而不可持续。</li><li>数据大量涌现 + 计算资源提升，使得“从数据学习”成为更有效的工程路径。</li><li>经验学习能自动捕捉复杂的统计关联，适合处理噪声、多样性大的现实世界数据。</li></ul><hr><h2 id="_2-2-学习系统的五要素-数据、表示、目标、优化、评估" tabindex="-1"><a class="header-anchor" href="#_2-2-学习系统的五要素-数据、表示、目标、优化、评估"><span>2.2 学习系统的五要素：数据、表示、目标、优化、评估</span></a></h2><p>成功的机器学习系统可以拆成五个核心构件——理解并设计好每一块，模型的表现通常会成倍提升。</p><h3 id="_1-数据-data-1" tabindex="-1"><a class="header-anchor" href="#_1-数据-data-1"><span>1) 数据（Data）</span></a></h3><ul><li><p>数据就是学习的燃料：质量重于数量。</p></li><li><p>关键任务：收集、清洗、标注、构建训练/验证/测试集、处理偏差（sampling bias）。</p></li><li><p>实工程指引：</p><ul><li>明确标签来源与质量；</li><li>查看标签偏差、缺失分布、时间分布（是否存在概念漂移）；</li><li>若标签昂贵，优先考虑弱监督、半监督或 active learning。</li></ul></li></ul><h3 id="_2-表示-representation-1" tabindex="-1"><a class="header-anchor" href="#_2-表示-representation-1"><span>2) 表示（Representation）</span></a></h3><ul><li><p>表示决定信息如何呈现给模型：传统 ML 强调<strong>特征工程</strong>（TF-IDF、统计量、手工交叉项）；深度学习强调<strong>学习表示</strong>（embeddings、卷积特征、多层抽象）。</p></li><li><p>好的表示具有：判别性、紧凑性、稳健性（对噪声不敏感）、可迁移性（在相关任务上复用）。</p></li><li><p>工程实践：</p><ul><li>先做简单但强的手工特征（均值/方差、滞后项、one-hot、WOE）；</li><li>对文本/图像用预训练 embedding 先试验，再考虑端到端训练。</li></ul></li></ul><h3 id="_3-目标-objective-loss-1" tabindex="-1"><a class="header-anchor" href="#_3-目标-objective-loss-1"><span>3) 目标（Objective / Loss）</span></a></h3><ul><li>明确你希望模型学会什么（回归 MSE、分类交叉熵、排序 loss、定制业务损失）。</li><li>目标决定优化方向，若业务成本不对称（假阳性/假阴性代价不同），目标函数要反映该成本（cost-sensitive learning）。</li></ul><h3 id="_4-优化-optimization-1" tabindex="-1"><a class="header-anchor" href="#_4-优化-optimization-1"><span>4) 优化（Optimization）</span></a></h3><ul><li>优化器是把目标最小化的算法：常见有 GD、SGD、Momentum、Adam、L-BFGS 等。</li><li>实务重点：学习率与学习率调度通常比选择优化器更重要，良好的初始化、批量大小和正则化（weight decay、dropout）也至关重要。</li></ul><h3 id="_5-评估-evaluation-1" tabindex="-1"><a class="header-anchor" href="#_5-评估-evaluation-1"><span>5) 评估（Evaluation）</span></a></h3><ul><li>用恰当的指标来衡量性能：不要只看准确率。</li><li>指标选择要与业务目标一致：AUC、Precision@K、Recall、F1、MAP、RMSE、MAE、NDCG 等。</li><li>验证策略：留出法、交叉验证（K-fold）、时间序列的时间切分（rolling window）。</li><li>实务建议：做模型卡（model card），记录数据分布、训练过程、版本、最终性能与已知局限。</li></ul><hr><h2 id="_2-3-偏差–方差权衡-bias–variance-tradeoff" tabindex="-1"><a class="header-anchor" href="#_2-3-偏差–方差权衡-bias–variance-tradeoff"><span>2.3 偏差–方差权衡（Bias–Variance Tradeoff）</span></a></h2><p>偏差-方差权衡是机器学习中解释泛化行为的一个核心概念。</p><h3 id="基本概念" tabindex="-1"><a class="header-anchor" href="#基本概念"><span>基本概念</span></a></h3><p>对于某个输入 (x)，模型的预测误差可以分解为三部分（回归和平方误差设定下）：<br> [<br> \\mathbb{E}[(\\hat{f}(x)-y)^2] = \\underbrace{(\\mathbb{E}[\\hat{f}(x)] - f(x))<sup>2}*{\\text{偏差（Bias）}</sup>2} + \\underbrace{\\mathbb{E}[(\\hat{f}(x) - \\mathbb{E}[\\hat{f}(x)])^2]}*{\\text{方差（Variance）}} + \\underbrace{\\sigma^2}_{\\text{噪声（Irreducible noise）}<br> }<br> ]</p><ul><li><strong>偏差（Bias）</strong>：模型的期望预测与真实函数 (f(x)) 的差距。偏差大通常意味着模型过于简单（欠拟合）。</li><li><strong>方差（Variance）</strong>：不同训练集下模型预测的变动性。方差大通常意味着模型过于复杂（过拟合）。</li><li><strong>不可约噪声（Noise）</strong>：数据本身无法被模型解释的随机性。</li></ul><h3 id="直观理解" tabindex="-1"><a class="header-anchor" href="#直观理解"><span>直观理解</span></a></h3><ul><li>简单模型（线性回归）→ 偏差高、方差低。</li><li>复杂模型（深度网络、深树）→ 偏差低、方差高。<br> 目标是找到能使两者综合误差最低的模型复杂度。</li></ul><h3 id="工程上的权衡技巧" tabindex="-1"><a class="header-anchor" href="#工程上的权衡技巧"><span>工程上的权衡技巧</span></a></h3><ul><li><strong>如果欠拟合（偏差大）</strong>：增加模型能力（更复杂模型、增加特征、更多训练数据、降低正则化强度）。</li><li><strong>如果过拟合（方差大）</strong>：增加正则化（L1/L2、dropout）、更多数据、早停（early stopping）、使用更简单模型、模型集成（bagging能降低方差）。</li><li><strong>正则化与特征选择</strong>：L1 有助于稀疏特征选择，L2 控制权重大小；树模型天然有正则化手段（树深、叶节点最小样本数）。</li></ul><hr><h2 id="_2-4-泛化能力与过拟合" tabindex="-1"><a class="header-anchor" href="#_2-4-泛化能力与过拟合"><span>2.4 泛化能力与过拟合</span></a></h2><h3 id="泛化-generalization" tabindex="-1"><a class="header-anchor" href="#泛化-generalization"><span>泛化（Generalization）</span></a></h3><p>泛化指模型在未见数据上的表现好坏。一个泛化良好的模型能把训练中学到的规律稳健地应用到新样本上。</p><h3 id="过拟合-overfitting" tabindex="-1"><a class="header-anchor" href="#过拟合-overfitting"><span>过拟合（Overfitting）</span></a></h3><p>模型过度拟合训练数据（包括噪声或偶然性模式），以至于在测试集上表现差。过拟合表现在训练误差低而验证或测试误差高。</p><h3 id="识别过拟合的实用信号" tabindex="-1"><a class="header-anchor" href="#识别过拟合的实用信号"><span>识别过拟合的实用信号</span></a></h3><ul><li>训练损失持续下降，但验证损失在某点后回升。</li><li>模型在训练集上的性能远好于在验证集/测试集上的性能。</li><li>在高维稀疏数据中，复杂模型容易记忆噪声。</li></ul><h3 id="常见防止过拟合的方法-实践清单" tabindex="-1"><a class="header-anchor" href="#常见防止过拟合的方法-实践清单"><span>常见防止过拟合的方法（实践清单）</span></a></h3><ol><li><strong>更多数据</strong>：最直接也是最有效的方法。</li><li><strong>数据增强（Data Augmentation）</strong>：图像旋转、翻转、颜色扰动；文本同义替换；时间序列的抖动/切片。</li><li><strong>正则化</strong>：L1/L2、dropout、early stopping、数据噪声注入。</li><li><strong>简化模型</strong>：减少层数/节点数、树深度限制。</li><li><strong>交叉验证</strong>：用 K-fold 等估计模型稳定性与泛化误差。</li><li><strong>集成方法</strong>：bagging 降低方差、boosting 降低偏差（但需注意boosting可能过拟合小噪声）。</li><li><strong>特征工程</strong>：选择合适的特征，移除信息泄露（leakage）来源。</li><li><strong>校准（Calibration）</strong>：对概率输出做校准（例如 Platt scaling、Isotonic regression）（与过拟合相关的概率失真问题）。</li></ol><h3 id="概念漂移-concept-drift" tabindex="-1"><a class="header-anchor" href="#概念漂移-concept-drift"><span>概念漂移（Concept Drift）</span></a></h3><p>在生产环境中，数据分布可能随时间变化（例如用户行为变化、市场变化），即便模型训练时泛化良好，也可能随时间失效。对策包括：</p><ul><li>定期重训或在线学习；</li><li>监控输入特征与输出分布的漂移（数据漂移检测）；</li><li>使用可自适应的模型或增量学习策略。</li></ul><hr><h2 id="_2-5-机器学习与人类学习的异同" tabindex="-1"><a class="header-anchor" href="#_2-5-机器学习与人类学习的异同"><span>2.5 机器学习与人类学习的异同</span></a></h2><h3 id="相似点" tabindex="-1"><a class="header-anchor" href="#相似点"><span>相似点</span></a></h3><ul><li><strong>从经验中学习</strong>：两者都依赖示例和反馈（人类通过监督/经验学习，机器通过训练数据和标签）。</li><li><strong>抽象与概念形成</strong>：人和机器都能从具体样本中抽象出一般规律（人类会形成概念类，机器会学习到判别边界或高维表示）。</li><li><strong>迁移能力</strong>：人类擅长将已学知识迁移到新任务，现代 ML 也在通过迁移学习、预训练模型实现类似能力。</li></ul><h3 id="不同点" tabindex="-1"><a class="header-anchor" href="#不同点"><span>不同点</span></a></h3><table><thead><tr><th>维度</th><th>人类学习</th><th>机器学习</th></tr></thead><tbody><tr><td>样本效率</td><td>极高（少量示例即可学会）</td><td>通常低（需大量数据）</td></tr><tr><td>常识与世界模型</td><td>拥有丰富常识与因果理解</td><td>主要基于统计相关性，常识缺失</td></tr><tr><td>强化学习 / 想象</td><td>人类能用推理、想象来补充数据</td><td>机器弱，需专门设计推理模块或模拟器</td></tr><tr><td>忘却与持续学习</td><td>人类可持续整合新知识且不会简单丢失旧知识（有遗忘但更灵活）</td><td>机器易遭“灾难性遗忘”需专门方法（如经验回放、正则化）</td></tr><tr><td>可解释性</td><td>人类能用语言解释原因</td><td>机器（尤其深模型）解释困难，除非有可解释性工具</td></tr></tbody></table><h3 id="对机器学习的启示-从认知科学借鉴" tabindex="-1"><a class="header-anchor" href="#对机器学习的启示-从认知科学借鉴"><span>对机器学习的启示（从认知科学借鉴）</span></a></h3><ul><li><strong>样本效率的改进</strong>：引入元学习（meta-learning）、few-shot/one-shot 学习、因果推断来提高效率。</li><li><strong>融入先验知识</strong>：结合符号规则、知识图谱或物理约束能提高可靠性（hybrid models）。</li><li><strong>终生学习</strong>：设计增量学习、避免灾难性遗忘，使模型能像人那样持续学习。</li></ul><hr><h2 id="小结与工程清单" tabindex="-1"><a class="header-anchor" href="#小结与工程清单"><span>小结与工程清单</span></a></h2><h3 id="本章要点回顾" tabindex="-1"><a class="header-anchor" href="#本章要点回顾"><span>本章要点回顾</span></a></h3><ul><li>机器学习是从“人写规则”到“机器从数据学规则”的范式转变。</li><li>成功的学习系统由五个要素构成：数据、表示、目标、优化、评估。</li><li>偏差-方差权衡是理解泛化的核心；工程上通过正则化、数据增强、模型复杂度控制来平衡。</li><li>过拟合是常态，识别与缓解过拟合是工程师的必备技能。</li><li>机器和人类在学习机制上既有相似也有根本差别，向人类学习的优点（常识、样本效率）是 ML 重要研究方向。</li></ul><h3 id="可操作的实践检查表-做模型前" tabindex="-1"><a class="header-anchor" href="#可操作的实践检查表-做模型前"><span>可操作的实践检查表（做模型前）</span></a></h3><ol><li>数据：是否有代表性？是否存在漏标/偏差？是否需要分层抽样？</li><li>表示：试验简单强基线特征（统计特征/one-hot/embeddings）后再做复杂表示。</li><li>目标：业务损失是否映射到训练 loss？是否需要不对称代价？</li><li>优化：设置学习率/批量大小，监控训练/验证曲线；启用早停。</li><li>评估：选好指标、做交叉验证、做模型卡记录实验。</li><li>泛化检查：做错误分析、画学习曲线（train/val 随样本数走势），判断是偏差还是方差问题。</li></ol>',115)])])}const p=i(l,[["render",s]]),d=JSON.parse('{"path":"/posts/ml/2025-11-03-02-ml-book-core-thought.html","title":"dive-into-llms-112-第2章 机器学习的核心思想","lang":"zh-CN","frontmatter":{"title":"dive-into-llms-112-第2章 机器学习的核心思想","date":"2025-11-03T00:00:00.000Z","categories":["AI"],"tags":["ai","learn-note"],"published":true,"description":"机器学习的核心思想：从“人写规则”到“机器自己学” 很多人第一次听到“机器学习”，脑子里都会浮现一个念头——这是不是某种黑盒魔法？ 其实不是。 机器学习的本质是一种新的“做事方式”：它不靠人一条条写规则，而是让机器自己从数据里学规律。 理解了这个核心转变，你在做任何和 AI 有关的项目时，都会更清楚地知道，自己到底在调什么、该先解决什么。 一、从“规则...","head":[["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"dive-into-llms-112-第2章 机器学习的核心思想\\",\\"image\\":[\\"\\"],\\"datePublished\\":\\"2025-11-03T00:00:00.000Z\\",\\"dateModified\\":\\"2025-12-27T05:15:15.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"老马啸西风\\",\\"url\\":\\"https://houbb.github.io\\"}]}"],["meta",{"property":"og:url","content":"https://houbb.github.io/awesome-ai-coding/posts/ml/2025-11-03-02-ml-book-core-thought.html"}],["meta",{"property":"og:site_name","content":"老马啸西风"}],["meta",{"property":"og:title","content":"dive-into-llms-112-第2章 机器学习的核心思想"}],["meta",{"property":"og:description","content":"机器学习的核心思想：从“人写规则”到“机器自己学” 很多人第一次听到“机器学习”，脑子里都会浮现一个念头——这是不是某种黑盒魔法？ 其实不是。 机器学习的本质是一种新的“做事方式”：它不靠人一条条写规则，而是让机器自己从数据里学规律。 理解了这个核心转变，你在做任何和 AI 有关的项目时，都会更清楚地知道，自己到底在调什么、该先解决什么。 一、从“规则..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2025-12-27T05:15:15.000Z"}],["meta",{"property":"article:tag","content":"learn-note"}],["meta",{"property":"article:tag","content":"ai"}],["meta",{"property":"article:published_time","content":"2025-11-03T00:00:00.000Z"}],["meta",{"property":"article:modified_time","content":"2025-12-27T05:15:15.000Z"}]]},"git":{"createdTime":1766812269000,"updatedTime":1766812515000,"contributors":[{"name":"bbhou","username":"bbhou","email":"1557740299@qq.com","commits":3,"url":"https://github.com/bbhou"}]},"readingTime":{"minutes":13.4,"words":4020},"filePathRelative":"posts/ml/2025-11-03-02-ml-book-core-thought.md","excerpt":"\\n<p>很多人第一次听到“机器学习”，脑子里都会浮现一个念头——这是不是某种黑盒魔法？</p>\\n<p>其实不是。</p>\\n<p>机器学习的本质是一种新的“做事方式”：它不靠人一条条写规则，而是让机器<strong>自己从数据里学规律</strong>。</p>\\n<p>理解了这个核心转变，你在做任何和 AI 有关的项目时，都会更清楚地知道，自己到底在调什么、该先解决什么。</p>\\n<hr>\\n<h2>一、从“规则编程”到“经验学习”</h2>\\n<p><strong>规则编程</strong>是老派思路。我们告诉计算机所有判断逻辑，比如：</p>\\n<div class=\\"language- line-numbers-mode\\" data-highlighter=\\"shiki\\" data-ext=\\"\\" style=\\"--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34\\"><pre class=\\"shiki shiki-themes one-light one-dark-pro vp-code\\"><code class=\\"language-\\"><span class=\\"line\\"><span>如果 体温 &gt; 38°C 且 咳嗽，则 疑似感冒。</span></span></code></pre>\\n<div class=\\"line-numbers\\" aria-hidden=\\"true\\" style=\\"counter-reset:line-number 0\\"><div class=\\"line-number\\"></div></div></div>","autoDesc":true}');export{p as comp,d as data};
