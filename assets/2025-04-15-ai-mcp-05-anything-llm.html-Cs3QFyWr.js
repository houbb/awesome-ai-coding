import{_ as i}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as p,a as t,b as r,f as o,w as l,e as a,r as h,o as s}from"./app-B0et4AS6.js";const g={};function c(b,e){const n=h("RouteLink");return s(),p("div",null,[e[5]||(e[5]=t('<h1 id="ai-mcp-系列" tabindex="-1"><a class="header-anchor" href="#ai-mcp-系列"><span>AI MCP 系列</span></a></h1><p><a href="https://houbb.github.io/2025/04/03/ai-brower-agent-01-agentGPT" target="_blank" rel="noopener noreferrer">AgentGPT-01-入门介绍</a></p><p><a href="https://houbb.github.io/2025/04/03/ai-brower-agent-02-browser-use" target="_blank" rel="noopener noreferrer">Browser-use 是连接你的AI代理与浏览器的最简单方式</a></p><p><a href="https://houbb.github.io/2025/04/15/ai-mcp-01-intro" target="_blank" rel="noopener noreferrer">AI MCP(大模型上下文)-01-入门介绍</a></p><p><a href="https://houbb.github.io/2025/04/15/ai-mcp-02-awesome-servers" target="_blank" rel="noopener noreferrer">AI MCP(大模型上下文)-02-awesome-mcp-servers 精选的 MCP 服务器</a></p><p><a href="https://houbb.github.io/2025/04/15/ai-mcp-03-open-webui" target="_blank" rel="noopener noreferrer">AI MCP(大模型上下文)-03-open webui 介绍 是一个可扩展、功能丰富且用户友好的本地部署 AI 平台，支持完全离线运行。</a></p><p><a href="https://houbb.github.io/2025/04/15/ai-mcp-04-n8n" target="_blank" rel="noopener noreferrer">AI MCP(大模型上下文)-04-n8n 为技术团队打造的安全工作流自动化平台</a></p><p><a href="https://houbb.github.io/2025/04/15/ai-mcp-05-anything-llm" target="_blank" rel="noopener noreferrer">AI MCP(大模型上下文)-05-anything-llm AnythingLLM 您一直在寻找的全方位AI应用程序</a></p><p><a href="https://houbb.github.io/2025/04/15/ai-mcp-06-maxkb" target="_blank" rel="noopener noreferrer">AI MCP(大模型上下文)-06-maxkb 强大易用的企业级 AI 助手</a></p><p><a href="https://houbb.github.io/2025/04/15/ai-mcp-07-dify-intro" target="_blank" rel="noopener noreferrer">AI MCP(大模型上下文)-07-dify 入门介绍</a></p><p><a href="https://houbb.github.io/2025/04/15/ai-mcp-08-awesome-dify-workflow" target="_blank" rel="noopener noreferrer">AI MCP(大模型上下文)-08-分享一些好用的 Dify DSL 工作流程</a></p><p><a href="https://houbb.github.io/2025/04/15/ai-mcp-09-difyaia" target="_blank" rel="noopener noreferrer">AI MCP(大模型上下文)-09-基于Dify自主创建的AI应用DSL工作流</a></p><p><a href="https://houbb.github.io/2025/04/15/ai-mcp-10-activepieces" target="_blank" rel="noopener noreferrer">AI MCP(大模型上下文)-10-Activepieces 一个开源的 Zapier 替代方案</a></p><p><a href="https://houbb.github.io/2025/04/15/ai-mcp-11-playwright-mcp" target="_blank" rel="noopener noreferrer">AI MCP(大模型上下文)-11-微软 Playwright MCP server</a></p><p><a href="https://houbb.github.io/2025/04/15/ai-mcp-12-aws-mcp" target="_blank" rel="noopener noreferrer">AI MCP(大模型上下文)-12-AWS MCP</a></p><p><a href="https://houbb.github.io/2025/04/15/ai-mcp-13-github-mcp" target="_blank" rel="noopener noreferrer">AI MCP(大模型上下文)-13-github MCP</a></p><h1 id="anythingllm-您一直在寻找的全方位ai应用程序。" tabindex="-1"><a class="header-anchor" href="#anythingllm-您一直在寻找的全方位ai应用程序。"><span>AnythingLLM 您一直在寻找的全方位AI应用程序。</span></a></h1><p>与您的文档聊天，使用AI代理，高度可配置，多用户，无需繁琐的设置。</p><p>适用于桌面（Mac、Windows和Linux）的AnythingLLM！</p><p>这是一个全栈应用程序，可以将任何文档、资源（如网址链接、音频、视频）或内容片段转换为上下文，以便任何大语言模型（LLM）在聊天期间作为参考使用。此应用程序允许您选择使用哪个LLM或向量数据库，同时支持多用户管理并设置不同权限。</p><h3 id="产品概览" tabindex="-1"><a class="header-anchor" href="#产品概览"><span>产品概览</span></a></h3><p>AnythingLLM是一个全栈应用程序，您可以使用现成的商业大语言模型或流行的开源大语言模型，再结合向量数据库解决方案构建一个私有ChatGPT，不再受制于人：您可以本地运行，也可以远程托管，并能够与您提供的任何文档智能聊天。</p><p>AnythingLLM将您的文档划分为称为<code>workspaces</code> (工作区)的对象。</p><p>工作区的功能类似于线程，同时增加了文档的容器化。工作区可以共享文档，但工作区之间的内容不会互相干扰或污染，因此您可以保持每个工作区的上下文清晰。</p><h2 id="anythingllm的一些酷炫特性" tabindex="-1"><a class="header-anchor" href="#anythingllm的一些酷炫特性"><span>AnythingLLM的一些酷炫特性</span></a></h2><ul><li>🆕 <a href="https://docs.anythingllm.com/agent/custom/introduction" target="_blank" rel="noopener noreferrer"><strong>自定义AI代理</strong></a></li><li>🆕 <a href="https://docs.anythingllm.com/agent-flows/overview" target="_blank" rel="noopener noreferrer"><strong>无代码AI代理构建器</strong></a></li><li>🖼️ <strong>多用户实例支持和权限管理（支持封闭源和开源LLM！）</strong></li><li>👤 多用户实例支持和权限管理 <em>仅限Docker版本</em></li><li>🦾 工作区内的智能体Agent（浏览网页、运行代码等）</li><li>💬 <a href="https://github.com/Mintplex-Labs/anythingllm-embed/blob/main/README.md" target="_blank" rel="noopener noreferrer">为您的网站定制的可嵌入聊天窗口</a></li><li>📖 支持多种文档类型（PDF、TXT、DOCX等）</li><li>通过简单的用户界面管理向量数据库中的文档</li><li>两种对话模式：<code>聊天</code>和<code>查询</code>。聊天模式保留先前的对话记录。查询模式则是针对您的文档做简单问答</li><li>聊天中会提供所引用的相应文档内容</li><li>100%云部署就绪。</li><li>“部署你自己的LLM模型”。</li><li>管理超大文档时高效、低耗。只需要一次就可以嵌入（Embedding）一个庞大的文档或文字记录。比其他文档聊天机器人解决方案节省90%的成本。</li><li>全套的开发人员API，用于自定义集成！</li></ul><h3 id="支持的llm、嵌入模型、转录模型和向量数据库" tabindex="-1"><a class="header-anchor" href="#支持的llm、嵌入模型、转录模型和向量数据库"><span>支持的LLM、嵌入模型、转录模型和向量数据库</span></a></h3><p><strong>支持的LLM：</strong></p>',28)),r("ul",null,[r("li",null,[o(n,{to:"/server/storage/models/#text-generation-llm-selection"},{default:l(()=>[...e[0]||(e[0]=[a("任何与llama.cpp兼容的开源模型",-1)])]),_:1})]),e[1]||(e[1]=t('<li><a href="https://openai.com" target="_blank" rel="noopener noreferrer">OpenAI</a></li><li><a href="https://openai.com" target="_blank" rel="noopener noreferrer">OpenAI (通用)</a></li><li><a href="https://azure.microsoft.com/en-us/products/ai-services/openai-service" target="_blank" rel="noopener noreferrer">Azure OpenAI</a></li><li><a href="https://www.anthropic.com/" target="_blank" rel="noopener noreferrer">Anthropic</a></li><li><a href="https://ai.google.dev/" target="_blank" rel="noopener noreferrer">Google Gemini Pro</a></li><li><a href="https://huggingface.co/" target="_blank" rel="noopener noreferrer">Hugging Face (聊天模型)</a></li><li><a href="https://ollama.ai/" target="_blank" rel="noopener noreferrer">Ollama (聊天模型)</a></li><li><a href="https://lmstudio.ai" target="_blank" rel="noopener noreferrer">LM Studio (所有模型)</a></li><li><a href="https://localai.io/" target="_blank" rel="noopener noreferrer">LocalAi (所有模型)</a></li><li><a href="https://www.together.ai/" target="_blank" rel="noopener noreferrer">Together AI (聊天模型)</a></li><li><a href="https://fireworks.ai/" target="_blank" rel="noopener noreferrer">Fireworks AI (聊天模型)</a></li><li><a href="https://www.perplexity.ai/" target="_blank" rel="noopener noreferrer">Perplexity (聊天模型)</a></li><li><a href="https://openrouter.ai/" target="_blank" rel="noopener noreferrer">OpenRouter (聊天模型)</a></li><li><a href="https://novita.ai/model-api/product/llm-api?utm_source=github_anything-llm&amp;utm_medium=github_readme&amp;utm_campaign=link" target="_blank" rel="noopener noreferrer">Novita AI (聊天模型)</a></li><li><a href="https://mistral.ai/" target="_blank" rel="noopener noreferrer">Mistral</a></li><li><a href="https://groq.com/" target="_blank" rel="noopener noreferrer">Groq</a></li><li><a href="https://cohere.com/" target="_blank" rel="noopener noreferrer">Cohere</a></li><li><a href="https://github.com/LostRuins/koboldcpp" target="_blank" rel="noopener noreferrer">KoboldCPP</a></li><li><a href="https://ppinfra.com?utm_source=github_anything-llm" target="_blank" rel="noopener noreferrer">PPIO (聊天模型)</a></li>',19))]),e[6]||(e[6]=r("p",null,[r("strong",null,"支持的嵌入模型：")],-1)),r("ul",null,[r("li",null,[o(n,{to:"/server/storage/models/"},{default:l(()=>[...e[2]||(e[2]=[a("AnythingLLM原生嵌入器",-1)])]),_:1}),e[3]||(e[3]=a("（默认）",-1))]),e[4]||(e[4]=t('<li><a href="https://openai.com" target="_blank" rel="noopener noreferrer">OpenAI</a></li><li><a href="https://azure.microsoft.com/en-us/products/ai-services/openai-service" target="_blank" rel="noopener noreferrer">Azure OpenAI</a></li><li><a href="https://localai.io/" target="_blank" rel="noopener noreferrer">LocalAi (全部)</a></li><li><a href="https://ollama.ai/" target="_blank" rel="noopener noreferrer">Ollama (全部)</a></li><li><a href="https://lmstudio.ai" target="_blank" rel="noopener noreferrer">LM Studio (全部)</a></li><li><a href="https://cohere.com/" target="_blank" rel="noopener noreferrer">Cohere</a></li>',6))]),e[7]||(e[7]=t('<p><strong>支持的转录模型：</strong></p><ul><li><a href="https://github.com/Mintplex-Labs/anything-llm/tree/master/server/storage/models#audiovideo-transcription" target="_blank" rel="noopener noreferrer">AnythingLLM内置</a> （默认）</li><li><a href="https://openai.com/" target="_blank" rel="noopener noreferrer">OpenAI</a></li></ul><p><strong>TTS (文本转语音) 支持：</strong></p><ul><li>浏览器内置（默认）</li><li><a href="https://github.com/rhasspy/piper" target="_blank" rel="noopener noreferrer">PiperTTSLocal - 在浏览器中运行</a></li><li><a href="https://platform.openai.com/docs/guides/text-to-speech/voice-options" target="_blank" rel="noopener noreferrer">OpenAI TTS</a></li><li><a href="https://elevenlabs.io/" target="_blank" rel="noopener noreferrer">ElevenLabs</a></li><li>任何与 OpenAI 兼容的 TTS 服务</li></ul><p><strong>STT (语音转文本) 支持：</strong></p><ul><li>浏览器内置（默认）</li></ul><p><strong>支持的向量数据库：</strong></p><ul><li><a href="https://github.com/lancedb/lancedb" target="_blank" rel="noopener noreferrer">LanceDB</a> （默认）</li><li><a href="https://www.datastax.com/products/datastax-astra" target="_blank" rel="noopener noreferrer">Astra DB</a></li><li><a href="https://pinecone.io" target="_blank" rel="noopener noreferrer">Pinecone</a></li><li><a href="https://trychroma.com" target="_blank" rel="noopener noreferrer">Chroma</a></li><li><a href="https://weaviate.io" target="_blank" rel="noopener noreferrer">Weaviate</a></li><li><a href="https://qdrant.tech" target="_blank" rel="noopener noreferrer">QDrant</a></li><li><a href="https://milvus.io" target="_blank" rel="noopener noreferrer">Milvus</a></li><li><a href="https://zilliz.com" target="_blank" rel="noopener noreferrer">Zilliz</a></li></ul><h3 id="技术概览" tabindex="-1"><a class="header-anchor" href="#技术概览"><span>技术概览</span></a></h3><p>这个单库由三个主要部分组成：</p><ul><li><code>frontend</code>: 一个 viteJS + React 前端，您可以运行它来轻松创建和管理LLM可以使用的所有内容。</li><li><code>server</code>: 一个 NodeJS express 服务器，用于处理所有交互并进行所有向量数据库管理和 LLM 交互。</li><li><code>docker</code>: Docker 指令和构建过程 + 从源代码构建的信息。</li><li><code>collector</code>: NodeJS express 服务器，用于从UI处理和解析文档。</li></ul><h2 id="🛳-自托管" tabindex="-1"><a class="header-anchor" href="#🛳-自托管"><span>🛳 自托管</span></a></h2><p>Mintplex Labs和社区维护了许多部署方法、脚本和模板，您可以使用它们在本地运行AnythingLLM。请参阅下面的表格，了解如何在您喜欢的环境上部署，或自动部署。</p><table><thead><tr><th>Docker</th><th>AWS</th><th>GCP</th><th>Digital Ocean</th><th><a href="http://Render.com" target="_blank" rel="noopener noreferrer">Render.com</a></th></tr></thead><tbody><tr><td>[![在 Docker 上部署][docker-btn]][docker-deploy]</td><td>[![在 AWS 上部署][aws-btn]][aws-deploy]</td><td>[![在 GCP 上部署][gcp-btn]][gcp-deploy]</td><td>[![在DigitalOcean上部署][do-btn]][do-deploy]</td><td>[![在 <a href="http://Render.com" target="_blank" rel="noopener noreferrer">Render.com</a> 上部署][render-btn]][render-deploy]</td></tr></tbody></table><table><thead><tr><th>Railway</th></tr></thead><tbody><tr><td>[![在Railway上部署][railway-btn]][railway-deploy]</td></tr></tbody></table><h2 id="如何设置开发环境" tabindex="-1"><a class="header-anchor" href="#如何设置开发环境"><span>如何设置开发环境</span></a></h2><ul><li><code>yarn setup</code> 填充每个应用程序部分所需的 <code>.env</code> 文件（从仓库的根目录）。 <ul><li>在开始下一步之前，先填写这些信息<code>server/.env.development</code>，不然代码无法正常执行。</li></ul></li><li><code>yarn dev:server</code> 在本地启动服务器（从仓库的根目录）。</li><li><code>yarn dev:frontend</code> 在本地启动前端（从仓库的根目录）。</li><li><code>yarn dev:collector</code> 然后运行文档收集器（从仓库的根目录）。</li></ul><h2 id="如何贡献" tabindex="-1"><a class="header-anchor" href="#如何贡献"><span>如何贡献</span></a></h2><ul><li>创建 issue</li><li>创建 PR，分支名称格式为 <code>&lt;issue number&gt;-&lt;short name&gt;</code></li><li>合并</li></ul><h2 id="远程信息收集与隐私保护" tabindex="-1"><a class="header-anchor" href="#远程信息收集与隐私保护"><span>远程信息收集与隐私保护</span></a></h2><p>由 Mintplex Labs Inc 开发的 AnythingLLM 包含一个收集匿名使用信息的 Telemetry 功能。</p><h3 id="为什么收集信息" tabindex="-1"><a class="header-anchor" href="#为什么收集信息"><span>为什么收集信息？</span></a></h3><p>我们使用这些信息来帮助我们理解 AnythingLLM 的使用情况，帮助我们确定新功能和错误修复的优先级，并帮助我们提高 AnythingLLM 的性能和稳定性。</p><h3 id="怎样关闭" tabindex="-1"><a class="header-anchor" href="#怎样关闭"><span>怎样关闭</span></a></h3><p>通过在服务器或 docker 的 <code>.env</code> 设置中将 <code>DISABLE_TELEMETRY</code> 设置为 “true” 来选择退出 Telemetry 远程信息收集功能。您也可以进入 AnythingLLM 应用 &gt;&gt;&gt; 侧边栏最下方 &gt;&gt;&gt; <code>隐私和数据</code> （Privacy&amp;Data） &gt;&gt;&gt; 找到最下方的 Anonymous Telemetry Enabled，点击绿色按钮让它变灰色，从而禁用信息收集功能。</p><h3 id="你们跟踪收集哪些信息" tabindex="-1"><a class="header-anchor" href="#你们跟踪收集哪些信息"><span>你们跟踪收集哪些信息？</span></a></h3><p>我们只会跟踪有助于我们做出产品和路线图决策的使用细节，具体包括：</p><ul><li>您的安装方式（Docker或桌面版）</li><li>文档被添加或移除的时间。但不包括文档内的具体内容。我们只关注添加或移除文档这个行为。这些信息能让我们了解到文档功能的使用情况。</li><li>使用中的向量数据库类型。让我们知道哪个向量数据库最受欢迎，并在后续更新中优先考虑相应的数据库。</li><li>使用中的LLM类型。让我们知道谁才是最受欢迎的LLM模型，并在后续更新中优先考虑相应模型。</li><li>信息被<code>发送</code>出去。这是最常规的“事件/行为/event”，并让我们了解到所有安装了这个项目的每日活动情况。同样，只收集<code>发送</code>这个行为的信息，我们不会收集关于聊天本身的性质或内容的任何信息。</li></ul><p>您可以通过查找所有调用<code>Telemetry.sendTelemetry</code>的位置来验证这些声明。</p><p>此外，如果启用，这些事件也会被写入输出日志，因此您也可以看到发送了哪些具体数据。</p><p>不收集IP或其他识别信息。Telemetry远程信息收集的方案来自<a href="https://posthog.com/" target="_blank" rel="noopener noreferrer">PostHog</a> - 一个开源的远程信息收集服务。</p><h2 id="🔗-更多产品" tabindex="-1"><a class="header-anchor" href="#🔗-更多产品"><span>🔗 更多产品</span></a></h2><ul><li><strong>[VectorAdmin][vector-admin]</strong>：一个用于管理向量数据库的全方位GUI和工具套件。</li><li><strong>[OpenAI Assistant Swarm][assistant-swarm]</strong>：一个智能体Agent就可以管理您所有的OpenAI助手。</li></ul><p>版权所有 © 2025 [Mintplex Labs][profile-link]。</p><p>本项目采用<a href="https://github.com/Mintplex-Labs/anything-llm/blob/master/LICENSE" target="_blank" rel="noopener noreferrer">MIT</a>许可证。</p><h1 id="参考资料" tabindex="-1"><a class="header-anchor" href="#参考资料"><span>参考资料</span></a></h1><p><a href="https://github.com/Mintplex-Labs/anything-llm" target="_blank" rel="noopener noreferrer">https://github.com/Mintplex-Labs/anything-llm</a></p>',37))])}const f=i(g,[["render",c]]),u=JSON.parse('{"path":"/posts/mcp/2025-04-15-ai-mcp-05-anything-llm.html","title":"AI MCP(大模型上下文)-05-anything-llm AnythingLLM 您一直在寻找的全方位AI应用程序","lang":"zh-CN","frontmatter":{"title":"AI MCP(大模型上下文)-05-anything-llm AnythingLLM 您一直在寻找的全方位AI应用程序","date":"2025-04-15T00:00:00.000Z","categories":["AI"],"tags":["ai","mcp","sh"],"published":true,"description":"AI MCP 系列 AgentGPT-01-入门介绍 Browser-use 是连接你的AI代理与浏览器的最简单方式 AI MCP(大模型上下文)-01-入门介绍 AI MCP(大模型上下文)-02-awesome-mcp-servers 精选的 MCP 服务器 AI MCP(大模型上下文)-03-open webui 介绍 是一个可扩展、功能丰富且用...","head":[["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"AI MCP(大模型上下文)-05-anything-llm AnythingLLM 您一直在寻找的全方位AI应用程序\\",\\"image\\":[\\"\\"],\\"datePublished\\":\\"2025-04-15T00:00:00.000Z\\",\\"dateModified\\":\\"2025-12-27T05:33:57.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"老马啸西风\\",\\"url\\":\\"https://houbb.github.io\\"}]}"],["meta",{"property":"og:url","content":"https://houbb.github.io/awesome-ai-coding/posts/mcp/2025-04-15-ai-mcp-05-anything-llm.html"}],["meta",{"property":"og:site_name","content":"老马啸西风"}],["meta",{"property":"og:title","content":"AI MCP(大模型上下文)-05-anything-llm AnythingLLM 您一直在寻找的全方位AI应用程序"}],["meta",{"property":"og:description","content":"AI MCP 系列 AgentGPT-01-入门介绍 Browser-use 是连接你的AI代理与浏览器的最简单方式 AI MCP(大模型上下文)-01-入门介绍 AI MCP(大模型上下文)-02-awesome-mcp-servers 精选的 MCP 服务器 AI MCP(大模型上下文)-03-open webui 介绍 是一个可扩展、功能丰富且用..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2025-12-27T05:33:57.000Z"}],["meta",{"property":"article:tag","content":"sh"}],["meta",{"property":"article:tag","content":"mcp"}],["meta",{"property":"article:tag","content":"ai"}],["meta",{"property":"article:published_time","content":"2025-04-15T00:00:00.000Z"}],["meta",{"property":"article:modified_time","content":"2025-12-27T05:33:57.000Z"}]]},"git":{"createdTime":1766806441000,"updatedTime":1766813637000,"contributors":[{"name":"bbhou","username":"bbhou","email":"1557740299@qq.com","commits":5,"url":"https://github.com/bbhou"}]},"readingTime":{"minutes":7.88,"words":2364},"filePathRelative":"posts/mcp/2025-04-15-ai-mcp-05-anything-llm.md","excerpt":"\\n<p><a href=\\"https://houbb.github.io/2025/04/03/ai-brower-agent-01-agentGPT\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">AgentGPT-01-入门介绍</a></p>\\n<p><a href=\\"https://houbb.github.io/2025/04/03/ai-brower-agent-02-browser-use\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">Browser-use 是连接你的AI代理与浏览器的最简单方式</a></p>","autoDesc":true}');export{f as comp,u as data};
