import{_ as r}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as n,a,o as e}from"./app-DYfk_09i.js";const o={};function s(i,t){return e(),n("div",null,[...t[0]||(t[0]=[a('<p>这一章标志着从传统机器学习走向深度学习时代的关键转折点，它聚焦于两大深度结构 —— <strong>CNN（卷积神经网络）</strong> 与 <strong>RNN（循环神经网络）/Transformer（注意力模型）</strong>，它们分别代表了机器在“看图”和“理解序列”上的两条主线。</p><hr><h1 id="第17章-卷积与序列模型" tabindex="-1"><a class="header-anchor" href="#第17章-卷积与序列模型"><span>第17章　卷积与序列模型</span></a></h1><h2 id="_17-1-cnn-的思想-局部感受野与权重共享" tabindex="-1"><a class="header-anchor" href="#_17-1-cnn-的思想-局部感受野与权重共享"><span><strong>17.1 CNN 的思想：局部感受野与权重共享</strong></span></a></h2><h3 id="🔹-一、背景" tabindex="-1"><a class="header-anchor" href="#🔹-一、背景"><span>🔹 一、背景</span></a></h3><p>传统的全连接神经网络在图像处理上效率极低，因为每个像素点都与所有神经元相连，导致参数量巨大、过拟合严重、计算成本极高。<br> 为了解决这一问题，卷积神经网络（Convolutional Neural Network, CNN）应运而生。</p><h3 id="🔹-二、核心思想" tabindex="-1"><a class="header-anchor" href="#🔹-二、核心思想"><span>🔹 二、核心思想</span></a></h3><p>CNN 模型灵感来自生物视觉皮层的感知机制，核心有两大关键思想：</p><ol><li><p><strong>局部感受野（Local Receptive Field）</strong></p><ul><li>每个神经元只“看”输入图像中的局部区域，而不是整个图像。</li><li>这使模型能捕捉局部特征（如边缘、角点、纹理等）。</li></ul></li><li><p><strong>权重共享（Weight Sharing）</strong></p><ul><li>同一卷积核（Filter）在整张图像上滑动，用相同的参数检测不同位置的同类特征。</li><li>大幅减少参数量，提高泛化能力。</li></ul></li></ol><h3 id="🔹-三、典型结构" tabindex="-1"><a class="header-anchor" href="#🔹-三、典型结构"><span>🔹 三、典型结构</span></a></h3><p>CNN 一般包含以下层级：</p><ul><li><strong>卷积层（Convolution Layer）</strong>：提取局部特征。</li><li><strong>激活层（ReLU）</strong>：引入非线性。</li><li><strong>池化层（Pooling Layer）</strong>：降维、增强平移不变性。</li><li><strong>全连接层（Fully Connected Layer）</strong>：进行分类或回归。</li></ul><h3 id="🔹-四、代表模型" tabindex="-1"><a class="header-anchor" href="#🔹-四、代表模型"><span>🔹 四、代表模型</span></a></h3><ul><li><strong>LeNet-5（1998）</strong>：最早的手写数字识别网络。</li><li><strong>AlexNet（2012）</strong>：ImageNet 大赛冠军，标志深度学习复兴。</li><li><strong>VGG、ResNet、Inception</strong>：多层结构与残差连接的典型代表。</li></ul><h3 id="🔹-五、意义" tabindex="-1"><a class="header-anchor" href="#🔹-五、意义"><span>🔹 五、意义</span></a></h3><p>CNN 的诞生使得“特征工程”从人工设计转向<strong>自动学习</strong>，成为计算机视觉（CV）领域的核心基础。</p><hr><h2 id="_17-2-rnn、lstm、gru-与序列依赖" tabindex="-1"><a class="header-anchor" href="#_17-2-rnn、lstm、gru-与序列依赖"><span><strong>17.2 RNN、LSTM、GRU 与序列依赖</strong></span></a></h2><h3 id="🔹-一、为什么需要-rnn" tabindex="-1"><a class="header-anchor" href="#🔹-一、为什么需要-rnn"><span>🔹 一、为什么需要 RNN？</span></a></h3><p>在 NLP、语音识别、时间序列预测等任务中，输入数据是<strong>有顺序的</strong>。</p><p>传统神经网络无法捕捉“时间上的依赖关系”，因此引入了循环神经网络（RNN）。</p><h3 id="🔹-二、rnn-的核心机制" tabindex="-1"><a class="header-anchor" href="#🔹-二、rnn-的核心机制"><span>🔹 二、RNN 的核心机制</span></a></h3><p>RNN 的关键思想是：</p><blockquote><p>当前时刻的输出不仅依赖当前输入，还依赖上一个时刻的隐藏状态。</p></blockquote><p>即：<br> [<br> h_t = f(Wx_t + Uh_{t-1})<br> ]<br> 这样，模型可以“记住”先前的信息，实现序列建模。</p><h3 id="🔹-三、rnn-的问题-梯度消失-爆炸" tabindex="-1"><a class="header-anchor" href="#🔹-三、rnn-的问题-梯度消失-爆炸"><span>🔹 三、RNN 的问题：梯度消失/爆炸</span></a></h3><p>由于反向传播要在时间维度上展开（BPTT），RNN 很容易出现<strong>长期依赖问题</strong>，导致训练不稳定。</p><h3 id="🔹-四、改进模型" tabindex="-1"><a class="header-anchor" href="#🔹-四、改进模型"><span>🔹 四、改进模型</span></a></h3><ol><li><p><strong>LSTM（Long Short-Term Memory）</strong></p><ul><li>通过“门机制”（输入门、遗忘门、输出门）控制信息流动。</li><li>能更好地捕捉长期依赖。</li></ul></li><li><p><strong>GRU（Gated Recurrent Unit）</strong></p><ul><li>LSTM 的简化版本，减少参数，提高训练速度。</li></ul></li></ol><h3 id="🔹-五、典型应用" tabindex="-1"><a class="header-anchor" href="#🔹-五、典型应用"><span>🔹 五、典型应用</span></a></h3><ul><li>语言模型（预测下一个词）</li><li>机器翻译</li><li>语音识别</li><li>股票预测、传感器序列分析等</li></ul><h3 id="🔹-六、意义" tabindex="-1"><a class="header-anchor" href="#🔹-六、意义"><span>🔹 六、意义</span></a></h3><p>RNN 系列模型让神经网络从“静态感知”迈向“动态理解”，为后续 Transformer 奠定了思想基础。</p><hr><h2 id="_17-3-注意力机制与-transformer" tabindex="-1"><a class="header-anchor" href="#_17-3-注意力机制与-transformer"><span><strong>17.3 注意力机制与 Transformer</strong></span></a></h2><h3 id="🔹-一、rnn-的局限性" tabindex="-1"><a class="header-anchor" href="#🔹-一、rnn-的局限性"><span>🔹 一、RNN 的局限性</span></a></h3><ul><li>序列依赖导致计算<strong>难以并行</strong>；</li><li>远距离依赖仍然难以捕捉；</li><li>训练时间长。</li></ul><h3 id="🔹-二、注意力机制-attention-mechanism" tabindex="-1"><a class="header-anchor" href="#🔹-二、注意力机制-attention-mechanism"><span>🔹 二、注意力机制（Attention Mechanism）</span></a></h3><p>灵感来源于人类的注意力：</p><blockquote><p>在处理信息时，人类不会平均关注所有输入，而是会“聚焦”在关键部分。</p></blockquote><p><strong>核心公式：</strong><br> [<br> Attention(Q,K,V) = softmax(\\frac{QK^T}{\\sqrt{d_k}})V<br> ]</p><ul><li>Q：查询向量（query）</li><li>K：键向量（key）</li><li>V：值向量（value）</li></ul><p>这个机制允许模型在每个时间步动态选择“该关注的输入部分”。</p><h3 id="🔹-三、transformer-的崛起" tabindex="-1"><a class="header-anchor" href="#🔹-三、transformer-的崛起"><span>🔹 三、Transformer 的崛起</span></a></h3><p>2017年，Google 提出了 Transformer 结构（论文《Attention is All You Need》），完全抛弃循环结构，<strong>仅依靠注意力机制</strong>建模序列关系。</p><h4 id="transformer-的优势" tabindex="-1"><a class="header-anchor" href="#transformer-的优势"><span>Transformer 的优势：</span></a></h4><ul><li>完全并行化（适合 GPU 加速）；</li><li>捕捉长距离依赖；</li><li>可扩展性极强。</li></ul><h4 id="核心组件" tabindex="-1"><a class="header-anchor" href="#核心组件"><span>核心组件：</span></a></h4><ul><li><strong>多头注意力（Multi-Head Attention）</strong>：让模型从多个角度关注不同的关系。</li><li><strong>位置编码（Positional Encoding）</strong>：保留序列顺序信息。</li><li><strong>前馈网络（Feed Forward Layer）</strong>：在每个位置独立变换特征。</li></ul><h3 id="🔹-四、代表模型与应用" tabindex="-1"><a class="header-anchor" href="#🔹-四、代表模型与应用"><span>🔹 四、代表模型与应用</span></a></h3><ul><li><strong>BERT（2018）</strong>：预训练语言模型，引发 NLP 革命。</li><li><strong>GPT 系列</strong>：从生成式预训练到大语言模型（LLM）。</li><li><strong>Vision Transformer（ViT）</strong>：将 Transformer 引入计算机视觉。</li><li><strong>Time Series Transformer</strong>：用于序列预测与异常检测。</li></ul><h3 id="🔹-五、意义-1" tabindex="-1"><a class="header-anchor" href="#🔹-五、意义-1"><span>🔹 五、意义</span></a></h3><p>Transformer 的出现标志着“统一的深度学习架构”时代。<br> 它打通了文本、图像、语音等不同模态的壁垒，成为当今 AI 的底层支撑结构。</p><hr><h2 id="📘-小结" tabindex="-1"><a class="header-anchor" href="#📘-小结"><span>📘 小结</span></a></h2><table><thead><tr><th>模型类型</th><th>核心思想</th><th>代表模型</th><th>典型应用</th><th>意义</th></tr></thead><tbody><tr><td>CNN</td><td>局部感受野 + 权重共享</td><td>LeNet, ResNet</td><td>图像分类、检测、识别</td><td>视觉革命</td></tr><tr><td>RNN</td><td>序列依赖 + 时间状态</td><td>LSTM, GRU</td><td>NLP、语音、时间序列</td><td>序列建模</td></tr><tr><td>Transformer</td><td>注意力 + 并行化</td><td>BERT, GPT, ViT</td><td>NLP、CV、语音、跨模态</td><td>统一架构</td></tr></tbody></table>',56)])])}const p=r(o,[["render",s]]),d=JSON.parse('{"path":"/posts/ml/2025-11-03-17-ml-book-CNN.html","title":"第17章　卷积与序列模型 卷积神经网络（Convolutional Neural Network, CNN）","lang":"zh-CN","frontmatter":{"title":"第17章　卷积与序列模型 卷积神经网络（Convolutional Neural Network, CNN）","date":"2025-11-03T00:00:00.000Z","categories":["AI"],"tags":["ai","learn-note"],"published":true,"description":"这一章标志着从传统机器学习走向深度学习时代的关键转折点，它聚焦于两大深度结构 —— CNN（卷积神经网络） 与 RNN（循环神经网络）/Transformer（注意力模型），它们分别代表了机器在“看图”和“理解序列”上的两条主线。 第17章 卷积与序列模型 17.1 CNN 的思想：局部感受野与权重共享 🔹 一、背景 传统的全连接神经网络在图像处理上...","head":[["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"第17章　卷积与序列模型 卷积神经网络（Convolutional Neural Network, CNN）\\",\\"image\\":[\\"\\"],\\"datePublished\\":\\"2025-11-03T00:00:00.000Z\\",\\"dateModified\\":\\"2025-12-27T05:15:15.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"老马啸西风\\",\\"url\\":\\"https://houbb.github.io\\"}]}"],["meta",{"property":"og:url","content":"https://houbb.github.io/blog-thinking/posts/ml/2025-11-03-17-ml-book-CNN.html"}],["meta",{"property":"og:site_name","content":"老马啸西风"}],["meta",{"property":"og:title","content":"第17章　卷积与序列模型 卷积神经网络（Convolutional Neural Network, CNN）"}],["meta",{"property":"og:description","content":"这一章标志着从传统机器学习走向深度学习时代的关键转折点，它聚焦于两大深度结构 —— CNN（卷积神经网络） 与 RNN（循环神经网络）/Transformer（注意力模型），它们分别代表了机器在“看图”和“理解序列”上的两条主线。 第17章 卷积与序列模型 17.1 CNN 的思想：局部感受野与权重共享 🔹 一、背景 传统的全连接神经网络在图像处理上..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2025-12-27T05:15:15.000Z"}],["meta",{"property":"article:tag","content":"learn-note"}],["meta",{"property":"article:tag","content":"ai"}],["meta",{"property":"article:published_time","content":"2025-11-03T00:00:00.000Z"}],["meta",{"property":"article:modified_time","content":"2025-12-27T05:15:15.000Z"}]]},"git":{"createdTime":1766812269000,"updatedTime":1766812515000,"contributors":[{"name":"bbhou","username":"bbhou","email":"1557740299@qq.com","commits":3,"url":"https://github.com/bbhou"}]},"readingTime":{"minutes":4.34,"words":1301},"filePathRelative":"posts/ml/2025-11-03-17-ml-book-CNN.md","excerpt":"<p>这一章标志着从传统机器学习走向深度学习时代的关键转折点，它聚焦于两大深度结构 —— <strong>CNN（卷积神经网络）</strong> 与 <strong>RNN（循环神经网络）/Transformer（注意力模型）</strong>，它们分别代表了机器在“看图”和“理解序列”上的两条主线。</p>\\n<hr>\\n<h1>第17章　卷积与序列模型</h1>\\n<h2><strong>17.1 CNN 的思想：局部感受野与权重共享</strong></h2>\\n<h3>🔹 一、背景</h3>\\n<p>传统的全连接神经网络在图像处理上效率极低，因为每个像素点都与所有神经元相连，导致参数量巨大、过拟合严重、计算成本极高。<br>\\n为了解决这一问题，卷积神经网络（Convolutional Neural Network, CNN）应运而生。</p>","autoDesc":true}');export{p as comp,d as data};
