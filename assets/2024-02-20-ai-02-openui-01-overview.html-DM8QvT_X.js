import{_ as l}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as p,a as s,b as r,e,f as n,w as t,r as h,o}from"./app-BsNixVBM.js";const d={};function c(k,a){const i=h("RouteLink");return o(),p("div",null,[a[5]||(a[5]=s(`<h1 id="openui" tabindex="-1"><a class="header-anchor" href="#openui"><span>OpenUI</span></a></h1><p>构建用户界面组件可能会很乏味。OpenUI旨在使这个过程有趣、快速且灵活。</p><p>我们在<a href="https://wandb.com" target="_blank" rel="noopener noreferrer">W&amp;B</a>也在使用这个工具来测试和原型化我们构建强大应用程序的下一代工具，这些应用程序是建立在LLM之上的。</p><h2 id="概览" tabindex="-1"><a class="header-anchor" href="#概览"><span>概览</span></a></h2><figure><img src="https://github.com/wandb/openui/blob/main/assets/demo.gif" alt="演示" tabindex="0" loading="lazy"><figcaption>演示</figcaption></figure><p>OpenUI允许您使用想象力描述用户界面，然后看到其实时渲染。您可以请求更改并将HTML转换为React、Svelte、Web组件等。这就像<a href="https://v0.dev" target="_blank" rel="noopener noreferrer">v0</a>一样，但是开源且没有那么精致 😝。</p><h2 id="实时演示" tabindex="-1"><a class="header-anchor" href="#实时演示"><span>实时演示</span></a></h2><p><a href="https://openui.fly.dev" target="_blank" rel="noopener noreferrer">尝试演示</a></p><h2 id="本地运行" tabindex="-1"><a class="header-anchor" href="#本地运行"><span>本地运行</span></a></h2><p>您也可以在本地运行OpenUI并使用<a href="https://ollama.com" target="_blank" rel="noopener noreferrer">Ollama</a>提供的模型。<a href="https://ollama.com/download" target="_blank" rel="noopener noreferrer">安装Ollama</a>并拉取一个模型，比如<a href="https://ollama.com/library/codellama" target="_blank" rel="noopener noreferrer">CodeLlama</a>，然后假设您已经安装了git和Python：</p><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-bash"><span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">git</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> clone</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> https://github.com/wandb/openui</span></span>
<span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">cd</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> openui/backend</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 您可能想要从虚拟环境中执行此操作</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">pip</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> install</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> .</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 必须设置此项以使用OpenAI模型，请在此处查找您的API密钥：https://platform.openai.com/api-keys</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">export</span><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;"> OPENAI_API_KEY</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;">xxx</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">python</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> -m</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> openui</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="docker-compose" tabindex="-1"><a class="header-anchor" href="#docker-compose"><span>Docker Compose</span></a></h3><blockquote><p>免责声明：这可能会非常慢。如果您有GPU，则可能需要将<code>ollama</code>容器的标签更改为支持GPU的标签。如果您在Mac上运行，请按照上述说明操作，并在本机运行Ollama，以充分利用M1/M2。</p></blockquote><p>您可以从根目录运行：</p><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-bash"><span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">docker-compose</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> up</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> -d</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">docker</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> exec</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> -it</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> openui-ollama-1</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> ollama</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> pull</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> llava</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><p>如果您的OPENAI_API_KEY已在环境中设置，则只需从<code>OPENAI_API_KEY</code>行中删除<code>=xxx</code>。您也可以在上述命令中用您选择的开源模型替换<code>llava</code><em>（<a href="https://ollama.com/library/llava" target="_blank" rel="noopener noreferrer">llava</a>目前是唯一支持图像的Ollama模型之一）</em>。现在，您应该能够访问<a href="http://localhost:7878" target="_blank" rel="noopener noreferrer">http://localhost:7878</a>上的OpenUI。</p><p><em>如果您对前端或后端进行更改，您需要运行<code>docker-compose build</code>才能将它们反映在服务中。</em></p><h3 id="docker" tabindex="-1"><a class="header-anchor" href="#docker"><span>Docker</span></a></h3><p>您可以从<code>/backend</code>目录手动构建和运行docker文件：</p><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-bash"><span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">docker</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> build</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> .</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> -t</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> wandb/openui</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> --load</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">docker</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> run</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> -p</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> 7878:7878</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> -e</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> OPENAI_API_KEY</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> wandb/openui</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><p>现在您可以转到<a href="http://localhost:7878" target="_blank" rel="noopener noreferrer">http://localhost:7878</a></p><h2 id="开发" tabindex="-1"><a class="header-anchor" href="#开发"><span>开发</span></a></h2><p>此存储库中配置了一个<a href="https://github.com/wandb/openui/blob/main/.devcontainer/devcontainer.json" target="_blank" rel="noopener noreferrer">开发容器</a>，这是最快速的入门方式。</p><h3 id="codespace" tabindex="-1"><a class="header-anchor" href="#codespace"><span>Codespace</span></a></h3><img src="https://github.com/wandb/openui/raw/main/assets/codespace.png" alt="New with options..." width="500"><p>在创建Codespace时选择更多选项，然后选择<strong>使用选项新建...</strong>。如果您想要非常快的启动时间，请选择美国西部地区。您还需要配置您的OPENAI_API_KEY密钥，或者如果要尝试Ollama，只需将其设置为<code>xxx</code><em>（您至少需要16GB的内存）</em>。</p><p>进入代码空间后，您可以在一个终端中运行服务器：<code>python -m openui --dev</code>。然后在一个新的终端中：</p><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-bash"><span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">cd</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> /workspaces/openui/frontend</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">npm</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> run</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> dev</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><p>这应该会在端口5173上打开另一个服务，这是您想要访问的服务。对前端和后端的所有更改都将自动重新加载并反映在您的浏览器中。</p><h3 id="ollama" tabindex="-1"><a class="header-anchor" href="#ollama"><span>Ollama</span></a></h3><p>Codespace自动安装ollama并下载<code>llava</code>模型。您可以使用<code>ollama list</code>验证Ollama是否正在运行，如果失败，请打开一个新终端并运行<code>ollama serve</code>。在Codespaces中，我们在启动时拉取llava，因此您应该在列表中看到它。您可以从应用程序左上角的设置齿轮图标中选择Ollama模型。您拉取的任何模型，例如<code>ollama pull llama</code>，都将显示在设置模态中。</p><img src="https://github.com/wandb/openui/raw/main/assets/ollama.png" width="500" alt="选择Ollama模型"><h3 id="资源" tabindex="-1"><a class="header-anchor" href="#资源"><span>资源</span></a></h3>`,33)),r("p",null,[a[2]||(a[2]=e("请参阅",-1)),n(i,{to:"/posts/ai/frontend/"},{default:t(()=>[...a[0]||(a[0]=[e("frontend",-1)])]),_:1}),a[3]||(a[3]=e("和",-1)),n(i,{to:"/posts/ai/backend/"},{default:t(()=>[...a[1]||(a[1]=[e("backend",-1)])]),_:1}),a[4]||(a[4]=e("目录中的自述文件。",-1))]),a[6]||(a[6]=s('<h1 id="chat" tabindex="-1"><a class="header-anchor" href="#chat"><span>chat</span></a></h1><h2 id="详细介绍一下-https-github-com-wandb-openui" tabindex="-1"><a class="header-anchor" href="#详细介绍一下-https-github-com-wandb-openui"><span>详细介绍一下 <a href="https://github.com/wandb/openui/" target="_blank" rel="noopener noreferrer">https://github.com/wandb/openui/</a></span></a></h2><p>OpenUI 是由 W&amp;B（Weights &amp; Biases）开发的一个开源项目，旨在简化构建用户界面（UI）组件的过程，使其更加有趣、快速和灵活。以下是关于 OpenUI 的详细介绍：</p><h3 id="项目目标" tabindex="-1"><a class="header-anchor" href="#项目目标"><span>项目目标</span></a></h3><ul><li>OpenUI 旨在让开发者能够通过想象力描述 UI，然后实时看到它被渲染出来。它允许用户请求更改，并将 HTML 转换为 React、Svelte、Web Components 等。</li></ul><h3 id="概述" tabindex="-1"><a class="header-anchor" href="#概述"><span>概述</span></a></h3><ul><li>OpenUI 允许用户使用自然语言描述他们想要的 UI 组件，然后这些描述可以被转换成实际的 UI 组件代码。它是一个开源工具，用于测试和原型设计，以构建基于大型语言模型（LLMs）的下一代强大应用程序。</li></ul><h3 id="实时演示-1" tabindex="-1"><a class="header-anchor" href="#实时演示-1"><span>实时演示</span></a></h3><ul><li>项目页面提供了一个实时演示，用户可以尝试 OpenUI 的功能。</li></ul><h3 id="本地运行-1" tabindex="-1"><a class="header-anchor" href="#本地运行-1"><span>本地运行</span></a></h3><ul><li>用户可以在本地运行 OpenUI，并使用 Ollama 可用的模型。需要先安装 Ollama 并拉取一个模型，如 CodeLlama。然后，假设用户已经安装了 git 和 python，可以按照提供的步骤运行 OpenUI。</li></ul><h3 id="docker-compose-1" tabindex="-1"><a class="header-anchor" href="#docker-compose-1"><span>Docker Compose</span></a></h3><ul><li>用户也可以使用 Docker Compose 来运行 OpenUI。需要注意的是，这种方式可能会比较慢，如果用户有 GPU，可能需要更改 <code>ollama</code> 容器的标签以支持 GPU。对于 Mac 用户，建议按照上面的指示本地运行 Ollama 以利用 M1/M2 芯片的优势。</li></ul><h3 id="docker-1" tabindex="-1"><a class="header-anchor" href="#docker-1"><span>Docker</span></a></h3><ul><li>用户还可以手动从 <code>/backend</code> 目录构建和运行 Docker 文件。</li></ul><h3 id="开发-1" tabindex="-1"><a class="header-anchor" href="#开发-1"><span>开发</span></a></h3><ul><li>该项目配置了开发容器，这是最快开始使用的方式。</li><li>项目还支持 Codespace，允许用户在云端开发环境中进行开发。</li></ul><h3 id="ollama-1" tabindex="-1"><a class="header-anchor" href="#ollama-1"><span>Ollama</span></a></h3><ul><li>Codespace 会自动安装 Ollama 并下载 <code>llava</code> 模型。用户可以通过 <code>ollama list</code> 命令来验证 Ollama 是否正在运行。在 Codespace 中，<code>llava</code> 会在启动时被拉取，因此应该可以在列表中看到。</li></ul><h3 id="资源-1" tabindex="-1"><a class="header-anchor" href="#资源-1"><span>资源</span></a></h3><ul><li>用户可以参考前端和后端目录中的自述文件，以获取更多关于如何使用 OpenUI 的信息。</li></ul><p>OpenUI 的开发和运行依赖于一些外部工具和模型，如 Ollama 和 OpenAI 的 API。它为开发者提供了一种快速迭代和原型设计的方法，特别是对于那些希望利用最新的 AI 技术来加速 UI 开发过程的人。通过 OpenUI，开发者可以更专注于创意和设计，而不是繁琐的编码工作。</p><h1 id="参考资料" tabindex="-1"><a class="header-anchor" href="#参考资料"><span>参考资料</span></a></h1><p><a href="https://github.com/wandb/openui/blob/main/README.md" target="_blank" rel="noopener noreferrer">https://github.com/wandb/openui/blob/main/README.md</a></p>',24))])}const g=l(d,[["render",c]]),u=JSON.parse('{"path":"/posts/ai/2024-02-20-ai-02-openui-01-overview.html","title":"AI-02-openui 允许您使用想象力描述用户界面，然后看到其实时渲染。","lang":"zh-CN","frontmatter":{"title":"AI-02-openui 允许您使用想象力描述用户界面，然后看到其实时渲染。","date":"2024-02-20T00:00:00.000Z","categories":["AI"],"tags":["ai","aigc","sh"],"published":true,"description":"OpenUI 构建用户界面组件可能会很乏味。OpenUI旨在使这个过程有趣、快速且灵活。 我们在W&B也在使用这个工具来测试和原型化我们构建强大应用程序的下一代工具，这些应用程序是建立在LLM之上的。 概览 演示演示 OpenUI允许您使用想象力描述用户界面，然后看到其实时渲染。您可以请求更改并将HTML转换为React、Svelte、Web组件等。这...","head":[["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"AI-02-openui 允许您使用想象力描述用户界面，然后看到其实时渲染。\\",\\"image\\":[\\"https://github.com/wandb/openui/blob/main/assets/demo.gif\\"],\\"datePublished\\":\\"2024-02-20T00:00:00.000Z\\",\\"dateModified\\":\\"2025-12-27T05:15:15.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"老马啸西风\\",\\"url\\":\\"https://houbb.github.io\\"}]}"],["meta",{"property":"og:url","content":"https://houbb.github.io/awesome-ai-coding/posts/ai/2024-02-20-ai-02-openui-01-overview.html"}],["meta",{"property":"og:site_name","content":"老马啸西风"}],["meta",{"property":"og:title","content":"AI-02-openui 允许您使用想象力描述用户界面，然后看到其实时渲染。"}],["meta",{"property":"og:description","content":"OpenUI 构建用户界面组件可能会很乏味。OpenUI旨在使这个过程有趣、快速且灵活。 我们在W&B也在使用这个工具来测试和原型化我们构建强大应用程序的下一代工具，这些应用程序是建立在LLM之上的。 概览 演示演示 OpenUI允许您使用想象力描述用户界面，然后看到其实时渲染。您可以请求更改并将HTML转换为React、Svelte、Web组件等。这..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:image","content":"https://github.com/wandb/openui/blob/main/assets/demo.gif"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2025-12-27T05:15:15.000Z"}],["meta",{"property":"article:tag","content":"sh"}],["meta",{"property":"article:tag","content":"aigc"}],["meta",{"property":"article:tag","content":"ai"}],["meta",{"property":"article:published_time","content":"2024-02-20T00:00:00.000Z"}],["meta",{"property":"article:modified_time","content":"2025-12-27T05:15:15.000Z"}]]},"git":{"createdTime":1766812269000,"updatedTime":1766812515000,"contributors":[{"name":"bbhou","username":"bbhou","email":"1557740299@qq.com","commits":3,"url":"https://github.com/bbhou"}]},"readingTime":{"minutes":5.21,"words":1563},"filePathRelative":"posts/ai/2024-02-20-ai-02-openui-01-overview.md","excerpt":"\\n<p>构建用户界面组件可能会很乏味。OpenUI旨在使这个过程有趣、快速且灵活。</p>\\n<p>我们在<a href=\\"https://wandb.com\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">W&amp;B</a>也在使用这个工具来测试和原型化我们构建强大应用程序的下一代工具，这些应用程序是建立在LLM之上的。</p>\\n<h2>概览</h2>\\n<figure><img src=\\"https://github.com/wandb/openui/blob/main/assets/demo.gif\\" alt=\\"演示\\" tabindex=\\"0\\" loading=\\"lazy\\"><figcaption>演示</figcaption></figure>","autoDesc":true}');export{g as comp,u as data};
