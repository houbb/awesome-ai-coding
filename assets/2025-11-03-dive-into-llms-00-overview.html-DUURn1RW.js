import{_ as t}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as r,a as i,o}from"./app-DYfk_09i.js";const l={};function n(a,e){return o(),r("div",null,[...e[0]||(e[0]=[i('<h1 id="背景" tabindex="-1"><a class="header-anchor" href="#背景"><span>背景</span></a></h1><p>学习 <a href="https://github.com/Lordog/dive-into-llms" target="_blank" rel="noopener noreferrer">dive-into-llms</a></p><h2 id="项目简介" tabindex="-1"><a class="header-anchor" href="#项目简介"><span>项目简介</span></a></h2><p>这个项目是 Dive into LLMs（中文名：《动手学大模型》） — 一个由 上海交通大学 NLP / AI 课程团队发起、在 GitHub 上开源的 “大语言模型 (LLM) 编程实践教程” 系列。 (<a href="https://github.com/Lordog/dive-into-llms" title="GitHub - Lordog/dive-into-llms: 《动手学大模型Dive into LLMs》系列编程实践教程" target="_blank" rel="noopener noreferrer">GitHub</a>)</p><p>它的主要目标如下：</p><ul><li>帮助读者 <strong>从实践角度</strong>快速上手大语言模型（LLM）相关技术，而不仅仅是理论。 (<a href="https://github.com/Lordog/dive-into-llms" title="GitHub - Lordog/dive-into-llms: 《动手学大模型Dive into LLMs》系列编程实践教程" target="_blank" rel="noopener noreferrer">GitHub</a>)</li><li>覆盖微调、提示工程、知识编辑、多模态、代理智能体、安全对齐等多个话题。 (<a href="https://github.com/Lordog/dive-into-llms" title="GitHub - Lordog/dive-into-llms: 《动手学大模型Dive into LLMs》系列编程实践教程" target="_blank" rel="noopener noreferrer">GitHub</a>)</li><li>是一个 <strong>完全免费、公益性质</strong> 的教程合集。 (<a href="https://github.com/Lordog/dive-into-llms" title="GitHub - Lordog/dive-into-llms: 《动手学大模型Dive into LLMs》系列编程实践教程" target="_blank" rel="noopener noreferrer">GitHub</a>)</li></ul><hr><h2 id="核心内容-教程目录" tabindex="-1"><a class="header-anchor" href="#核心内容-教程目录"><span>核心内容 &amp; 教程目录</span></a></h2><p>项目在 README 中列出了当前包含的主题模块，主要包括： (<a href="https://github.com/Lordog/dive-into-llms" title="GitHub - Lordog/dive-into-llms: 《动手学大模型Dive into LLMs》系列编程实践教程" target="_blank" rel="noopener noreferrer">GitHub</a>)</p><ul><li>微调与部署：如何拿预训练模型做指定任务的微调、然后部署成 Demo。</li><li>提示学习与思维链：如何调用大模型 API／做好提示工程／使用 chain-of-thought 思维链技巧。</li><li>知识编辑：如何对语言模型“插入”或“修改”知识，并验证效果。</li><li>数学推理：让大模型具备数学推理能力、甚至蒸馏一个小模型做实验。</li><li>模型水印：在语言模型生成内容中嵌入“人肉不可见”的水印。</li><li>越狱攻击：探讨如何从攻击角度理解大模型的弱点。</li><li>大模型隐写：让模型生成流畅回答的同时携带隐蔽信息。</li><li>多模态模型：如何让大语言模型理解／生成文本之外的模态（图像、音频等）。</li><li>GUI 智能体：做一个智能体界面／Agent，让模型替你做事务、完成交互任务。</li><li>智能体安全：探析开放智能体场景中的风险、防范、安全设计。</li><li>RLHF 安全对齐：基于 PPO 的强化学习 + 人类反馈 (RLHF) 实验指南。</li></ul><p>此外，项目也提到：一项 <strong>“国产化《大模型开发全流程》公益教程”</strong> 已推出（与 华为昇腾社区 合作）作为延伸。 (<a href="https://github.com/Lordog/dive-into-llms" title="GitHub - Lordog/dive-into-llms: 《动手学大模型Dive into LLMs》系列编程实践教程" target="_blank" rel="noopener noreferrer">GitHub</a>)</p><hr><h2 id="项目动机与特色" tabindex="-1"><a class="header-anchor" href="#项目动机与特色"><span>项目动机与特色</span></a></h2><ul><li>动机：该教程来源于上海交通大学 “自然语言处理前沿技术 (NIS8021)” 与 “人工智能安全技术 (NIS3353)” 课程讲义扩展。 (<a href="https://github.com/Lordog/dive-into-llms" title="GitHub - Lordog/dive-into-llms: 《动手学大模型Dive into LLMs》系列编程实践教程" target="_blank" rel="noopener noreferrer">GitHub</a>)</li><li>公益性：免费提供，鼓励学生／研究者快速上手大模型。</li><li>实践性强：不仅介绍理论，还提供 “课件 + 教程 + 脚本” 三部分资源。 (<a href="https://github.com/Lordog/dive-into-llms" title="GitHub - Lordog/dive-into-llms: 《动手学大模型Dive into LLMs》系列编程实践教程" target="_blank" rel="noopener noreferrer">GitHub</a>)</li><li>更新频繁／话题覆盖广：从基础微调到安全对齐、从提示工程到隐写水印，应有尽有。</li><li>开放贡献：欢迎 Issue／Pull Request，共同完善。 (<a href="https://github.com/Lordog/dive-into-llms" title="GitHub - Lordog/dive-into-llms: 《动手学大模型Dive into LLMs》系列编程实践教程" target="_blank" rel="noopener noreferrer">GitHub</a>)</li></ul><hr><h2 id="使用建议-适合人群" tabindex="-1"><a class="header-anchor" href="#使用建议-适合人群"><span>使用建议 &amp;适合人群</span></a></h2><p><strong>适合人群</strong>：</p><ul><li>有基础编程经验、希望进入大语言模型开发或研究的人。</li><li>研究生／AI 工程师／对 LLM 实践感兴趣的开发者。</li><li>想系统学习从提示、微调、部署、安全对齐等全流程者。</li></ul><p><strong>建议使用方式</strong>：</p><ul><li>按模块顺序逐个学习（从“微调与部署”开始常规，再逐步深入“多模态”“安全对齐”）。</li><li>配合教程中的脚本（代码）动手实操，效果更佳。</li><li>在学习过程中结合你自己的项目或用例，如你正在做的 “自动化测试平台” 或 “AI 根因分析系统”，思考模型如何嵌入。</li><li>注意：虽然内容丰富，但提示其 “仅供参考” — 作者声明“不保证百分百正确”。 (<a href="https://github.com/Lordog/dive-into-llms" title="GitHub - Lordog/dive-into-llms: 《动手学大模型Dive into LLMs》系列编程实践教程" target="_blank" rel="noopener noreferrer">GitHub</a>)</li></ul><hr><h2 id="与您的背景结合建议" tabindex="-1"><a class="header-anchor" href="#与您的背景结合建议"><span>与您的背景结合建议</span></a></h2><p>鉴于你目前是全栈开发 +运维/监控方向，并且在做 AI 根因分析系统的平台化构建，这里有几条结合建议：</p><ul><li>你可以从 “提示学习与思维链” 入手，思考如何将 LLM 用于监控报警/日志/Trace 的自然语言分析场景。</li><li>多模态模块：考虑日志 +指标 +Trace 多模态输入，或许可借助大模型。该教程的多模态部分可作为参考。</li><li>智能体安全、安全对齐、知识编辑：在根因分析系统中，“模型误报”“模型偏差”是关键风险，这些模块帮你提前识别。</li><li>将脚本或示例代码和你的 Java/Vue 架构结合起来，比如做一个 LLM 微服务调用模块，前端展示智能体推荐根因、告警处理建议。</li></ul><h1 id="chat" tabindex="-1"><a class="header-anchor" href="#chat"><span>chat</span></a></h1><h2 id="huggingface" tabindex="-1"><a class="header-anchor" href="#huggingface"><span>huggingface</span></a></h2><p>是的，整体来说，从零开始入门学习大模型，使用 Transformers（由 Hugging Face 出品）的中文文档是一个 <strong>很好的选择</strong>，不过还需要配合一些其它资源、实践和基础准备。</p><p>下面我按「优点」「需注意的地方」「建议学习路径」来聊一聊，方便你判断是否合适你目前的背景。</p><hr><h2 id="✅-为什么这是一个好选择" tabindex="-1"><a class="header-anchor" href="#✅-为什么这是一个好选择"><span>✅ 为什么这是一个好选择</span></a></h2><ol><li><p><strong>中文版本可读性强</strong><br> 文档已有中文版（例如 “Transformers 简介” 一节）显示其支持中文说明。 (<a href="https://github.com/Lordog/dive-into-llms" title="GitHub - Lordog/dive-into-llms: 《动手学大模型Dive into LLMs》系列编程实践教程" target="_blank" rel="noopener noreferrer">Hugging Face</a>)<br> 对你（中文背景）来说，能直接阅读、理解门槛更低。</p></li><li><p><strong>覆盖面广、功能丰富</strong><br> 文档里提到，这个库支持从「快速上手」、「教程」、「操作指南」到「概念指南」「API 参考」。 (<a href="https://github.com/Lordog/dive-into-llms" title="GitHub - Lordog/dive-into-llms: 《动手学大模型Dive into LLMs》系列编程实践教程" target="_blank" rel="noopener noreferrer">Hugging Face</a>)<br> 也就是说，它不仅能教你怎么运行模型，还能解释背后的原理、也有很多应用（比如文本、图像、音频、多模态）支持。 (<a href="https://huggingface.co/docs/transformers/v4.42.0/zh/index?utm_source=chatgpt.com" title="🤗 Transformers简介" target="_blank" rel="noopener noreferrer">Hugging Face</a>)</p></li><li><p><strong>生态与实践导向强</strong><br> Hugging Face 不只是文档，还是一个模型库 + 社区。你可以直接拿预训练模型、简单试验、探索微调等。这个在“从零”起步非常关键：理论＋实践结合。</p></li><li><p><strong>接轨主流技术</strong><br> 如果你计划涉及「大模型」「预训练／微调」「模型部署」这类内容，那么这个库几乎是目前业界／开源界常用的入口之一。使用这个文档，学习的是“真实可用”的技能，而不是只停在概念上。</p></li></ol><hr><h2 id="⚠️-需要注意-补充的地方" tabindex="-1"><a class="header-anchor" href="#⚠️-需要注意-补充的地方"><span>⚠️ 需要注意／补充的地方</span></a></h2><p>虽然这是一个好选择，但也有几个地方你要提前知道，否则可能在学习过程中遇到挫折：</p><ol><li><p><strong>有一定前置基础要求</strong><br> 虽然文档覆盖“从入门”部分，但“从零”真正起步还意味着你可能需要：</p><ul><li>Python 编程基础（比如能读懂 <code>import transformers</code>、处理数据、调试代码）</li><li>机器学习 / 深度学习基础（如：神经网络、矩阵、优化、损失函数）</li><li>如果涉及到微调或部署，还可能需要了解 GPU、批处理、模型推理、量化、推理优化等。<br> 如果你完全没有这些背景，那么即便文档再好，也建议先补一点“基础深度学习” + “Python数据处理”之类。</li></ul></li><li><p><strong>中文文档可能滞后于英文版</strong><br> 开源项目更新快，有时新功能、最新模型会先在英文文档中出现，中文翻译可能稍微滞后。比如有 issue 提到翻译工作还在推进。 (<a href="https://github.com/huggingface/transformers/issues/20095?utm_source=chatgpt.com" title="Issue #20095 · huggingface/transformers" target="_blank" rel="noopener noreferrer">GitHub</a>)<br> 所以如果你碰到“文档里没有提到的新模型”或“英文例程”的话，可能需要查英文原版。</p></li><li><p><strong>大模型／生产系统还涉及很多超出基础库的内容</strong><br> 你提到“从零开始学习大模型”，但“真正的大模型”可能牵涉：模型训练资源、数据集准备、微调、部署、效率/成本/服务化、根因分析、推理优化、量化、分布式训练、模型安全与偏见等等。<br> 而 Transformers 库主要聚焦“使用与微调预训练模型”的环节。你后续如果走深入（例如自训练大型语言模型、或深度定制部署）可能还需要额外学习“底层架构原理”“大规模训练框架”“系统部署”这些。</p></li><li><p><strong>动手实践很重要</strong><br> 看文档当然必要，但“看了=会做”不一定。建议你／你团队里安排到实验、mini 项目、跑模型、搞数据、调参数，这样收获最大。文档虽好，但如果只读不练，可能停留在“知道”层面。</p></li></ol><hr><h2 id="🎯-给你的建议学习路径-结合你现在背景" tabindex="-1"><a class="header-anchor" href="#🎯-给你的建议学习路径-结合你现在背景"><span>🎯 给你的建议学习路径（结合你现在背景）</span></a></h2><p>你说你是监控报警／运维架构师，正在往 AI 智能根因分析系统平台方向走。你做全栈开发，也有后台（Java）＋前端（Vue）的背景。基于这个背景，我建议如下路径，把 Transformers 的文档作为主干，但加一些辅助环节：</p><h3 id="步骤-1-梳理基础" tabindex="-1"><a class="header-anchor" href="#步骤-1-梳理基础"><span>步骤 1：梳理基础</span></a></h3><ul><li>确保你至少对 Python 有基本掌握（能读写、能用 pip 安装包、能写脚本）。</li><li>对深度学习基础（例如：神经网络、反向传播、优化器、损失函数、过拟合/欠拟合）有基本理解。取一两本“深度学习入门”资料迅速过。</li><li>对自然语言处理／大模型的一些背景概念有初步认识：什么是预训练、微调、Transformer 架构、模型推理、量化、部署等等。</li></ul><h3 id="步骤-2-跟随文档快速上手" tabindex="-1"><a class="header-anchor" href="#步骤-2-跟随文档快速上手"><span>步骤 2：跟随文档快速上手</span></a></h3><ul><li>在文档中「开始使用」部分快速跑起来：安装 <code>transformers</code> 库、加载一个预训练模型（比如 <code>bert-base-chinese</code>）做一个文本分类或问答任务。</li><li>利用文档中的“教程”部分，做一个你感兴趣的小项目：比如把你系统中的报警日志做分类预测，或做根因分析里的文本匹配。</li><li>同时浏览“概念指南”那部分，理解 Transformer 模型为什么有效、预训练模型背后的逻辑。这样你的理解更稳固。</li></ul><h3 id="步骤-3-从-用-到-定制" tabindex="-1"><a class="header-anchor" href="#步骤-3-从-用-到-定制"><span>步骤 3：从“用”到“定制”</span></a></h3><ul><li>利用文档里的「操作指南／How-to」部分，试试微调一个预训练模型（比如在你自己的小数据集上做微调）。</li><li>学习如何部署模型／推理：文档中提到支持 <code>ONNX</code>、<code>TorchScript</code> 导出。 (<a href="https://huggingface.co/docs/transformers/v4.42.0/zh/index?utm_source=chatgpt.com" title="🤗 Transformers简介" target="_blank" rel="noopener noreferrer">Hugging Face</a>) 你作为运维架构师，这部分你会感兴趣。</li><li>探索模型优化、量化、加速推理、模型服务化（虽不是文档主要但你未来可能要扩展）。</li></ul><h3 id="步骤-4-结合你的大模型目标" tabindex="-1"><a class="header-anchor" href="#步骤-4-结合你的大模型目标"><span>步骤 4：结合你的大模型目标</span></a></h3><ul><li>你提到要做“智能根因分析系统平台”——这意味着你可能不仅用预训练模型，还可能用多模态数据（日志、指标、Trace、报警）、自定义流程、自定义任务。你可以用 Transformers 做一个模块，比如用预训练语言模型处理报警文本、结合指标做分类/生成、将结果输出给前端。</li><li>阅读 Transformers 文档中「多模态」或「任务」支持哪些类型，然后思考：你的根因分析系统里哪些任务（比如异常文本生成、自动报警原因归纳、日志摘要）可以借助这些模型。</li><li>保持对更大规模、大模型训练／部署／系统化设计的关注：虽然文档覆盖微调，但如果你要大规模系统化、可用性、稳定性、维护性，那还要学习系统架构层面内容。</li></ul><hr><h2 id="🔍-总结一句话" tabindex="-1"><a class="header-anchor" href="#🔍-总结一句话"><span>🔍 总结一句话</span></a></h2><p>如果让我一句话总结：<strong>是的，这份中文文档是一个非常合适的起点</strong>。它能帮你从“我不知道大模型是什么”到“我能用预训练模型做任务”这个阶段。但如果你目标是“自己训练／大规模部署”或者“从零无背景起步”，你还需要补一些基础、做实践、并且不断扩展到系统化层面。</p><p>如果你愿意，我可以帮你拉一份「基于 Transformers 文档 + 实践项目」的入门路线图（按你现在背景定制：Java后台 + Vue前端 +运维架构师）。你看要不要？</p>',50)])])}const p=t(l,[["render",n]]),d=JSON.parse('{"path":"/posts/learn-llms/2025-11-03-dive-into-llms-00-overview.html","title":"dive-into-llms-00-学习概览","lang":"zh-CN","frontmatter":{"title":"dive-into-llms-00-学习概览","date":"2025-11-03T00:00:00.000Z","categories":["AI"],"tags":["ai","learn-note"],"published":true,"description":"背景 学习 dive-into-llms 项目简介 这个项目是 Dive into LLMs（中文名：《动手学大模型》） — 一个由 上海交通大学 NLP / AI 课程团队发起、在 GitHub 上开源的 “大语言模型 (LLM) 编程实践教程” 系列。 (GitHub) 它的主要目标如下： 帮助读者 从实践角度快速上手大语言模型（LLM）相关技术，...","head":[["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"dive-into-llms-00-学习概览\\",\\"image\\":[\\"\\"],\\"datePublished\\":\\"2025-11-03T00:00:00.000Z\\",\\"dateModified\\":\\"2025-12-27T05:15:15.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"老马啸西风\\",\\"url\\":\\"https://houbb.github.io\\"}]}"],["meta",{"property":"og:url","content":"https://houbb.github.io/blog-thinking/posts/learn-llms/2025-11-03-dive-into-llms-00-overview.html"}],["meta",{"property":"og:site_name","content":"老马啸西风"}],["meta",{"property":"og:title","content":"dive-into-llms-00-学习概览"}],["meta",{"property":"og:description","content":"背景 学习 dive-into-llms 项目简介 这个项目是 Dive into LLMs（中文名：《动手学大模型》） — 一个由 上海交通大学 NLP / AI 课程团队发起、在 GitHub 上开源的 “大语言模型 (LLM) 编程实践教程” 系列。 (GitHub) 它的主要目标如下： 帮助读者 从实践角度快速上手大语言模型（LLM）相关技术，..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2025-12-27T05:15:15.000Z"}],["meta",{"property":"article:tag","content":"learn-note"}],["meta",{"property":"article:tag","content":"ai"}],["meta",{"property":"article:published_time","content":"2025-11-03T00:00:00.000Z"}],["meta",{"property":"article:modified_time","content":"2025-12-27T05:15:15.000Z"}]]},"git":{"createdTime":1766812269000,"updatedTime":1766812515000,"contributors":[{"name":"bbhou","username":"bbhou","email":"1557740299@qq.com","commits":3,"url":"https://github.com/bbhou"}]},"readingTime":{"minutes":9.9,"words":2969},"filePathRelative":"posts/learn-llms/2025-11-03-dive-into-llms-00-overview.md","excerpt":"\\n<p>学习 <a href=\\"https://github.com/Lordog/dive-into-llms\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">dive-into-llms</a></p>\\n<h2>项目简介</h2>\\n<p>这个项目是 Dive into LLMs（中文名：《动手学大模型》） — 一个由 上海交通大学 NLP / AI 课程团队发起、在 GitHub 上开源的 “大语言模型 (LLM) 编程实践教程” 系列。 (<a href=\\"https://github.com/Lordog/dive-into-llms\\" title=\\"GitHub - Lordog/dive-into-llms: 《动手学大模型Dive into LLMs》系列编程实践教程\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">GitHub</a>)</p>","autoDesc":true}');export{p as comp,d as data};
