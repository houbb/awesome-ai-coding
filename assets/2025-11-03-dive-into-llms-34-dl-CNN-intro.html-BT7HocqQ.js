import{_ as i}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as a,a as t,o as n}from"./app-Br9pe4tt.js";const h={};function l(e,s){return n(),a("div",null,[...s[0]||(s[0]=[t(`<h1 id="chat" tabindex="-1"><a class="header-anchor" href="#chat"><span>chat</span></a></h1><h2 id="详细介绍一下-cnn" tabindex="-1"><a class="header-anchor" href="#详细介绍一下-cnn"><span>详细介绍一下 CNN</span></a></h2><p>太棒了👏你现在的问题正好是所有做 AI、尤其是做图像识别的入门者都会问的：</p><blockquote><p>到底什么是 CNN（卷积神经网络）？它的每一层在干嘛？为什么这么厉害？</p></blockquote><p>我们来系统、通俗、逐层地拆解它。<br> 我保证你读完这一篇，就能**“从概念到结构”完全吃透 CNN**。</p><hr><h2 id="🧠-一、什么是-cnn" tabindex="-1"><a class="header-anchor" href="#🧠-一、什么是-cnn"><span>🧠 一、什么是 CNN？</span></a></h2><p><strong>CNN（Convolutional Neural Network）</strong><br> 全称叫「卷积神经网络」，是一种专门处理<strong>图像、语音、视频</strong>等有“空间结构”的数据的神经网络。</p><p>它是深度学习里最核心的网络结构之一，主要用于：</p><ul><li>✅ 图像分类（如 MNIST、ImageNet）</li><li>✅ 目标检测（如 YOLO、Faster R-CNN）</li><li>✅ 语义分割（如 UNet）</li><li>✅ 人脸识别、OCR、医学影像、自动驾驶……</li></ul><p>可以说，只要涉及“看图”，就有 CNN 的身影。</p><hr><h2 id="🧩-二、cnn-的整体结构" tabindex="-1"><a class="header-anchor" href="#🧩-二、cnn-的整体结构"><span>🧩 二、CNN 的整体结构</span></a></h2><p>我们先看一下典型 CNN 的结构流程：</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-"><span class="line"><span>输入图像 → 卷积层 → 激活层(ReLU) → 池化层</span></span>
<span class="line"><span>          → 卷积层 → 激活层 → 池化层</span></span>
<span class="line"><span>          → 展平(Flatten)</span></span>
<span class="line"><span>          → 全连接层 → 输出层(分类)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>每一层都在干不一样的事情👇</p><hr><h2 id="🧱-三、cnn-的核心组成部分" tabindex="-1"><a class="header-anchor" href="#🧱-三、cnn-的核心组成部分"><span>🧱 三、CNN 的核心组成部分</span></a></h2><h3 id="_1️⃣-卷积层-convolution-layer-——提取特征" tabindex="-1"><a class="header-anchor" href="#_1️⃣-卷积层-convolution-layer-——提取特征"><span>1️⃣ 卷积层（Convolution Layer）——提取特征</span></a></h3><p>👉 <strong>核心作用：从图像中提取局部特征</strong></p><h4 id="🧩-工作原理" tabindex="-1"><a class="header-anchor" href="#🧩-工作原理"><span>🧩 工作原理</span></a></h4><p>卷积层会有一个或多个小矩阵（称为「卷积核」或「滤波器」），<br> 例如一个 3×3 的卷积核。</p><p>这个卷积核在图片上<strong>滑动（卷积）</strong>，<br> 每次滑动都会与对应区域的像素做“加权求和”，生成一个新的像素值。</p><p>👉 每个卷积核学到的东西不同，比如：</p><ul><li>有的检测“水平边缘”</li><li>有的检测“垂直边缘”</li><li>有的检测“曲线、圆角、纹理”</li></ul><p>这样，经过多个卷积核扫描后，<br> 你会得到多个「特征图（Feature Maps）」。</p><h4 id="🔢-举个例子" tabindex="-1"><a class="header-anchor" href="#🔢-举个例子"><span>🔢 举个例子：</span></a></h4><p>输入图片：28×28<br> 卷积核：3×3，步长1，padding=1<br> 输出特征图：仍然是 28×28<br> （因为 padding=1 保留边界）</p><p>每个卷积核都相当于一个“视觉滤镜”。</p><hr><h3 id="_2️⃣-激活层-activation-layer-——增加非线性" tabindex="-1"><a class="header-anchor" href="#_2️⃣-激活层-activation-layer-——增加非线性"><span>2️⃣ 激活层（Activation Layer）——增加非线性</span></a></h3><p>卷积本质是线性运算。<br> 为了让网络能学习到复杂的非线性特征（比如猫和狗的区别），<br> 我们要加一个激活函数，比如：</p><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-python"><span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">ReLU</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(x) </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> max</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">0</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, x)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>📈 优点：</p><ul><li>计算简单；</li><li>防止梯度消失；</li><li>模型表达力增强。</li></ul><hr><h3 id="_3️⃣-池化层-pooling-layer-——降低维度-保留关键信息" tabindex="-1"><a class="header-anchor" href="#_3️⃣-池化层-pooling-layer-——降低维度-保留关键信息"><span>3️⃣ 池化层（Pooling Layer）——降低维度，保留关键信息</span></a></h3><p>池化就是“信息压缩”。<br> 常见的池化方式是：</p><ul><li><strong>Max Pooling（最大池化）</strong>：取局部区域最大值</li><li><strong>Average Pooling（平均池化）</strong>：取平均值</li></ul><p>例如：<br> 一个 2×2 的池化核 + 步长 2<br> → 图像长宽减半（从 28×28 → 14×14）<br> → 参数更少、计算更快、特征更稳定（平移不敏感）</p><p>📉 就像人看图片时，不会记住每个像素，而是记住“有只猫”。</p><hr><h3 id="_4️⃣-dropout-层-正则化层" tabindex="-1"><a class="header-anchor" href="#_4️⃣-dropout-层-正则化层"><span>4️⃣ Dropout 层（正则化层）</span></a></h3><p>训练时随机“丢弃”部分神经元（比如 25%），<br> 防止模型记住训练集（过拟合）。<br> 推理时不会丢弃。</p><hr><h3 id="_5️⃣-全连接层-fully-connected-layer-——整合特征并分类" tabindex="-1"><a class="header-anchor" href="#_5️⃣-全连接层-fully-connected-layer-——整合特征并分类"><span>5️⃣ 全连接层（Fully Connected Layer）——整合特征并分类</span></a></h3><p>前面的卷积层提取了“局部特征”；<br> 全连接层把这些特征整合起来，<br> 输出最终的类别概率。</p><p>📊 比如：</p><div class="language-text line-numbers-mode" data-highlighter="shiki" data-ext="text" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-text"><span class="line"><span>输入：特征 [0.2, 0.9, 0.3, ...]</span></span>
<span class="line"><span>输出：[猫: 0.85, 狗: 0.10, 马: 0.05]</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><p>最后通过 <code>softmax</code> 输出概率分布。</p><hr><h2 id="🧮-四、cnn-的数学核心-卷积运算" tabindex="-1"><a class="header-anchor" href="#🧮-四、cnn-的数学核心-卷积运算"><span>🧮 四、CNN 的数学核心：卷积运算</span></a></h2><p>假设有一张灰度图（3×3）：</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-"><span class="line"><span>1 2 3</span></span>
<span class="line"><span>4 5 6</span></span>
<span class="line"><span>7 8 9</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>卷积核（2×2）：</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-"><span class="line"><span>1 0</span></span>
<span class="line"><span>0 -1</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><p>滑动计算：</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-"><span class="line"><span>(1*1 + 2*0 + 4*0 + 5*(-1)) = -4</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>然后移动卷积核继续计算。<br> 这一步就是 CNN 的最底层特征提取。</p><hr><h2 id="🔁-五、为什么-cnn-效果好" tabindex="-1"><a class="header-anchor" href="#🔁-五、为什么-cnn-效果好"><span>🔁 五、为什么 CNN 效果好？</span></a></h2><table><thead><tr><th>优点</th><th>说明</th></tr></thead><tbody><tr><td><strong>局部连接</strong></td><td>每个神经元只看局部区域（更接近人类视觉）</td></tr><tr><td><strong>权值共享</strong></td><td>同一个卷积核在全图扫描，参数更少</td></tr><tr><td><strong>平移不变性</strong></td><td>图像稍微移动、旋转不影响识别</td></tr><tr><td><strong>层级特征学习</strong></td><td>从“边缘”→“形状”→“物体”</td></tr><tr><td><strong>高泛化能力</strong></td><td>能适应各种图像任务</td></tr></tbody></table><hr><h2 id="🔍-六、cnn-的发展脉络-很关键" tabindex="-1"><a class="header-anchor" href="#🔍-六、cnn-的发展脉络-很关键"><span>🔍 六、CNN 的发展脉络（很关键！）</span></a></h2><table><thead><tr><th>年份</th><th>模型</th><th>特点</th></tr></thead><tbody><tr><td>1998</td><td><strong>LeNet-5</strong></td><td>手写数字识别（MNIST）CNN 开端</td></tr><tr><td>2012</td><td><strong>AlexNet</strong></td><td>ImageNet 冠军，CNN 崛起</td></tr><tr><td>2014</td><td><strong>VGGNet</strong></td><td>深层结构（16/19 层）</td></tr><tr><td>2014</td><td><strong>GoogLeNet</strong></td><td>引入 Inception 模块</td></tr><tr><td>2015</td><td><strong>ResNet</strong></td><td>提出残差连接，解决深层训练问题</td></tr><tr><td>2017</td><td><strong>MobileNet</strong></td><td>轻量化 CNN（用于手机端）</td></tr></tbody></table><p>这些模型都是 CNN 的进化版。</p><hr><h2 id="🧠-七、一个完整-cnn-示例-pytorch" tabindex="-1"><a class="header-anchor" href="#🧠-七、一个完整-cnn-示例-pytorch"><span>🧠 七、一个完整 CNN 示例（PyTorch）</span></a></h2><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-python"><span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> torch</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> torch.nn </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">as</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> nn</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">class</span><span style="--shiki-light:#C18401;--shiki-dark:#E5C07B;"> CNN</span><span style="--shiki-light:#C18401;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#C18401;--shiki-dark:#E5C07B;">nn</span><span style="--shiki-light:#C18401;--shiki-dark:#ABB2BF;">.</span><span style="--shiki-light:#C18401;--shiki-dark:#E5C07B;">Module</span><span style="--shiki-light:#C18401;--shiki-dark:#ABB2BF;">)</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">:</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">    def</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> __init__</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E5C07B;--shiki-dark-font-style:italic;">self</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">):</span></span>
<span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">        super</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#383A42;--shiki-dark:#D19A66;">CNN</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;">self</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">).</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">__init__</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span>
<span class="line"><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;">        self</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.conv1 </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> nn.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">Conv2d</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">1</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">32</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">kernel_size</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">3</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">padding</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">1</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;">        self</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.conv2 </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> nn.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">Conv2d</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">32</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">64</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">kernel_size</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">3</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">padding</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">1</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;">        self</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.pool </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> nn.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">MaxPool2d</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">2</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">2</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;">        self</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.dropout </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> nn.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">Dropout</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">0.25</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;">        self</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.fc1 </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> nn.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">Linear</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">64</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;"> *</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> 7</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;"> *</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> 7</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">128</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;">        self</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.fc2 </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> nn.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">Linear</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">128</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">10</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">    def</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;"> forward</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E5C07B;--shiki-dark-font-style:italic;">self</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#D19A66;--shiki-dark-font-style:italic;"> x</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">):</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        x </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> torch.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">relu</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;">self</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">conv1</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(x))</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        x </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;"> self</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">pool</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(torch.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">relu</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;">self</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">conv2</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(x)))</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        x </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;"> self</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">dropout</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(x)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        x </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> x.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">view</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">-</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">1</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">64</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;"> *</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> 7</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;"> *</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> 7</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        x </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> torch.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">relu</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;">self</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">fc1</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(x))</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        x </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;"> self</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">fc2</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(x)</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">        return</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> x</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><hr><h2 id="🧩-八、可视化理解-图像特征是怎么学的" tabindex="-1"><a class="header-anchor" href="#🧩-八、可视化理解-图像特征是怎么学的"><span>🧩 八、可视化理解（图像特征是怎么学的？）</span></a></h2><table><thead><tr><th>层级</th><th>学到的特征</th><th>类比</th></tr></thead><tbody><tr><td>第1层</td><td>边缘、线条</td><td>看清轮廓</td></tr><tr><td>第2层</td><td>局部形状</td><td>眼睛、鼻子、耳朵</td></tr><tr><td>第3层</td><td>组合结构</td><td>脸、身体、轮廓</td></tr><tr><td>第4层</td><td>语义概念</td><td>猫、狗、人、车</td></tr></tbody></table><p>CNN 就像一个“逐层抽象”的大脑。</p><hr><h2 id="✨-九、一句话总结" tabindex="-1"><a class="header-anchor" href="#✨-九、一句话总结"><span>✨ 九、一句话总结</span></a></h2><blockquote><p>CNN 是模仿人类视觉皮层的深度学习结构，<br> 通过卷积（局部特征）、池化（信息压缩）、多层抽象（语义理解），<br> 让机器能“看懂”图像中的模式与结构。</p></blockquote><h2 id="为什么-cnn-在图片识别效果更好" tabindex="-1"><a class="header-anchor" href="#为什么-cnn-在图片识别效果更好"><span>为什么 CNN 在图片识别效果更好？</span></a></h2><p>这是理解深度学习里最核心的一块内容之一。</p><p>我们来系统、通俗地讲一下：</p><hr><h2 id="🧠-一句话解释" tabindex="-1"><a class="header-anchor" href="#🧠-一句话解释"><span>🧠 一句话解释：</span></a></h2><blockquote><p><strong>CNN（卷积神经网络）之所以在图像识别上效果更好，是因为它能自动从图像中学习“局部特征”与“空间层次结构”，而不像传统算法那样依赖人工提取特征。</strong></p></blockquote><hr><h2 id="🔍-先回顾一下传统的思路" tabindex="-1"><a class="header-anchor" href="#🔍-先回顾一下传统的思路"><span>🔍 先回顾一下传统的思路</span></a></h2><p>在深度学习出现之前，图像识别大多靠人工设计特征：</p><p>比如识别猫：</p><ul><li>提取边缘 → 看看有没有胡须形状；</li><li>提取纹理 → 看毛发的密度；</li><li>提取颜色 → 猫的毛色范围；</li><li>再用 SVM、KNN、逻辑回归等分类器。</li></ul><p>📉 缺点：</p><ul><li>特征靠人“猜”，不一定对；</li><li>特征一旦换领域（比如换成识别人脸）就要重做；</li><li>特征太复杂时模型吃不下。</li></ul><hr><h2 id="🧩-cnn-的革命性改变" tabindex="-1"><a class="header-anchor" href="#🧩-cnn-的革命性改变"><span>🧩 CNN 的革命性改变</span></a></h2><p>CNN 直接对原始像素做处理，不需要人工特征。<br> 它自己“学会”哪些是重要的特征。</p><p>CNN 的三个核心思想：</p><ol><li><strong>局部连接（Local Connectivity）</strong></li><li><strong>权值共享（Weight Sharing）</strong></li><li><strong>多层抽象（Hierarchical Features）</strong></li></ol><p>我们分别看👇</p><hr><h3 id="🧱-1️⃣-局部连接-只看局部-不看全局" tabindex="-1"><a class="header-anchor" href="#🧱-1️⃣-局部连接-只看局部-不看全局"><span>🧱 1️⃣ 局部连接：只看局部，不看全局</span></a></h3><ul><li>普通全连接层：每个神经元都连接所有像素。<br> → 参数巨多、容易过拟合。</li><li>卷积层：每个神经元只看<strong>一小块区域（卷积核）</strong>。<br> → 比如一个 3×3 卷积核，只看 9 个像素。</li></ul><p>📸 类比：<br> 人看照片不是一次看全图，而是看“眼睛”“鼻子”“嘴巴”局部特征再组合。</p><hr><h3 id="♻️-2️⃣-权值共享-一个-滤镜-扫全图" tabindex="-1"><a class="header-anchor" href="#♻️-2️⃣-权值共享-一个-滤镜-扫全图"><span>♻️ 2️⃣ 权值共享：一个“滤镜”扫全图</span></a></h3><p>同一个卷积核在整张图上滑动，用<strong>同一组参数</strong>。<br> 比如有一个滤镜专门识别“边缘”，<br> 它会在图的每个角落找有没有边缘特征。</p><p>📉 好处：</p><ul><li>参数数量骤减；</li><li>更快训练；</li><li>能自动识别“同样的形状”出现在不同位置（平移不变性）。</li></ul><hr><h3 id="🌄-3️⃣-多层抽象-从低层到高层特征" tabindex="-1"><a class="header-anchor" href="#🌄-3️⃣-多层抽象-从低层到高层特征"><span>🌄 3️⃣ 多层抽象：从低层到高层特征</span></a></h3><p>CNN 的层级结构让它能“分层理解图片”：</p><table><thead><tr><th>层级</th><th>学到的特征</th><th>类比</th></tr></thead><tbody><tr><td>第1层</td><td>边缘、角点</td><td>看轮廓</td></tr><tr><td>第2层</td><td>纹理、颜色块</td><td>看毛发/阴影</td></tr><tr><td>第3层</td><td>形状、结构</td><td>看耳朵、眼睛</td></tr><tr><td>第4层</td><td>整体物体</td><td>猫、狗、人脸</td></tr></tbody></table><p>🧠 这叫做 <strong>特征层次结构（Feature Hierarchy）</strong>，<br> 人类视觉系统其实也是这么做的。</p><hr><h2 id="⚙️-具体优势总结" tabindex="-1"><a class="header-anchor" href="#⚙️-具体优势总结"><span>⚙️ 具体优势总结</span></a></h2><table><thead><tr><th>优势点</th><th>解释</th></tr></thead><tbody><tr><td>参数更少</td><td>权值共享让模型轻量</td></tr><tr><td>更能泛化</td><td>平移、旋转不敏感</td></tr><tr><td>自动特征学习</td><td>不需要人工特征</td></tr><tr><td>层级抽象能力</td><td>能从像素 → 形状 → 物体逐层理解</td></tr><tr><td>高可扩展性</td><td>能套在更大网络（ResNet、VGG、MobileNet）中</td></tr></tbody></table><hr><h2 id="🔬-举个实际例子" tabindex="-1"><a class="header-anchor" href="#🔬-举个实际例子"><span>🔬 举个实际例子</span></a></h2><p>假设我们识别手写数字 &quot;5&quot;：</p><ol><li>第1层卷积：学到“竖线”“横线”“弧线”；</li><li>第2层卷积：组合这些线条形成“半圆形”或“环形结构”；</li><li>第3层：识别“这就是数字5的轮廓”；</li><li>全连接层：根据特征图输出“类别5”。</li></ol><hr><h2 id="🧠-一句总结" tabindex="-1"><a class="header-anchor" href="#🧠-一句总结"><span>🧠 一句总结</span></a></h2><blockquote><p>CNN 擅长“从局部到全局”的自动特征提取，<br> 在图像识别中能捕捉空间结构关系，<br> 因而比传统神经网络和机器学习方法更有效、更泛化。</p></blockquote>`,119)])])}const d=i(h,[["render",l]]),k=JSON.parse('{"path":"/posts/learn-llms/2025-11-03-dive-into-llms-34-dl-CNN-intro.html","title":"dive-into-llms-34-CNN（Convolutional Neural Network，卷积神经网络）介绍","lang":"zh-CN","frontmatter":{"title":"dive-into-llms-34-CNN（Convolutional Neural Network，卷积神经网络）介绍","date":"2025-11-03T00:00:00.000Z","categories":["AI"],"tags":["ai","learn-note"],"published":true,"description":"chat 详细介绍一下 CNN 太棒了👏你现在的问题正好是所有做 AI、尤其是做图像识别的入门者都会问的： 到底什么是 CNN（卷积神经网络）？它的每一层在干嘛？为什么这么厉害？ 我们来系统、通俗、逐层地拆解它。 我保证你读完这一篇，就能**“从概念到结构”完全吃透 CNN**。 🧠 一、什么是 CNN？ CNN（Convolutional Neu...","head":[["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"dive-into-llms-34-CNN（Convolutional Neural Network，卷积神经网络）介绍\\",\\"image\\":[\\"\\"],\\"datePublished\\":\\"2025-11-03T00:00:00.000Z\\",\\"dateModified\\":\\"2025-12-27T05:15:15.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"老马啸西风\\",\\"url\\":\\"https://houbb.github.io\\"}]}"],["meta",{"property":"og:url","content":"https://houbb.github.io/awesome-ai-coding/posts/learn-llms/2025-11-03-dive-into-llms-34-dl-CNN-intro.html"}],["meta",{"property":"og:site_name","content":"老马啸西风"}],["meta",{"property":"og:title","content":"dive-into-llms-34-CNN（Convolutional Neural Network，卷积神经网络）介绍"}],["meta",{"property":"og:description","content":"chat 详细介绍一下 CNN 太棒了👏你现在的问题正好是所有做 AI、尤其是做图像识别的入门者都会问的： 到底什么是 CNN（卷积神经网络）？它的每一层在干嘛？为什么这么厉害？ 我们来系统、通俗、逐层地拆解它。 我保证你读完这一篇，就能**“从概念到结构”完全吃透 CNN**。 🧠 一、什么是 CNN？ CNN（Convolutional Neu..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2025-12-27T05:15:15.000Z"}],["meta",{"property":"article:tag","content":"learn-note"}],["meta",{"property":"article:tag","content":"ai"}],["meta",{"property":"article:published_time","content":"2025-11-03T00:00:00.000Z"}],["meta",{"property":"article:modified_time","content":"2025-12-27T05:15:15.000Z"}]]},"git":{"createdTime":1766812269000,"updatedTime":1766812515000,"contributors":[{"name":"bbhou","username":"bbhou","email":"1557740299@qq.com","commits":3,"url":"https://github.com/bbhou"}]},"readingTime":{"minutes":7.28,"words":2184},"filePathRelative":"posts/learn-llms/2025-11-03-dive-into-llms-34-dl-CNN-intro.md","excerpt":"\\n<h2>详细介绍一下 CNN</h2>\\n<p>太棒了👏你现在的问题正好是所有做 AI、尤其是做图像识别的入门者都会问的：</p>\\n<blockquote>\\n<p>到底什么是 CNN（卷积神经网络）？它的每一层在干嘛？为什么这么厉害？</p>\\n</blockquote>\\n<p>我们来系统、通俗、逐层地拆解它。<br>\\n我保证你读完这一篇，就能**“从概念到结构”完全吃透 CNN**。</p>\\n<hr>\\n<h2>🧠 一、什么是 CNN？</h2>\\n<p><strong>CNN（Convolutional Neural Network）</strong><br>\\n全称叫「卷积神经网络」，是一种专门处理<strong>图像、语音、视频</strong>等有“空间结构”的数据的神经网络。</p>","autoDesc":true}');export{d as comp,k as data};
